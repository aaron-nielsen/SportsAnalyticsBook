<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Probability | Sports Analytics</title>
  <meta name="description" content="Chapter 2 Probability | Sports Analytics Notes" />
  <meta name="generator" content="bookdown 0.27 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Probability | Sports Analytics" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://aaron-nielsen.github.io/SportsAnalyticsBook/images/csu.png" />
  <meta property="og:description" content="Chapter 2 Probability | Sports Analytics Notes" />
  <meta name="github-repo" content="aaron-nielsen.github.io/SportsAnalyticsBook/" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Probability | Sports Analytics" />
  
  <meta name="twitter:description" content="Chapter 2 Probability | Sports Analytics Notes" />
  <meta name="twitter:image" content="https://aaron-nielsen.github.io/SportsAnalyticsBook/images/csu.png" />

<meta name="author" content="Aaron Nielsen, Department of Statistics, Colorado State University" />


<meta name="date" content="2022-06-29" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="images/favicon.ico" type="image/x-icon" />
<link rel="prev" href="exploratory-data-analysis.html"/>
<link rel="next" href="monte-carlo-simulation.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="lib/css/bootstrap.min.css" type="text/css" />
<link rel="stylesheet" href="lib/css/style.css" type="text/css" />
<link rel="stylesheet" href="lib/css/lesson.css" type="text/css" />
<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Sports Analytics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About</a></li>
<li class="chapter" data-level="" data-path="current-tasks.html"><a href="current-tasks.html"><i class="fa fa-check"></i>Current Tasks</a></li>
<li class="chapter" data-level="1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html"><i class="fa fa-check"></i><b>1</b> Exploratory Data Analysis</a>
<ul>
<li class="chapter" data-level="1.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#getting-started-with-r"><i class="fa fa-check"></i><b>1.1</b> Getting Started With R</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#installing-r"><i class="fa fa-check"></i><b>1.1.1</b> Installing R</a></li>
<li class="chapter" data-level="1.1.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#some-r-basics"><i class="fa fa-check"></i><b>1.1.2</b> Some R Basics</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#descriptive-statistics"><i class="fa fa-check"></i><b>1.2</b> Descriptive Statistics</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#definitions"><i class="fa fa-check"></i><b>1.2.1</b> Definitions</a></li>
<li class="chapter" data-level="1.2.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#descriptive-statistics-1"><i class="fa fa-check"></i><b>1.2.2</b> Descriptive Statistics</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#visualizations"><i class="fa fa-check"></i><b>1.3</b> Visualizations</a></li>
<li class="chapter" data-level="1.4" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#baseball"><i class="fa fa-check"></i><b>1.4</b> Baseball</a></li>
<li class="chapter" data-level="1.5" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#football"><i class="fa fa-check"></i><b>1.5</b> Football</a></li>
<li class="chapter" data-level="1.6" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#basketball"><i class="fa fa-check"></i><b>1.6</b> Basketball</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#four-factors"><i class="fa fa-check"></i><b>1.6.1</b> Four Factors</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#soccer"><i class="fa fa-check"></i><b>1.7</b> Soccer</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#bar-plot"><i class="fa fa-check"></i><b>1.7.1</b> Bar Plot</a></li>
<li class="chapter" data-level="1.7.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#scatter-plot"><i class="fa fa-check"></i><b>1.7.2</b> Scatter Plot</a></li>
<li class="chapter" data-level="1.7.3" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#density-ridges-plot"><i class="fa fa-check"></i><b>1.7.3</b> Density Ridges Plot</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#volleyball"><i class="fa fa-check"></i><b>1.8</b> Volleyball</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#scatter-plot-1"><i class="fa fa-check"></i><b>1.8.1</b> Scatter Plot</a></li>
<li class="chapter" data-level="1.8.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#box-plot"><i class="fa fa-check"></i><b>1.8.2</b> Box Plot</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#hockey"><i class="fa fa-check"></i><b>1.9</b> Hockey</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>2</b> Probability</a>
<ul>
<li class="chapter" data-level="" data-path="probability.html"><a href="probability.html#chapter-preview"><i class="fa fa-check"></i>Chapter Preview</a></li>
<li class="chapter" data-level="2.1" data-path="probability.html"><a href="probability.html#definitions-1"><i class="fa fa-check"></i><b>2.1</b> Definitions</a></li>
<li class="chapter" data-level="2.2" data-path="probability.html"><a href="probability.html#set-theory"><i class="fa fa-check"></i><b>2.2</b> Set Theory</a></li>
<li class="chapter" data-level="2.3" data-path="probability.html"><a href="probability.html#probability-axioms-and-properties"><i class="fa fa-check"></i><b>2.3</b> Probability Axioms and Properties</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="probability.html"><a href="probability.html#axioms-of-probability"><i class="fa fa-check"></i><b>2.3.1</b> Axioms of Probability</a></li>
<li class="chapter" data-level="2.3.2" data-path="probability.html"><a href="probability.html#properties-of-probability"><i class="fa fa-check"></i><b>2.3.2</b> Properties of Probability</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="probability.html"><a href="probability.html#laws-of-probability"><i class="fa fa-check"></i><b>2.4</b> Laws of Probability</a></li>
<li class="chapter" data-level="2.5" data-path="probability.html"><a href="probability.html#combinatorics"><i class="fa fa-check"></i><b>2.5</b> Combinatorics</a></li>
<li class="chapter" data-level="2.6" data-path="probability.html"><a href="probability.html#odds-and-gambling"><i class="fa fa-check"></i><b>2.6</b> Odds and Gambling</a></li>
<li class="chapter" data-level="2.7" data-path="probability.html"><a href="probability.html#random-variables"><i class="fa fa-check"></i><b>2.7</b> Random Variables</a></li>
<li class="chapter" data-level="2.8" data-path="probability.html"><a href="probability.html#common-random-variables"><i class="fa fa-check"></i><b>2.8</b> Common Random Variables</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="probability.html"><a href="probability.html#binomial-rvs"><i class="fa fa-check"></i><b>2.8.1</b> Binomial RVs</a></li>
<li class="chapter" data-level="2.8.2" data-path="probability.html"><a href="probability.html#geometric-rvs"><i class="fa fa-check"></i><b>2.8.2</b> Geometric RVs</a></li>
<li class="chapter" data-level="2.8.3" data-path="probability.html"><a href="probability.html#poisson-rvs"><i class="fa fa-check"></i><b>2.8.3</b> Poisson RVs</a></li>
<li class="chapter" data-level="2.8.4" data-path="probability.html"><a href="probability.html#normal-rvs"><i class="fa fa-check"></i><b>2.8.4</b> Normal RVs</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="probability.html"><a href="probability.html#extra-stuff"><i class="fa fa-check"></i><b>2.9</b> Extra Stuff</a>
<ul>
<li class="chapter" data-level="2.9.1" data-path="probability.html"><a href="probability.html#sets-and-conditional-probability"><i class="fa fa-check"></i><b>2.9.1</b> Sets and Conditional Probability</a></li>
<li class="chapter" data-level="2.9.2" data-path="probability.html"><a href="probability.html#binomials-and-multinomials"><i class="fa fa-check"></i><b>2.9.2</b> Binomials and Multinomials</a></li>
<li class="chapter" data-level="2.9.3" data-path="probability.html"><a href="probability.html#expectation---baseball"><i class="fa fa-check"></i><b>2.9.3</b> Expectation - Baseball</a></li>
<li class="chapter" data-level="2.9.4" data-path="probability.html"><a href="probability.html#basketball-scenario"><i class="fa fa-check"></i><b>2.9.4</b> Basketball Scenario</a></li>
<li class="chapter" data-level="2.9.5" data-path="probability.html"><a href="probability.html#multiple-probability-distributions---basketball"><i class="fa fa-check"></i><b>2.9.5</b> Multiple Probability Distributions - Basketball</a></li>
<li class="chapter" data-level="2.9.6" data-path="probability.html"><a href="probability.html#law-of-total-probability---hockey"><i class="fa fa-check"></i><b>2.9.6</b> Law of Total Probability - Hockey</a></li>
<li class="chapter" data-level="2.9.7" data-path="probability.html"><a href="probability.html#law-of-total-probability---baseball"><i class="fa fa-check"></i><b>2.9.7</b> Law of Total Probability - Baseball</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="monte-carlo-simulation.html"><a href="monte-carlo-simulation.html"><i class="fa fa-check"></i><b>3</b> Monte Carlo Simulation</a>
<ul>
<li class="chapter" data-level="3.1" data-path="monte-carlo-simulation.html"><a href="monte-carlo-simulation.html#a-few-reminderstips-for-simulation-and-a-basic-example"><i class="fa fa-check"></i><b>3.1</b> A few reminders/tips for simulation, and a basic example</a></li>
<li class="chapter" data-level="3.2" data-path="monte-carlo-simulation.html"><a href="monte-carlo-simulation.html#streak-simulation---basketball"><i class="fa fa-check"></i><b>3.2</b> Streak Simulation - Basketball</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="statistical-inference.html"><a href="statistical-inference.html"><i class="fa fa-check"></i><b>4</b> Statistical Inference</a>
<ul>
<li class="chapter" data-level="4.1" data-path="statistical-inference.html"><a href="statistical-inference.html#one-sample-and-two-sample-t-tests-and-confidence-intervals"><i class="fa fa-check"></i><b>4.1</b> One Sample and Two Sample t-tests and confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="correlation.html"><a href="correlation.html"><i class="fa fa-check"></i><b>5</b> Correlation</a></li>
<li class="chapter" data-level="6" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>6</b> Linear Regression</a></li>
<li class="chapter" data-level="7" data-path="data-scraping.html"><a href="data-scraping.html"><i class="fa fa-check"></i><b>7</b> Data Scraping</a></li>
<li class="chapter" data-level="8" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html"><i class="fa fa-check"></i><b>8</b> Principal Component Analysis</a></li>
<li class="chapter" data-level="9" data-path="clustering.html"><a href="clustering.html"><i class="fa fa-check"></i><b>9</b> Clustering</a></li>
<li class="chapter" data-level="10" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>10</b> Classification</a></li>
<li class="chapter" data-level="11" data-path="decision-trees.html"><a href="decision-trees.html"><i class="fa fa-check"></i><b>11</b> Decision Trees</a>
<ul>
<li class="chapter" data-level="11.1" data-path="decision-trees.html"><a href="decision-trees.html#random-forests"><i class="fa fa-check"></i><b>11.1</b> Random Forests</a></li>
<li class="chapter" data-level="11.2" data-path="decision-trees.html"><a href="decision-trees.html#gradient-boosting"><i class="fa fa-check"></i><b>11.2</b> Gradient Boosting</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="non-parametric-statistics.html"><a href="non-parametric-statistics.html"><i class="fa fa-check"></i><b>12</b> Non-parametric Statistics</a></li>
<li class="chapter" data-level="13" data-path="baseball-1.html"><a href="baseball-1.html"><i class="fa fa-check"></i><b>13</b> Baseball</a></li>
<li class="chapter" data-level="14" data-path="football-1.html"><a href="football-1.html"><i class="fa fa-check"></i><b>14</b> Football</a></li>
<li class="chapter" data-level="15" data-path="basketball-1.html"><a href="basketball-1.html"><i class="fa fa-check"></i><b>15</b> Basketball</a></li>
<li class="chapter" data-level="16" data-path="soccer-1.html"><a href="soccer-1.html"><i class="fa fa-check"></i><b>16</b> Soccer</a></li>
<li class="chapter" data-level="17" data-path="hockey-1.html"><a href="hockey-1.html"><i class="fa fa-check"></i><b>17</b> Hockey</a></li>
<li class="chapter" data-level="18" data-path="volleyball-1.html"><a href="volleyball-1.html"><i class="fa fa-check"></i><b>18</b> Volleyball</a>
<ul>
<li class="chapter" data-level="18.1" data-path="volleyball-1.html"><a href="volleyball-1.html#resources"><i class="fa fa-check"></i><b>18.1</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="other-sports.html"><a href="other-sports.html"><i class="fa fa-check"></i><b>19</b> Other Sports</a></li>
<li class="chapter" data-level="20" data-path="text-solutions.html"><a href="text-solutions.html"><i class="fa fa-check"></i><b>20</b> Text solutions</a>
<ul>
<li class="chapter" data-level="20.1" data-path="text-solutions.html"><a href="text-solutions.html#chapter-1"><i class="fa fa-check"></i><b>20.1</b> Chapter 1</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="aarons-stuff.html"><a href="aarons-stuff.html"><i class="fa fa-check"></i><b>21</b> Aaron’s stuff</a>
<ul>
<li class="chapter" data-level="21.1" data-path="aarons-stuff.html"><a href="aarons-stuff.html#notes-for-chapter-2-probability"><i class="fa fa-check"></i><b>21.1</b> Notes for Chapter 2 (Probability)</a></li>
<li class="chapter" data-level="21.2" data-path="aarons-stuff.html"><a href="aarons-stuff.html#suggested-readings"><i class="fa fa-check"></i><b>21.2</b> Suggested Readings</a>
<ul>
<li class="chapter" data-level="21.2.1" data-path="aarons-stuff.html"><a href="aarons-stuff.html#moneyball"><i class="fa fa-check"></i><b>21.2.1</b> Moneyball</a></li>
<li class="chapter" data-level="21.2.2" data-path="aarons-stuff.html"><a href="aarons-stuff.html#future-value"><i class="fa fa-check"></i><b>21.2.2</b> Future Value</a></li>
</ul></li>
<li class="chapter" data-level="21.3" data-path="aarons-stuff.html"><a href="aarons-stuff.html#notes-for-chapter-4-simulation"><i class="fa fa-check"></i><b>21.3</b> Notes for Chapter 4 (Simulation)</a>
<ul>
<li class="chapter" data-level="21.3.1" data-path="aarons-stuff.html"><a href="aarons-stuff.html#baseball-simulation-example"><i class="fa fa-check"></i><b>21.3.1</b> Baseball Simulation Example</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Sports Analytics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="probability" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">Chapter 2</span> Probability<a href="probability.html#probability" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="chapter-preview" class="section level2 unnumbered hasAnchor">
<h2>Chapter Preview<a href="probability.html#chapter-preview" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Simply put, probability is the study of randomness. In this chapter, we will define probability, learn rules of probability, and apply these rules to sports data.</p>
</div>
<div id="definitions-1" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Definitions<a href="probability.html#definitions-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="definition">
<p><span id="def:unlabeled-div-34" class="definition"><strong>Definition 2.1  </strong></span>An <strong><em>experiment</em></strong> is any activity or process whose outcome is subject to uncertainty.</p>
</div>
<div class="definition">
<p><span id="def:unlabeled-div-35" class="definition"><strong>Definition 2.2  </strong></span>The <strong><em>sample space</em></strong> of an experiment, denoted by <span class="math inline">\(\Omega\)</span> or <span class="math inline">\(\mathcal{S}\)</span>, is the set of all possible outcomes of that experiment.</p>
</div>
<div class="definition">
<p><span id="def:unlabeled-div-36" class="definition"><strong>Definition 2.3  </strong></span>An <strong><em>event</em></strong> is any collection (subset) of outcomes contained in the sample space, <span class="math inline">\(\Omega\)</span>.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-37" class="example"><strong>Example 2.1  </strong></span><span class="math display">\[ \]</span></p>
</div>
<p><br />
<br />
<br />
<br />
<br />
</p>
<div class="example">
<p><span id="exm:unlabeled-div-38" class="example"><strong>Example 2.2  </strong></span><span class="math display">\[ \]</span></p>
</div>
<p> <br />
<br />
<br />
<br />
</p>
</div>
<div id="set-theory" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> Set Theory<a href="probability.html#set-theory" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>For the following examples, suppose that we are interested in the batting outcomes of a plate appearance in softball.</p>
<p>Let <span class="math inline">\(A\)</span> be the event that the batter gets walked, let <span class="math inline">\(B\)</span> be the event that the batter gets a hit, let <span class="math inline">\(C\)</span> be the event that the batter strikes out, and let <span class="math inline">\(D\)</span> be the event that the batter makes it to first base at the end of their at bat.</p>
<p>We will define a handful of set operations to help us when we begin calculating the probability of different events occurring.</p>
<div class="definition">
<p><span id="def:unlabeled-div-39" class="definition"><strong>Definition 2.4  </strong></span>The <strong><em>compliment</em></strong> of an event <span class="math inline">\(A\)</span>, denoted by <span class="math inline">\(A^c\)</span> or <span class="math inline">\(A&#39;\)</span>, is the set of all outcomes in <span class="math inline">\(\Omega\)</span> that are not contained in <span class="math inline">\(A\)</span>.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-40" class="example"><strong>Example 2.3  </strong></span>Draw a Venn diagram illustrating <span class="math inline">\(A^c\)</span> and describe the event.</p>
</div>
<p><br />
<br />
<br />
<br />
<br />
</p>
<div class="definition">
<p><span id="def:unlabeled-div-41" class="definition"><strong>Definition 2.5  </strong></span>The <strong><em>union</em></strong> of two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, denoted by <span class="math inline">\(A \cup B\)</span> and read “<span class="math inline">\(A\)</span> or <span class="math inline">\(B\)</span>”, is the event consisting of all outcomes that are either in <span class="math inline">\(A\)</span> or <span class="math inline">\(B\)</span> or in both.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-42" class="example"><strong>Example 2.4  </strong></span>Draw a Venn diagram illustrating <span class="math inline">\(A \cup D\)</span> and describe the event.</p>
</div>
<p><br />
<br />
<br />
<br />
<br />
</p>
<div class="definition">
<p><span id="def:unlabeled-div-43" class="definition"><strong>Definition 2.6  </strong></span>The <strong><em>intersection</em></strong> of two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, denoted by <span class="math inline">\(A \cap B\)</span> and read “<span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>”, is the event consisting of all outcomes that are in both <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-44" class="example"><strong>Example 2.5  </strong></span>Draw a Venn diagram illustrating <span class="math inline">\(A \cap D\)</span> and describe the event.</p>
</div>
<p><br />
<br />
<br />
<br />
<br />
</p>
<div class="definition">
<p><span id="def:unlabeled-div-45" class="definition"><strong>Definition 2.7  </strong></span>The <strong><em>difference</em></strong> of two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, denoted by <span class="math inline">\(A \mathbin{/} B\)</span> and read “difference of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>”, is
the event consisting of all outcomes that are in <span class="math inline">\(A\)</span> but not in <span class="math inline">\(B\)</span>.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-46" class="example"><strong>Example 2.6  </strong></span>Draw a Venn diagram illustrating <span class="math inline">\(D \mathbin{/} A\)</span> and describe the event.</p>
</div>
<p><br />
<br />
<br />
<br />
<br />
</p>
<div class="definition">
<p><span id="def:unlabeled-div-47" class="definition"><strong>Definition 2.8  </strong></span>Two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are said to be <strong><em>disjoint</em></strong> (or <strong><em>mutually exclusive</em></strong>) if <span class="math inline">\(A \cap B = \emptyset\)</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-48" class="example"><strong>Example 2.7  </strong></span>Are the events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> disjoint? How about <span class="math inline">\(A\)</span> and <span class="math inline">\(D\)</span>?</p>
</div>
<p><br />
<br />
<br />
<br />
<br />
</p>
</div>
<div id="probability-axioms-and-properties" class="section level2 hasAnchor" number="2.3">
<h2><span class="header-section-number">2.3</span> Probability Axioms and Properties<a href="probability.html#probability-axioms-and-properties" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>There are some basic assumptions of “axioms” which are the foundation of the theory of probability. Andrey Kolmogorov first described these axioms in 1933.</p>
<div id="axioms-of-probability" class="section level3 hasAnchor" number="2.3.1">
<h3><span class="header-section-number">2.3.1</span> Axioms of Probability<a href="probability.html#axioms-of-probability" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(P(A) \geq 0\)</span>, for any event <span class="math inline">\(A\)</span><br />
</li>
<li><span class="math inline">\(P(\Omega) = 1\)</span><br />
</li>
<li>If <span class="math inline">\(A_1, A_2, A_3, \ldots\)</span> is a collection of disjoint events, then:<br />
<span class="math inline">\(P(\cup_{i=1}^{\infty} A_i) = P(A_1 \cup A_2 \cup \ldots ) = \sum_{i=1}^{\infty} P(A_i)\)</span></li>
</ol>
<p>Note that all probabilities are between 0 and 1, that is, for any event <span class="math inline">\(A\)</span>, <span class="math inline">\(0 \leq P(A) \leq 1\)</span>.</p>
<p>We can convert to percentages by multiplying probabilities by 100, however, this is a set that is only done after all calculations have been completed.</p>
</div>
<div id="properties-of-probability" class="section level3 hasAnchor" number="2.3.2">
<h3><span class="header-section-number">2.3.2</span> Properties of Probability<a href="probability.html#properties-of-probability" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p><span class="math inline">\(P(\emptyset) = 0\)</span><br />
</p></li>
<li><p><span class="math inline">\(P(A^c) = 1 - P(A)\)</span></p></li>
<li><p><span class="math inline">\(P(A \cup B) = P(A) + P(B) - P(A \cap B)\)</span></p></li>
<li><p><span class="math inline">\(P(A \cup B \cup C) = \\ P(A) + P(B) + P(C) - P(A \cap B) - P(A \cap C) - P(B \cap C) + P(A \cap B \cap C)\)</span></p></li>
<li><p><span class="math inline">\(P([A \cup B]^c) = P(A^c \cap B^c)\)</span></p></li>
<li><p><span class="math inline">\(P([A \cap B]^c) = P(A^c \cup B^c)\)</span></p></li>
</ul>
</div>
</div>
<div id="laws-of-probability" class="section level2 hasAnchor" number="2.4">
<h2><span class="header-section-number">2.4</span> Laws of Probability<a href="probability.html#laws-of-probability" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="definition">
<p><span id="def:unlabeled-div-49" class="definition"><strong>Definition 2.9  </strong></span>Let <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> be two events such that <span class="math inline">\(P(B)&gt;0\)</span>. Then the <strong><em>conditional probability</em></strong> of <span class="math inline">\(A\)</span> given <span class="math inline">\(B\)</span>, written <span class="math inline">\(P(A|B)\)</span>, is given by:
<span class="math inline">\(P(A|B) = \frac{P(A \cap B)}{P(B)}\)</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-50" class="example"><strong>Example 2.8  </strong></span>In 2001, Barry Bonds broke the single season home run record with 73 home runs. In this season, he had 664 plate appearances, 156 hits, 177 walks and 9 hit by pitches. Given that Bonds reached base (via hit, walk, or HBP), what was the probability that he got a hit?</p>
</div>
<p><br />
<br />
<br />
</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-51" class="theorem"><strong>Theorem 2.1  (Multiplication Rule) </strong></span>For any two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, <span class="math inline">\(P(A \cap B) = P(B|A) \cdot P(A)\)</span>.</p>
</div>
<div class="definition">
<p><span id="def:unlabeled-div-52" class="definition"><strong>Definition 2.10  </strong></span>Events <span class="math inline">\(A_1, A_2, \ldots, A_n\)</span> are said to form a <strong><em>partition</em></strong> of a sample space <span class="math inline">\(\Omega\)</span> if both:<br />
(i) <span class="math inline">\(A_i \cap A_j = \emptyset\)</span> (<span class="math inline">\(i \neq j\)</span>)<br />
(ii) <span class="math inline">\(\cup_{i=1}^n A_i = \Omega\)</span><br />
</p>
</div>
<div class="theorem">
<p><span id="thm:unlabeled-div-53" class="theorem"><strong>Theorem 2.2  (Law of Total Probability) </strong></span>Suppose events <span class="math inline">\(A_1, A_2, \ldots, A_n\)</span> form a partition of <span class="math inline">\(\Omega\)</span>, then:
<span class="math inline">\(P(B) = P(B|A_1)P(A_1) + P(B|A_2)P(A_2) + \ldots P(B|A_n)P(A_n)\)</span></p>
</div>
<div class="theorem">
<p><span id="thm:unlabeled-div-54" class="theorem"><strong>Theorem 2.3  (Bayes Theorem: simple version) </strong></span>Suppose events <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span> form a partition of <span class="math inline">\(\Omega\)</span>, then:
<span class="math inline">\(P(B|A) = \frac{P(B \cap A)}{P(A)} = \frac{P(A|B)P(B)}{P(A|B)P(B)+P(A|C)P(C)}\)</span></p>
</div>
<div class="theorem">
<p><span id="thm:unlabeled-div-55" class="theorem"><strong>Theorem 2.4  (Bayes Theorem) </strong></span>Suppose events <span class="math inline">\(B_1, B_2, \ldots, B_n\)</span> form a partition of <span class="math inline">\(\Omega\)</span>, then:
<span class="math inline">\(P(B_k|A) = \frac{P(B_k \cap A)}{P(A)} = \frac{P(A|B_k)P(B_k)}{P(A|B_1)P(B_1)+P(A|B_2)P(B_2) + \ldots + P(A|B_n)P(B_n)}\)</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-56" class="example"><strong>Example 2.9  </strong></span>Over the course of a season, a hockey player scored a goal 30% of the time during a home game, and <span class="math inline">\(P(player\ scores\ |\ away\ game) = .18\)</span>. Assume all games are either home or away. Use this information to answer the following questions.</p>
</div>
<ol style="list-style-type: lower-alpha">
<li><p>What is the probability the player scored a goal in any game if there were an equal number of home and away games?<br />
<br />
<br />
<br />
</p></li>
<li><p>What is the probability the player scored a goal in any game if there were twice as many home games as away games?<br />
<br />
<br />
<br />
</p></li>
<li><p>What is the probability the player scored a goal in any game if the ratio of home games to away games is 2:3?<br />
<br />
<br />
<br />
</p></li>
</ol>
</div>
<div id="combinatorics" class="section level2 hasAnchor" number="2.5">
<h2><span class="header-section-number">2.5</span> Combinatorics<a href="probability.html#combinatorics" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Combinatorics is the mathematical study of counting, particularly with respect to permutations and combinations.</p>
<div class="definition">
<p><span id="def:unlabeled-div-57" class="definition"><strong>Definition 2.11  </strong></span>The <strong><em>factorial function (<span class="math inline">\(n!\)</span>)</em></strong> is defined for all positive integers by: <span class="math inline">\(n! = n \cdot (n-1) \cdot \ldots 2 \cdot 1\)</span></p>
</div>
<p>Note that <span class="math inline">\(0! \equiv 1\)</span> and <span class="math inline">\(1! \equiv 1\)</span>.</p>
<div class="definition">
<p><span id="def:unlabeled-div-58" class="definition"><strong>Definition 2.12  </strong></span>An ordered subset is called a <strong><em>permutation</em></strong>. The number of permutations of size <span class="math inline">\(k\)</span> that can be formed from the <span class="math inline">\(n\)</span> elements in a set is given by: <span class="math inline">\(P_{n,k} = \frac{n!}{(n-k)!}\)</span></p>
</div>
<div class="definition">
<p><span id="def:unlabeled-div-59" class="definition"><strong>Definition 2.13  </strong></span>An unordered subset is called a <strong><em>combination</em></strong>. The number of combinations of size <span class="math inline">\(k\)</span> that can be formed from the <span class="math inline">\(n\)</span> elements in a set is given by: <span class="math inline">\(C_{n,k} = {n \choose k} = \frac{n!}{k! \cdot (n-k)!}\)</span></p>
</div>
<div class="theorem">
<p><span id="thm:unlabeled-div-60" class="theorem"><strong>Theorem 2.5  (Product Rule for Ordered Pairs) </strong></span>If the first element of an ordered pair can be selected in <span class="math inline">\(n_1\)</span> ways and for each of the these <span class="math inline">\(n_1\)</span> ways the second element of the pair can be selected in <span class="math inline">\(n_2\)</span> ways, then the number of pairs is <span class="math inline">\(n_1 \cdot n_2\)</span>.</p>
</div>
<div class="theorem">
<p><span id="thm:unlabeled-div-61" class="theorem"><strong>Theorem 2.6  (Generalized Product Rule) </strong></span>Suppose a set consists of <span class="math inline">\(k\)</span> elements (k-tuples) and that there are <span class="math inline">\(n_1\)</span> possible choices for the first element, <span class="math inline">\(n_2\)</span> possible choices for the second element, … , and <span class="math inline">\(n_k\)</span> possible choices for the <span class="math inline">\(k^\text{th}\)</span> element, then there are <span class="math inline">\(n_1 \cdot n_2 \cdot \ldots \cdot n_k\)</span> possible k-tuples.</p>
</div>
</div>
<div id="odds-and-gambling" class="section level2 hasAnchor" number="2.6">
<h2><span class="header-section-number">2.6</span> Odds and Gambling<a href="probability.html#odds-and-gambling" class="anchor-section" aria-label="Anchor link to header"></a></h2>
</div>
<div id="random-variables" class="section level2 hasAnchor" number="2.7">
<h2><span class="header-section-number">2.7</span> Random Variables<a href="probability.html#random-variables" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="definition">
<p><span id="def:unlabeled-div-62" class="definition"><strong>Definition 2.14  </strong></span>Let <span class="math inline">\(\Omega\)</span> be the sample space of an experiment. A <strong><em>random variable</em></strong> is a rule that associates a number with each outcome in <span class="math inline">\(\Omega\)</span>. In other words, a random variable is a function whose domain is <span class="math inline">\(\Omega\)</span> and whose range is the set of real numbers.</p>
</div>
<p>Random variables are be broken down into subcategories:<br />
1. <strong><em>Discrete random variables</em></strong> - random variables which have a sample space that is finite or countably infinite.<br />
2. <strong><em>Continuous random variables</em></strong> - random variables which have a sample space that is uncountably infinite (such as an interval of real numbers)</p>
<p><strong><em>Discrete</em></strong> and <strong><em>Continuous</em></strong> random variables use similar yet slightly different mathematical tools. Discrete random variables involve working with “sums” and continuous random variables involve working with “integrals”.</p>
<div class="example">
<p><span id="exm:unlabeled-div-63" class="example"><strong>Example 2.10  </strong></span><span class="math display">\[ \]</span></p>
</div>
<p><br />
<br />
<br />
</p>
<div class="example">
<p><span id="exm:unlabeled-div-64" class="example"><strong>Example 2.11  </strong></span><span class="math display">\[ \]</span></p>
</div>
<p><br />
<br />
<br />
</p>
<div class="definition">
<p><span id="def:unlabeled-div-65" class="definition"><strong>Definition 2.15  </strong></span>A <strong><em>probability distribution</em></strong> is a function that gives probabilities of different possible outcomes for a given experiment.</p>
</div>
<p>The probability distribution for a discrete random variable, <span class="math inline">\(p(x)\)</span>, is called a <strong><em>probability mass function (pmf)</em></strong>.</p>
<p>The probability distribution for a continuous random variable, <span class="math inline">\(f(x)\)</span>, is called a <strong><em>probability density function (pdf)</em></strong>.</p>
<div class="example">
<p><span id="exm:unlabeled-div-66" class="example"><strong>Example 2.12  </strong></span>Suppose the Colorado Rockies are playing a four game series against the Chicago Cubs and that the Rockies have a 65% chance of winning an individual game. Further, assume that the games are independent. The following PMF describes the outcomes (number of Rockies wins) and their probabilities.</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<tbody>
<tr>
<td style="text-align:left;">
Rockies wins, X
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
2.000
</td>
<td style="text-align:right;">
3.000
</td>
<td style="text-align:right;">
4.000
</td>
</tr>
<tr>
<td style="text-align:left;">
Probability, p(X)
</td>
<td style="text-align:right;">
0.015
</td>
<td style="text-align:right;">
0.111
</td>
<td style="text-align:right;">
0.311
</td>
<td style="text-align:right;">
0.384
</td>
<td style="text-align:right;">
0.179
</td>
</tr>
</tbody>
</table>
<p>What is the probability that the Rockies win zero games? What is the probability that the Rockies win at least two games? Why might the independence assumption be false?</p>
</div>
<p><br />
<br />
<br />
<br />
<br />
</p>
<p>We may be interested in describing the center or average value of our random variable. We can do this with the following definitions.</p>
<div class="definition">
<p><span id="def:unlabeled-div-67" class="definition"><strong>Definition 2.16  </strong></span>The <strong><em>expected value</em></strong> (or <strong><em>population mean</em></strong> or <strong><em>average</em></strong>) of a random variable <span class="math inline">\(X\)</span> is given by:<br />
</p>
<ol style="list-style-type: lower-roman">
<li><p><span class="math inline">\(E[X] = \mu = \sum_{x \in \Omega} x \cdot p(x)\)</span> (for discrete random variables)</p></li>
<li><p><span class="math inline">\(E[X] = \mu = \int_{x \in \Omega} x \cdot f(x) dx\)</span> (for continuous random variables)</p></li>
</ol>
</div>
<p>For this class, evaluating integrals is not essential, so we will avoid using Calculus (integrals and derivatives) when possible.</p>
<p>Sometimes, it makes sense to calculate the expected value of a function of a random variable. This can be easily done with a slight modification to the previous definition. Let <span class="math inline">\(h(X)\)</span> be some function of a random variable <span class="math inline">\(X\)</span>. The expected value of <span class="math inline">\(h(X)\)</span>, <span class="math inline">\(E[h(X)]\)</span>, is given by:</p>
<ol style="list-style-type: lower-roman">
<li><p><span class="math inline">\(E[h(X)] = \sum_{x \in \Omega} h(x) \cdot p(x)\)</span> (for discrete random variables)</p></li>
<li><p><span class="math inline">\(E[h(X)] = \int_{x \in \Omega} h(x) \cdot f(x) dx\)</span> (for continuous random variables)</p></li>
</ol>
<div class="example">
<p><span id="exm:unlabeled-div-68" class="example"><strong>Example 2.13  </strong></span>For the Rockies/Cubs four game series example, calculate <span class="math inline">\(E[X]\)</span> and <span class="math inline">\(E[X^2]\)</span>.</p>
</div>
<p><br />
<br />
<br />
<br />
<br />
</p>
<p>The spread or variability associated with a random variable can be calculated using expected values as well.</p>
<div class="definition">
<p><span id="def:unlabeled-div-69" class="definition"><strong>Definition 2.17  </strong></span>The <strong><em>population variance</em></strong> of a random variable <span class="math inline">\(X\)</span> is given by:<br />
</p>
<ol style="list-style-type: lower-roman">
<li><p><span class="math inline">\(Var(X) = \sum_{x \in \Omega} (x-\mu)^2 \cdot p(x)\)</span> (for discrete random variables)</p></li>
<li><p><span class="math inline">\(Var(X) = \int_{x \in \Omega} (x-\mu)^2 \cdot f(x) dx\)</span> (for continuous random variables)</p></li>
</ol>
</div>
<p>There is also a shortcut formula for calculating variance:<br />
</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-70" class="theorem"><strong>Theorem 2.7  </strong></span><span class="math inline">\(Var(X) = E[X^2] - (E[X])^2\)</span></p>
</div>
<div class="definition">
<p><span id="def:unlabeled-div-71" class="definition"><strong>Definition 2.18  </strong></span>The <strong><em>population standard deviation</em></strong> of a random variable <span class="math inline">\(X\)</span> is given by:<br />
</p>
<p><span class="math inline">\(SD(X) = \sigma = \sqrt{Var(X)} = \sqrt{E[X^2]-(E[X])^2}\)</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-72" class="example"><strong>Example 2.14  </strong></span>For the Rockies/Cubs four game series example, calculate <span class="math inline">\(Var(X)\)</span>.</p>
</div>
<p><br />
<br />
<br />
<br />
<br />
</p>
</div>
<div id="common-random-variables" class="section level2 hasAnchor" number="2.8">
<h2><span class="header-section-number">2.8</span> Common Random Variables<a href="probability.html#common-random-variables" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>There are several families of random variables that show up frequently in applications. Some of these random variables include:
- Binomial
- Geometric
- Poisson
- Normal</p>
<div id="binomial-rvs" class="section level3 hasAnchor" number="2.8.1">
<h3><span class="header-section-number">2.8.1</span> Binomial RVs<a href="probability.html#binomial-rvs" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="definition">
<p><span id="def:unlabeled-div-73" class="definition"><strong>Definition 2.19  </strong></span>A <strong><em>binomial(n,p) random variable</em></strong> is a discrete random variable that counts the numbers of “successes” over a fixed number of trials, <span class="math inline">\(n\)</span>, with each trial having an equal probability of success, <span class="math inline">\(p\)</span>.</p>
<p><span class="math inline">\(P(X=k) = \binom{n}{k} p^k(1-p)^{n-k} = \frac{n!}{k!\ \cdot\ (n-k)!} p^k(1-p)^{n-k}\)</span>, where <span class="math inline">\(0 \leq k \leq n, 0 \leq p \leq 1\)</span></p>
<p>If <span class="math inline">\(X \sim Binomial(n,p)\)</span>, then <span class="math inline">\(E[X]=np\)</span> and <span class="math inline">\(Var(X)=np(1-p)\)</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-74" class="example"><strong>Example 2.15  </strong></span>The Cubs and Rockies are playing a 4-game series. The Rockies have a 0.65 probability of winning each game, and the Cubs have a 0.35 probability. Assume each game is independent. Solve for the following quantities.</p>
</div>
<ol style="list-style-type: lower-alpha">
<li><p>The Cubs wins exactly 1 game.<br />
<br />
<br />
<br />
</p></li>
<li><p>The Rockies win exactly 2 games.<br />
<br />
<br />
<br />
</p></li>
<li><p>The Cubs win at least 2 games.<br />
<br />
<br />
<br />
</p></li>
<li><p>The series ends in a sweep.<br />
<br />
<br />
<br />
</p></li>
<li><p>The expected number of wins for the Rockies.<br />
<br />
<br />
<br />
</p></li>
<li><p>The variance and standard deviations of wins for the Rockies.<br />
<br />
<br />
<br />
</p></li>
</ol>
<div class="example">
<p><span id="exm:unlabeled-div-75" class="example"><strong>Example 2.16  </strong></span>Complete 10,000 simulations of the four game series between the Rockies and Cubs. For the number of Rockies wins, calculate the sample mean and sample variance and compare these to the population values. Also, plot a histogram of the sample data.</p>
</div>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="probability.html#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2020</span>)</span>
<span id="cb86-2"><a href="probability.html#cb86-2" aria-hidden="true" tabindex="-1"></a>rockies_wins <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="at">n =</span> <span class="dv">10000</span>, <span class="at">size =</span> <span class="dv">4</span>, <span class="at">prob =</span> <span class="fl">0.65</span>)</span>
<span id="cb86-3"><a href="probability.html#cb86-3" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(rockies_wins)</span></code></pre></div>
<pre><code>## [1] 2.6123</code></pre>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="probability.html#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="fu">var</span>(rockies_wins)</span></code></pre></div>
<pre><code>## [1] 0.9110798</code></pre>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="probability.html#cb90-1" aria-hidden="true" tabindex="-1"></a>rockies_wins_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Wins =</span> rockies_wins)</span>
<span id="cb90-2"><a href="probability.html#cb90-2" aria-hidden="true" tabindex="-1"></a>rockies_wins_df <span class="sc">%&gt;%</span></span>
<span id="cb90-3"><a href="probability.html#cb90-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="fu">aes</span>(Wins)) <span class="sc">+</span> <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">fill =</span> <span class="st">&quot;purple&quot;</span>)</span></code></pre></div>
<p><img src="series_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<div id="binomial-coefficient-symmetry" class="section level4 hasAnchor" number="2.8.1.1">
<h4><span class="header-section-number">2.8.1.1</span> Binomial Coefficient Symmetry<a href="probability.html#binomial-coefficient-symmetry" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Playoff series for a certain sports league are played as a best-of-seven series, with one team hosting four games and the opposing team hosing three. An executive for the league wishes to know the number of ways the home and away games can be assigned. (One such combination is A-A-B-B-A-B-A, the format used by the NBA and NHL for their best-of-seven series.) What is the total number of combinations?<br />
<br />
<br />
<br />
</p>
<p>However, instead of thinking about the number of ways to assign the games to the team that gets four home games, what if we thought about the number of ways to assign games to the team that gets three home games?</p>
<p>That would be <span class="math inline">\(\binom{7}{3}\)</span>. We can use the <code>choose</code> command in R to find this quantity.</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="probability.html#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="fu">choose</span>(<span class="dv">7</span>, <span class="dv">3</span>)</span></code></pre></div>
<pre><code>## [1] 35</code></pre>
<p>It turns out that this binomial coefficient is also equal to 35.</p>
<p>Theorem: <span class="math inline">\(\binom{n}{k} = \binom{n}{n-k}\)</span></p>
<p><span class="math inline">\(\binom{n}{k} = \frac{n!}{k!\ \cdot\ (n-k)!}\)</span></p>
<p><span class="math inline">\(\binom{n}{n-k} = \frac{n!}{(n-k)!\ \cdot\ (n-(n-k))!} = \frac{n!}{(n-k)!\ \cdot\ k!} = \binom{n}{k}\)</span></p>
</div>
</div>
<div id="geometric-rvs" class="section level3 hasAnchor" number="2.8.2">
<h3><span class="header-section-number">2.8.2</span> Geometric RVs<a href="probability.html#geometric-rvs" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="definition">
<p><span id="def:unlabeled-div-76" class="definition"><strong>Definition 2.20  </strong></span>A <strong><em>Geometric(p) random variable</em></strong> is a discrete random variable that counts the numbers of trials until a “success” occurs, where the probability of success, <span class="math inline">\(p\)</span>, is constant across all trials.</p>
<p><span class="math inline">\(P(X=k) = p(1-p)^{k-1}\)</span>, where <span class="math inline">\(k \geq 1, 0 \leq p \leq 1\)</span></p>
<p>If <span class="math inline">\(X \sim Geometric(p)\)</span>, then <span class="math inline">\(E[X]=\frac{1}{p}\)</span> and <span class="math inline">\(Var(X)=\frac{p}{1-p}\)</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-77" class="example"><strong>Example 2.17  </strong></span>Suppose the number of shots needed by a hockey team in order to score their first goal, X, is modeled by a Geometric(<span class="math inline">\(\frac{1}{10}\)</span>) random variable. Use this information to answer the following questions.</p>
</div>
<ol style="list-style-type: lower-alpha">
<li><p>What is the probability that it takes exactly 3 shots to score the first goal?<br />
<br />
<br />
<br />
</p></li>
<li><p>What is the probability that it takes less than 3 shots to score the first goal?<br />
<br />
<br />
<br />
</p></li>
<li><p>What is the probability that it takes more than 3 shots to score the first goal?<br />
<br />
<br />
<br />
</p></li>
</ol>
<p><strong>Caution:</strong> Some references parameterize the Geometric distribution based on the number of failures before the first success, rather than the trial on which the first success occurs. This changes the PMF, mean, and variance, so be careful.</p>
<p>Let’s simulate the number of shot attempts required to score the first goal (Geometric(<span class="math inline">\(p=1/10\)</span>)) from the previous example.</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="probability.html#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2020</span>)</span>
<span id="cb93-2"><a href="probability.html#cb93-2" aria-hidden="true" tabindex="-1"></a>geometric <span class="ot">&lt;-</span> <span class="fu">rgeom</span>(<span class="dv">1000</span>, <span class="dv">1</span><span class="sc">/</span><span class="dv">10</span>)</span>
<span id="cb93-3"><a href="probability.html#cb93-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(geometric, <span class="dv">20</span>)</span></code></pre></div>
<pre><code>##  [1]  2  2  7 55  6 11  2 11  2  5  0 50 17  2  7  0  7 19 17  1</code></pre>
<p>Some of the values were 0, which could not happen if R was considering the number of the trial on which the first success occurred. You can add 1 to the values given by <code>R</code> to arrive at the first success distribution.</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="probability.html#cb95-1" aria-hidden="true" tabindex="-1"></a>first_success <span class="ot">&lt;-</span> geometric <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb95-2"><a href="probability.html#cb95-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(first_success, <span class="dv">20</span>)</span></code></pre></div>
<pre><code>##  [1]  3  3  8 56  7 12  3 12  3  6  1 51 18  3  8  1  8 20 18  2</code></pre>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb97-1"><a href="probability.html#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(first_success)</span></code></pre></div>
<pre><code>## [1] 10.827</code></pre>
<p>The mean of this sample of variables is 10.827, which is close to the expected mean of <span class="math inline">\(\frac{1}{p} = 10\)</span>.</p>
<p>Let’s plot the sample distribution of shots required to score a goal from the simulation as well.</p>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb99-1"><a href="probability.html#cb99-1" aria-hidden="true" tabindex="-1"></a>first_success_df <span class="ot">=</span> <span class="fu">data.frame</span>(<span class="at">Shots =</span> first_success)</span>
<span id="cb99-2"><a href="probability.html#cb99-2" aria-hidden="true" tabindex="-1"></a>first_success_df <span class="sc">%&gt;%</span></span>
<span id="cb99-3"><a href="probability.html#cb99-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Shots)) <span class="sc">+</span> <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="series_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
</div>
<div id="poisson-rvs" class="section level3 hasAnchor" number="2.8.3">
<h3><span class="header-section-number">2.8.3</span> Poisson RVs<a href="probability.html#poisson-rvs" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="definition">
<p><span id="def:unlabeled-div-78" class="definition"><strong>Definition 2.21  </strong></span>A <strong><em>Poisson(<span class="math inline">\(\lambda\)</span>) random variable</em></strong> is a discrete random variable that counts the numbers of “successes” for a given rate parameter, <span class="math inline">\(\lambda\)</span>, for a given interval.</p>
<p><span class="math inline">\(P(X=k) = \frac{e^{-\lambda}\lambda^k}{k!}\)</span>, where <span class="math inline">\(k \geq 1,\)</span></p>
<p>If <span class="math inline">\(X \sim Poisson(\lambda)\)</span>, then <span class="math inline">\(E[X]=\lambda\)</span> and <span class="math inline">\(Var(X)=\lambda\)</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-79" class="example"><strong>Example 2.18  </strong></span>During the 2021 Major League Soccer season, the Colorado Rapids scored 51 goals in 34 games on their way to a first-place finish in the Western Conference regular season standings.</p>
<p>The team scored <span class="math inline">\(\frac{51}{34} = 1.5\)</span> goals per game. Let’s model the distribution of Rapids goals using a Poisson(1.5) random variable that we’ll call Y.</p>
</div>
<ol style="list-style-type: lower-alpha">
<li>Which is more likely: Y taking on the value 0 or Y taking on the value 2?<br />
<br />
<br />
<br />
</li>
</ol>
<p>We can plot the PMF of Y to check visually.</p>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="probability.html#cb100-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">transform</span>(<span class="fu">data.frame</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">8</span>)), <span class="at">y =</span> <span class="fu">dpois</span>(x, <span class="at">lambda =</span> <span class="fl">1.5</span>)), <span class="fu">aes</span>(x, y)) <span class="sc">+</span></span>
<span id="cb100-2"><a href="probability.html#cb100-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">&quot;identity&quot;</span>) <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Value&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Frequency&quot;</span>, <span class="at">title =</span> <span class="st">&quot;Probability mass function of Poisson(1.5) random variable&quot;</span>)</span></code></pre></div>
<p><img src="series_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<p>We can calculate these probabilities in R as well using the <code>dpois</code> command.</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="probability.html#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dpois</span>(<span class="at">x =</span> <span class="dv">0</span>, <span class="at">lambda =</span> <span class="fl">1.5</span>)</span></code></pre></div>
<pre><code>## [1] 0.2231302</code></pre>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb103-1"><a href="probability.html#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dpois</span>(<span class="at">x =</span> <span class="dv">2</span>, <span class="at">lambda =</span> <span class="fl">1.5</span>)</span></code></pre></div>
<pre><code>## [1] 0.2510214</code></pre>
<p>Let’s check whether using a Poisson distribution was appropriate by comparing it to the actual 2021 Colorado Rapids match results.</p>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb105-1"><a href="probability.html#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Data: https://www.espn.com/soccer/team/results/_/id/184/season/2021</span></span>
<span id="cb105-2"><a href="probability.html#cb105-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-3"><a href="probability.html#cb105-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;kableExtra&quot;</span>)</span>
<span id="cb105-4"><a href="probability.html#cb105-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-5"><a href="probability.html#cb105-5" aria-hidden="true" tabindex="-1"></a>goals <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">4</span>, <span class="st">&quot;5 or more&quot;</span>)</span>
<span id="cb105-6"><a href="probability.html#cb105-6" aria-hidden="true" tabindex="-1"></a>actual_frequency <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">6</span>, <span class="dv">14</span>, <span class="dv">7</span>, <span class="dv">6</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb105-7"><a href="probability.html#cb105-7" aria-hidden="true" tabindex="-1"></a>actual_proportion <span class="ot">&lt;-</span> actual_frequency<span class="sc">/</span><span class="fu">sum</span>(actual_frequency)</span>
<span id="cb105-8"><a href="probability.html#cb105-8" aria-hidden="true" tabindex="-1"></a>expected_proportion <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">dpois</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">4</span>, <span class="at">lambda =</span> <span class="fl">1.5</span>), <span class="fu">ppois</span>(<span class="dv">4</span>, <span class="at">lambda =</span> <span class="fl">1.5</span>, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>))</span>
<span id="cb105-9"><a href="probability.html#cb105-9" aria-hidden="true" tabindex="-1"></a>expected_frequency <span class="ot">&lt;-</span> <span class="fu">round</span>(expected_proportion <span class="sc">*</span> <span class="dv">34</span>, <span class="dv">1</span>)</span>
<span id="cb105-10"><a href="probability.html#cb105-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-11"><a href="probability.html#cb105-11" aria-hidden="true" tabindex="-1"></a>rapids.data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(goals, actual_frequency, actual_proportion, expected_frequency,</span>
<span id="cb105-12"><a href="probability.html#cb105-12" aria-hidden="true" tabindex="-1"></a>    expected_proportion)</span>
<span id="cb105-13"><a href="probability.html#cb105-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-14"><a href="probability.html#cb105-14" aria-hidden="true" tabindex="-1"></a>rapids.data <span class="sc">%&gt;%</span></span>
<span id="cb105-15"><a href="probability.html#cb105-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">kbl</span>() <span class="sc">%&gt;%</span></span>
<span id="cb105-16"><a href="probability.html#cb105-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">kable_styling</span>()</span></code></pre></div>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
goals
</th>
<th style="text-align:right;">
actual_frequency
</th>
<th style="text-align:right;">
actual_proportion
</th>
<th style="text-align:right;">
expected_frequency
</th>
<th style="text-align:right;">
expected_proportion
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
0
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
0.1764706
</td>
<td style="text-align:right;">
7.6
</td>
<td style="text-align:right;">
0.2231302
</td>
</tr>
<tr>
<td style="text-align:left;">
1
</td>
<td style="text-align:right;">
14
</td>
<td style="text-align:right;">
0.4117647
</td>
<td style="text-align:right;">
11.4
</td>
<td style="text-align:right;">
0.3346952
</td>
</tr>
<tr>
<td style="text-align:left;">
2
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
0.2058824
</td>
<td style="text-align:right;">
8.5
</td>
<td style="text-align:right;">
0.2510214
</td>
</tr>
<tr>
<td style="text-align:left;">
3
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
0.1764706
</td>
<td style="text-align:right;">
4.3
</td>
<td style="text-align:right;">
0.1255107
</td>
</tr>
<tr>
<td style="text-align:left;">
4
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.0000000
</td>
<td style="text-align:right;">
1.6
</td>
<td style="text-align:right;">
0.0470665
</td>
</tr>
<tr>
<td style="text-align:left;">
5 or more
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.0294118
</td>
<td style="text-align:right;">
0.6
</td>
<td style="text-align:right;">
0.0185759
</td>
</tr>
</tbody>
</table>
<ol start="2" style="list-style-type: lower-alpha">
<li>What differences do you notice between the actual results and the expected values based on the Poisson random variable?<br />
<br />
<br />
<br />
</li>
</ol>
<!-- There were fewer games in which the Rapids scored 4 or more goals than the model would indicate, yet the Rapids were shut out less often than the model would indicate. -->
<ol start="3" style="list-style-type: lower-alpha">
<li>Even if the true population distribution of 2021 Rapids goals was truly a Poisson(1.5) random variable, why might the actual distribution of their goals differ from the probability mass function?<br />
<br />
<br />
<br />
</li>
</ol>
<!-- 34 is a relatively small sample size; random variables may not coincide with their expected values for finite sample sizes. -->
<ol start="4" style="list-style-type: lower-alpha">
<li>What are the advantages of using the Poisson distribution to model Major League soccer goals? What are the disadvantages?<br />
<br />
<br />
<br />
</li>
</ol>
<!-- Poisson random variables can take on the natural numbers (including zero), which aligns with the number of goals that can be scored in a match. One disadvantage is that it is possible for a Poisson to take on values that are not realistic for the situation, such as double-digit integers or higher. Only one game in MLS history has had a team score more than seven goals in a game. However, when $\lambda$ is small (such as 1.5), these extreme values are relatively unlikely. -->
</div>
<div id="normal-rvs" class="section level3 hasAnchor" number="2.8.4">
<h3><span class="header-section-number">2.8.4</span> Normal RVs<a href="probability.html#normal-rvs" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="definition">
<p><span id="def:unlabeled-div-80" class="definition"><strong>Definition 2.22  </strong></span>A <strong><em>Normal(<span class="math inline">\(\mu\)</span>,<span class="math inline">\(\sigma^2\)</span>) random variable</em></strong> is a continuous random variable that is bell-shaped with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>.</p>
<p>To calculate probabilities under the normal curve, you need either to integrate, use a table, or a computer.</p>
<p>Note that a normal random variable can be standardized by using: <span class="math inline">\(z = \frac{x-\mu}{\sigma}\)</span></p>
</div>
<div class="theorem">
<p><span id="thm:unlabeled-div-81" class="theorem"><strong>Theorem 2.8  </strong></span>For a normal(<span class="math inline">\(\mu\)</span>,<span class="math inline">\(\sigma^2\)</span>) random variable, we have the following approximations:<br />
- About 68% of the data falls within one standard deviation of the mean (i.e., <span class="math inline">\(\mu \pm \sigma\)</span>)<br />
- About 95% of the data falls within two standard deviations of the mean (i.e., <span class="math inline">\(\mu \pm 2\sigma\)</span>)<br />
- About 99.7% of the data falls within three standard deviations of the mean (i.e., <span class="math inline">\(\mu \pm 3\sigma\)</span>)</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-82" class="example"><strong>Example 2.19  </strong></span>The skills (or tools) of a baseball player are often rated on a scale of 20-80, where 50 is an average grade, 20 is the lowest grade, and 80 is the highest grade. The distribution of tool grades is approximately normally distributed (<span class="math inline">\(\mu=50, \sigma =10\)</span>).</p>
<p>See <a href="https://blogs.fangraphs.com/scouting-explained-the-20-80-scouting-scale/">https://blogs.fangraphs.com/scouting-explained-the-20-80-scouting-scale/</a> for more details. Calculate the following probabilities.</p>
</div>
<ol style="list-style-type: lower-alpha">
<li><p>Former Rockie Nolan Arenado has been graded to have game power of 70. Game power estimates a player’s ability to hit home runs. Approximately what percentage of baseball players have equal or greater game power than Arenado?<br />
<br />
<br />
<br />
</p></li>
<li><p>Mike Trout has been graded to have raw power of 55. Raw power estimates a player’s ability to hit baseballs hard (i.e., hard hit rate). Approximately what percentage of baseball players have equal or less raw power than Arenado?<br />
<br />
<br />
<br />
</p></li>
<li><p>Suppose a Rockies prospect is said to be in the top 10% of all baseball players in terms of their speed. What approximate speed grade would correspond to the player?<br />
<br />
<br />
<br />
</p></li>
<li><p>Suppose a Rockies prospect is said to be in the bottom 20% of all baseball players in terms of their hit ability. What approximate hit grade would correspond to the player?<br />
<br />
<br />
<br />
</p></li>
<li><p>Between what two grades do approximately 95% of all players lie for a given tool?<br />
<br />
<br />
<br />
</p></li>
</ol>
<p>Let’s check our answers:</p>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="probability.html#cb106-1" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> <span class="fu">pnorm</span>(<span class="at">q =</span> <span class="dv">70</span>, <span class="at">mean =</span> <span class="dv">50</span>, <span class="at">sd =</span> <span class="dv">10</span>)</span>
<span id="cb106-2"><a href="probability.html#cb106-2" aria-hidden="true" tabindex="-1"></a>a</span></code></pre></div>
<pre><code>## [1] 0.02275013</code></pre>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="probability.html#cb108-1" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="fu">pnorm</span>(<span class="at">q =</span> <span class="dv">55</span>, <span class="at">mean =</span> <span class="dv">50</span>, <span class="at">sd =</span> <span class="dv">10</span>)</span>
<span id="cb108-2"><a href="probability.html#cb108-2" aria-hidden="true" tabindex="-1"></a>b</span></code></pre></div>
<pre><code>## [1] 0.6914625</code></pre>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="probability.html#cb110-1" aria-hidden="true" tabindex="-1"></a>c <span class="ot">&lt;-</span> <span class="fu">qnorm</span>(<span class="fl">0.1</span>, <span class="at">mean =</span> <span class="dv">50</span>, <span class="at">sd =</span> <span class="dv">10</span>, <span class="at">lower.tail =</span> F)</span>
<span id="cb110-2"><a href="probability.html#cb110-2" aria-hidden="true" tabindex="-1"></a>c</span></code></pre></div>
<pre><code>## [1] 62.81552</code></pre>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="probability.html#cb112-1" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">qnorm</span>(<span class="fl">0.2</span>, <span class="at">mean =</span> <span class="dv">50</span>, <span class="at">sd =</span> <span class="dv">10</span>, <span class="at">lower.tail =</span> T)</span>
<span id="cb112-2"><a href="probability.html#cb112-2" aria-hidden="true" tabindex="-1"></a>d</span></code></pre></div>
<pre><code>## [1] 41.58379</code></pre>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="probability.html#cb114-1" aria-hidden="true" tabindex="-1"></a>e <span class="ot">&lt;-</span> <span class="fu">pnorm</span>(<span class="at">q =</span> <span class="dv">70</span>, <span class="at">mean =</span> <span class="dv">50</span>, <span class="at">sd =</span> <span class="dv">10</span>) <span class="sc">-</span> <span class="fu">pnorm</span>(<span class="at">q =</span> <span class="dv">30</span>, <span class="at">mean =</span> <span class="dv">50</span>, <span class="at">sd =</span> <span class="dv">10</span>)</span>
<span id="cb114-2"><a href="probability.html#cb114-2" aria-hidden="true" tabindex="-1"></a>e</span></code></pre></div>
<pre><code>## [1] 0.9544997</code></pre>
<hr />
</div>
</div>
<div id="extra-stuff" class="section level2 hasAnchor" number="2.9">
<h2><span class="header-section-number">2.9</span> Extra Stuff<a href="probability.html#extra-stuff" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="sets-and-conditional-probability" class="section level3 hasAnchor" number="2.9.1">
<h3><span class="header-section-number">2.9.1</span> Sets and Conditional Probability<a href="probability.html#sets-and-conditional-probability" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>100 sports fans in Colorado were polled and it was found that 64 had attended either a Denver Nuggets or Colorado Avalanche game at Ball Arena (formerly Pepsi Center). 34 people had seen only a Nuggets game, while 17 had seen both a Nuggets and an Avalanche game.</p>
<p>Q: How many people saw an Avalanche game but not a Nuggets game?</p>
<p>A: 64 - 34 - 17 = 13</p>
<p>Q: What is the probability that a randomly selected person in the poll had been to a Nuggets game?</p>
<p>A: (34 + 17) / 100 = .51</p>
<p>Q: What is the probability that a randomly selected person that had been to a game at Ball Arena had been to a Nuggets game?</p>
<p>A: (34 + 17) / 64 = .797</p>
<p>Q: What is the probability that a randomly selected person had been to a Nuggets game given they had been to an Avalanche game?</p>
<p>A: 17 / (17 + 13) = .567</p>
</div>
<div id="binomials-and-multinomials" class="section level3 hasAnchor" number="2.9.2">
<h3><span class="header-section-number">2.9.2</span> Binomials and Multinomials<a href="probability.html#binomials-and-multinomials" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suppose we are curious about probabilities regarding the results of a soccer team’s next five games.</p>
<p>Wait!!! A soccer game has three possible outcomes (win, lose, draw)! We can’t use the binomial distribution, since it limits us to two possible outcomes!</p>
<p>It depends. If we are interested in the probability that a soccer team wins 2 of their next 5 games, we can use the binomial distribution. We can create the following partition of the sample space of outcomes: <span class="math inline">\((Win)\)</span> and <span class="math inline">\((Win^C)\)</span>, where the second set includes both losing and drawing.</p>
<p>Then, the formula would be represented as:</p>
<p><span class="math inline">\(\binom{5}{2}\ P(Win)^2\  P(Win^C)^{(5-2)}\)</span></p>
<p>If we are interested in the probability of the team winning two of the next five games, drawing two, and losing one, we cannot use the binomial theorem. That involves three outcomes, and would be represented as a multinomial. <!--- assuming regularity conditions such as independence. --></p>
</div>
<div id="expectation---baseball" class="section level3 hasAnchor" number="2.9.3">
<h3><span class="header-section-number">2.9.3</span> Expectation - Baseball<a href="probability.html#expectation---baseball" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The expectation of a discrete random variable is a weighted average. The “weights” are the probabilities of the possible values of the variable.</p>
<p>Consider the following table, which shows the number of career hits by type for the all-time Major League Baseball leader in total bases, Hank Aaron.</p>
<!-- https://www.baseball-reference.com/players/a/aaronha01.shtml -->
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Hit_type
</th>
<th style="text-align:right;">
Number_bases
</th>
<th style="text-align:right;">
Hit_Frequency
</th>
<th style="text-align:right;">
Hit_Proportion
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Single
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
2294
</td>
<td style="text-align:right;">
0.6083267
</td>
</tr>
<tr>
<td style="text-align:left;">
Double
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
624
</td>
<td style="text-align:right;">
0.1654734
</td>
</tr>
<tr>
<td style="text-align:left;">
Triple
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
98
</td>
<td style="text-align:right;">
0.0259878
</td>
</tr>
<tr>
<td style="text-align:left;">
Home Run
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
755
</td>
<td style="text-align:right;">
0.2002122
</td>
</tr>
</tbody>
</table>
<p>The expected number of bases for a Hank Aaron hit is the sum of the number of bases attained for each hit multiplied by the relative frequency of the occurrence of that type of hit.</p>
<p><span class="math inline">\(1 \cdot \frac{2294}{3771} + 2 \cdot \frac{624}{3771} + 3 \cdot \frac{98}{3771} + 4 \cdot \frac{755}{3771} = 1.18181\)</span></p>
<p>This is the same process that is occurring whenever we calculate the expectation of any discrete random variable. Recall the formula for expectation is <span class="math inline">\(E[X] = \sum_{x \in \Omega}\ x \cdot p(x)\)</span>. Each value in the sample space is “adjusted” by the probability of that value, then the sum of all values in <span class="math inline">\(\Omega\)</span> is taken to arrive at the weighted average, or expected value, of the random variable.</p>
</div>
<div id="basketball-scenario" class="section level3 hasAnchor" number="2.9.4">
<h3><span class="header-section-number">2.9.4</span> Basketball Scenario<a href="probability.html#basketball-scenario" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>You are the coach of a basketball team that is down two points with one second remaining in the fourth quarter. During a timeout, you are considering the best play to call for your team. The first option is a three-point shot attempt, which you estimate has a 30% chance of succeeding. The second option is a two-point shot attempt, which has a 50% chance of making the field goal, a 30% chance of missing it and ending the game, and a 20% chance the shooter will miss but be fouled, in which case the shooter’s free throw success will follow a <span class="math inline">\(Bin(2, .8)\)</span> random variable. Finally, you estimate that your team’s probability of winning the game in overtime is .45.</p>
<p>Assume the above situations are exhaustive (i.e., the other team will not get another possession, no fouls will be called before the ball is put in play, lightning will not hit the arena and postpone the game, etc.). Which of the two plays should you call to maximize the win probability for your team?</p>
<p>A: The probability of winning the game with the three-point shot attempt is .3. If the two-point shot attempt is called for, there is a .5 probability of making the field goal and a (.2)(.8)(.8) = .128 probability that the foul is called and both free throws are made. Thus, the total probability of scoring two points and sending the game to overtime is .628. Then, the probability of winning the game in OT after tying it in regulation is (.628)(.45) = .2828. This is less than .3, so shooting the three-pointer is the option that maximizes the win probability, given these situational probabilities.</p>
<p>Q: What is the minimum estimated overtime win probability to make calling for the two-point play the better option?</p>
<p>A: <span class="math inline">\(P(score\ 2\ points\ in\ regulation) \cdot P(win\ in\ OT) &gt; P(win\ in\ regulation)\)</span><br />
<span class="math inline">\(.628 \cdot P(win\ in\ OT) &gt; .3\)</span><br />
<span class="math inline">\(P(win\ in\ OT) &gt; .478\)</span></p>
</div>
<div id="multiple-probability-distributions---basketball" class="section level3 hasAnchor" number="2.9.5">
<h3><span class="header-section-number">2.9.5</span> Multiple Probability Distributions - Basketball<a href="probability.html#multiple-probability-distributions---basketball" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suppose the number of points scored by a basketball player follows a Poisson(12) random variable, the number of rebounds by a Poisson(7) distribution, and assists by a Discrete Uniform(2, 11), independently of each other.</p>
<p>Q: What is the probability that this player records a points, rebounds, assists triple-double in a game?</p>
<p>A: <span class="math inline">\(P(Triple\ Double) = P(Points \geq 10\ \cap\ Rebounds \geq 10\ \cap\ Assists \geq 10)\)</span></p>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="probability.html#cb116-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ppois</span>(<span class="dv">9</span>, <span class="at">lambda =</span> <span class="dv">12</span>, <span class="at">lower.tail =</span> F)</span></code></pre></div>
<pre><code>## [1] 0.7576078</code></pre>
<p><span class="math inline">\(P(Points \geq 10) = P(Poisson(12) \geq 10) \approx .758\)</span></p>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb118-1"><a href="probability.html#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ppois</span>(<span class="dv">9</span>, <span class="at">lambda =</span> <span class="dv">7</span>, <span class="at">lower.tail =</span> F)</span></code></pre></div>
<pre><code>## [1] 0.1695041</code></pre>
<p><span class="math inline">\(P(Rebounds \geq 10) = P(Poisson(7) \geq 10) \approx .170\)</span></p>
<p><span class="math inline">\(P(Assists \geq 10) = P(Discrete\ Uniform(2, 11) \geq 10) = .2\)</span></p>
<p>Since the events are independent, we can multiply their probabilities. The probability of the player scoring the triple-double is <span class="math inline">\((.758)(.170)(.2) = .0257\)</span>.</p>
<p>Q: Your friend offers you 4 to 1 that the player will not record a triple-double in their next 10 games. With the knowledge that the athlete’s performance in a game is unaffected by performances in previous games, would you take the bet?</p>
<p>A: <span class="math inline">\(P(no\ triple\ double) = 1 - .0257 = .9743\)</span>, so <span class="math inline">\(P(no\ triple\ double\ in\ next\ 10\ games) = (.9743)^{10} = .771\)</span></p>
<p>The odds of no triple-double are <span class="math inline">\(\frac{.771}{1-.771} = 3.37\)</span>, so the bet of no triple-double at 4 to 1 odds is favorable.</p>
<p><em>answers may vary for following questions</em></p>
<p>Q: What differences do you notice between the actual results and the expected values based on the Poisson random variable?</p>
<p>A: There were fewer games in which the Rapids scored 4 or more goals than the model would indicate, yet the Rapids were shut out less often than the model would indicate.</p>
<p>Q: Even if the true population distribution of 2021 Rapids goals was truly a Poisson(1.5) random variable, why might the actual distribution of their goals differ from the probability mass function?</p>
<p>A: 34 is a relatively small sample size; random variables may not coincide with their expected values for finite sample sizes.</p>
<p>Q: What are the advantages of using the Poisson distribution to model Major League soccer goals? What are the disadvantages?</p>
<p>A: Poisson random variables can take on the natural numbers (including zero), which aligns with the number of goals that can be scored in a match. One disadvantage is that it is possible for a Poisson to take on values that are not realistic for the situation, such as double-digit integers or higher. Only one game in MLS history has had a team score more than seven goals in a game. However, when <span class="math inline">\(\lambda\)</span> is small (such as 1.5), these extreme values are relatively unlikely.</p>
</div>
<div id="law-of-total-probability---hockey" class="section level3 hasAnchor" number="2.9.6">
<h3><span class="header-section-number">2.9.6</span> Law of Total Probability - Hockey<a href="probability.html#law-of-total-probability---hockey" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Over the course of a season, a hockey player scored a goal 30% of the time during a home game, and <span class="math inline">\(P(player\ scores\ |\ away\ game) = .18\)</span>. Assume all games are either home or away.</p>
<p>Q: What is the probability the player scored a goal in any game if there were an equal number of home and away games?</p>
<p>A: <span class="math inline">\(P(score) = P(score|home)P(home) + P(score|away)P(away) = .3(.5) + .18(.5) = .24\)</span></p>
<p>Q: What is the probability the player scored a goal in any game if there were twice as many home games as away games?</p>
<p>A: <span class="math inline">\(P(score) = P(score|home)P(home) + P(score|away)P(away) = .3(\frac{2}{3}) + .18(\frac{1}{3}) = .26\)</span></p>
<p>Q: What is the probability the player scored a goal in any game if the ratio of home games to away games is 2:3?</p>
<p>A: <span class="math inline">\(P(score) = P(score|home)P(home) + P(score|away)P(away) = .3(\frac{2}{5}) + .18(\frac{3}{5}) = .228\)</span></p>
</div>
<div id="law-of-total-probability---baseball" class="section level3 hasAnchor" number="2.9.7">
<h3><span class="header-section-number">2.9.7</span> Law of Total Probability - Baseball<a href="probability.html#law-of-total-probability---baseball" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>You work in the front office of a professional baseball club and have just learned that a certain prospect hits .200 against left-handed pitchers and .400 against right-handed pitchers (their overall batting average is unknown). The general manager of the team overhears you talking about the .400 statistic of the player and becomes very exited that they have the chance to draft a .400 hitter. What would you say to caution the GM that the player might not be a remarkable hitter?</p>
<p>A: We don’t know the proportion of the player’s at-bats that came against left-handed pitchers versus right-handed pitchers. If we want to know the player’s batting average unconditional on the type of pitcher they are facing, we have to adjust <span class="math inline">\(P(hit\ |\ left-handed\ pitcher)\)</span> by <span class="math inline">\(P(left-handed\ pitcher)\)</span> and <span class="math inline">\(P(hit\ |\ right-handed\ pitcher)\)</span> by <span class="math inline">\(P(right-handed\ pitcher)\)</span> before adding them to determine <span class="math inline">\(P(hit)\)</span>. For example, if 90% of the player’s at-bats were against left-handed pitchers, then their overall batting average is a pedestrian .220.</p>
<p><em>Other possible issues: low sample size of player’s at-bats, the fact that pro pitchers will be harder to hit against than non-pros</em></p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="exploratory-data-analysis.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="monte-carlo-simulation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/aaron-nielsen/SportsAnalyticsBook/edit/master/02-probability.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["series.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
