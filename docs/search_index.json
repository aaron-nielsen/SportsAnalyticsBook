[["index.html", "Sports Analytics About", " Sports Analytics Aaron Nielsen, Department of Statistics, Colorado State University 2023-03-22 About This book serves as the course textbook for the following courses at Colorado State University: STAT 351 (Sports Statistics and Analytics I) STAT 451 (Sports Statistics and Analytics II) CSU students contributed to the creation of this book. Many thanks to the following student collaborators: Levi Kipp, Ellie Martinez, Isaac Moorman, Connor Gibbs "],["preliminaries.html", "Preliminaries Getting Started With R Which Sports? Challenges Ethical Concerns", " Preliminaries Getting Started With R Installing R For this class, you will be using R Studio to complete statistical analyses on your computer. To begin using R Studio, you will need to install “R” first and then install “R Studio” on your computer. Step 1: Download R (a) Visit https://www.r-project.org/ (b) Click CRAN under Download (c) Select any of the mirrors (d) Click the appropriate link for your type of system (Mac, Windows, Linux) (e) Download R on this next page. (For Windows, this will say install R for the first time. For Mac, this will be under Latest release and will be something like R-4.1.0.pkg – the numbers may differ depending on the most recent version) (f) Install R on your computer Step 2: Download R Studio (a) Visit https://www.rstudio.com/products/rstudio/download/#download (b) Click to download (c) Install R Studio on your computer Step 3: Verify R Studio is working (a) Open R Studio (b) Let’s enter a small dataset and calculate the average to make sure everything is working correctly. (c) In the console, type in the following dataset of Sammy Sosa’s season home run totals from 1998–2002: sosa.HR &lt;- c(66,63,50,64,49) In the console, calculate the average season home run total for Sammy Sosa between 1998–2002: mean(sosa.HR) ## [1] 58.4 (e) Did you find Slammin’ Sammy’s average home run total from 1998–2002 was 58.4? If so, you should be set up correctly! Some R Basics For the following examples, let’s consider Peyton Manning’s career with the Denver Broncos. In his four seasons with the Broncos, Manning’s passing yard totals were: 4659, 5477, 4727, 2249. Let’s enter this data into R. To enter a vector of data, use the c() function. peyton &lt;- c(4659, 5477, 4727, 2249) To look at the data you just put in the variable peyton, type peyton into the console and press enter. peyton ## [1] 4659 5477 4727 2249 Some basic function for calculating summary statistics include summary, mean(), median(), var(), and sd(). summary(peyton) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 2249 4056 4693 4278 4914 5477 mean(peyton) ## [1] 4278 sd(peyton) ## [1] 1402.522 R allows you to install additional packages (collections of functions) that aren’t offered in the base version of R. To install a package, use install.packages() and to load a package, use library(). One package that we will use frequently is tidyverse. This package includes several other packages and functions such as ggplot (plotting function), dplyr (data manipulation package), and stringr (string manipulation package). install.packages(&quot;tidyverse&quot;) library(&quot;tidyverse&quot;) You will also need to know how to load datasets from files. For this class, we will typically provide data files is .csv format. Here is how to load a file: # load readr package and load example dataset NFL_2021_Team_Passing &lt;- read_csv(&quot;data/NFL_2021_Team_Passing.csv&quot;) # we can look at the header (first few entries) using &quot;head()&quot; head(NFL_2021_Team_Passing) ## # A tibble: 6 × 25 ## Rk Tm G Cmp Att `Cmp%` Yds TD `TD%` Int `Int%` Lng ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 Tampa Bay… 17 492 731 67.3 5229 43 5.9 12 1.6 62 ## 2 2 Los Angel… 17 443 674 65.7 4800 38 5.6 15 2.2 72 ## 3 3 Dallas Co… 17 444 647 68.6 4800 40 6.2 11 1.7 73 ## 4 4 Kansas Ci… 17 448 675 66.4 4791 37 5.5 13 1.9 75 ## 5 5 Los Angel… 17 406 607 66.9 4642 41 6.8 18 3 79 ## 6 6 Las Vegas… 17 429 628 68.3 4567 23 3.7 14 2.2 61 ## # … with 13 more variables: `Y/A` &lt;dbl&gt;, `AY/A` &lt;dbl&gt;, `Y/C` &lt;dbl&gt;, ## # `Y/G` &lt;dbl&gt;, Rate &lt;dbl&gt;, Sk &lt;dbl&gt;, SKYds &lt;dbl&gt;, `Sk%` &lt;dbl&gt;, `NY/A` &lt;dbl&gt;, ## # `ANY/A` &lt;dbl&gt;, `4QC` &lt;dbl&gt;, GWD &lt;dbl&gt;, EXP &lt;dbl&gt; Which Sports? Which sports will we be analyzing in this class? Challenges What kind of challenges could we encounter dealing with sports data? Ethical Concerns What kinds of ethical concerns should we consider when dealing with sports data? "],["exploratory-data-analysis.html", "Chapter 1 Exploratory Data Analysis 1.1 Descriptive Statistics 1.2 Visualizations 1.3 Baseball 1.4 Football 1.5 Basketball 1.6 Hockey 1.7 Volleyball 1.8 Soccer", " Chapter 1 Exploratory Data Analysis 1.1 Descriptive Statistics 1.1.1 Definitions Definition 1.1 A population is a well-defined complete collection of objects. Definition 1.2 A sample is a subset of the population. Example 1.1 Suppose we are interested in studying Peyton’s Manning’s season passing yards totals. How could you define the population and what is one possible sample? Definition 1.3 Quantitative data is numeric data or numbers. It can be broken into two further categories: discrete and continuous data. Definition 1.4 Discrete data is quantitative data with a finite or countably infinite number of values. Definition 1.5 Continuous data is quantitative data with an uncountably infinite number of values or data taken from an interval. Example 1.2 What are possible discrete and continuous data associated with Peyton Manning? Definition 1.6 Qualitative data refers to names, categories, or descriptions. It can also be broken down into two further categories, nominal data and ordinal data. Definition 1.7 Nominal data is qualitative data with no natural ordering. Definition 1.8 Ordinal data is qualitative data with a natural ordering. Example 1.3 What are possible nominal and ordinal data associated with Peyton Manning? 1.1.2 Descriptive Statistics While we will learn about some descriptive statistics that are unique to specific sports, there are some descriptive statistics that are frequently used in many applications. 1.1.2.1 Quantitative Data There are different descriptive statistics depending on the type of data you are analyzing. We will begin by looking at descriptive statistics for quantitative data. To begin, let \\(x_1, x_2, \\ldots, x_n\\) represent a numerical dataset with a sample of size \\(n\\), where \\(x_i\\) is the \\(i^\\text{th}\\) value in the dataset. Definition 1.9 The sum of the data values is given by: \\(\\sum_{i=1}^n x_i = x_1 + x_2 + \\ldots + x_n\\) Definition 1.10 The sample mean (or sample average), \\(\\bar{x}\\), of the numerical dataset is given by \\(\\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i\\) Definition 1.11 The population mean (or population average), \\(\\mu\\), is the mean value for the entire population. The mean can be thought of as a measure of center or more generally, a measure of location. Example 1.4 Recall that Peyton Manning’s season passing yards total while with the Broncos were: 4659, 5477, 4727, 2249. Calculate the sample mean of these values. # Calculate the sample of Peyton Manning&#39;s passing yards season totals with Colts peyton.broncos &lt;- c(4659, 5477, 4727, 2249) mean(peyton.broncos) ## [1] 4278 In sports statistics, we often have to choose between using a descriptive statistic that summarizes a quantity versus a descriptive statistic that summarizes a rate. For instance, in basketball, we can compare two players based on how many points they score in a game (total quantity) or we can compare two players based on how many points per minute played (rate statistic). Many applications in sports analytics focus more on rate statistics rather than quantity statistics. Why? We can measure the spread or variability of a dataset using variance and standard devatiation. Definition 1.12 The sample variance, \\(s^2\\), of the numerical dataset is a measure of spread and is given by \\(s^2 = \\frac{1}{n-1}\\sum_{i=1}^n (x_i - \\bar{x})^2\\) Definition 1.13 The sample standard deviation, \\(s\\), of the numerical dataset is a measure of spread and is given by \\(s = \\sqrt{s^2} = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^n (x_i - \\bar{x})^2}\\) Definition 1.14 The population variance, \\(\\sigma^2\\), is the variance for an entire population and is given by \\(\\sigma^2 = \\frac{1}{N} \\sum_{i=1}^N (x_i - \\mu)^2\\), where \\(N\\) is the population size. Definition 1.15 The population standard deviation, \\(\\sigma\\), is the standard deviation for an entire population and is given by \\(\\sigma = \\sqrt{\\frac{1}{N} \\sum_{i=1}^N (x_i - \\mu)^2}\\) We often prefer to work with standard deviations as a measure of spread as opposed to variance because standard deviations are given in our original units. # Calculate the variance and standard deviation of Peyton Manning&#39;s passing # yards season totals with Broncos var(peyton.broncos) # units: yards^2 ## [1] 1967068 sd(peyton.broncos) # units: yards ## [1] 1402.522 Definition 1.16 The sample median, \\(\\tilde{x}\\), of a numerical dataset is the middle value when the data are ordered from smallest to largest. In other words, let \\(x_1, x_2, \\ldots, x_n\\) be the (unordered) dataset and let \\(x_{(1)},x_{(2)}, \\ldots, x_{(n)}\\) be the same dataset but ordered from smallest to largest. If \\(n\\) is odd, then \\(\\tilde{x} = x_{(n+1)/2}\\) and if \\(n\\) is even, then \\(\\tilde{x} = \\frac{1}{2} \\cdot \\left[x_{\\left(\\frac{n}{2}\\right)} + x_{\\left(\\frac{n+1}{2}\\right)}\\right]\\). Example 1.5 Calculate the sample median of Peyton Manning’s season passing yards total while with the Colts (3739, 4135, 4413, 4131, 4200, 4267, 4557, 3747, 4397, 4040, 4002, 4500, 4700). Like sample mean, sample median is a measure of center. It gives you an idea of where the ``middle” of your dataset is. We can calculate sample mean and sample median in R as follows: # Calculate the median of Peyton Manning&#39;s passing yards season totals with # Broncos and Colts peyton.colts &lt;- c(3739, 4135, 4413, 4131, 4200, 4267, 4557, 3747, 4397, 4040, 4002, 4500, 4700) median(peyton.broncos) ## [1] 4693 median(peyton.colts) ## [1] 4200 Definition 1.17 A percentile is a measure of relative standing. The \\(p^\\text{th}\\) percentile is the number where at least p% of the data values are less than or equal to this number. Definition 1.18 A quantile is a measure of relative standing and are the cut points for breaking a distribution of values into equal sized bins. Definition 1.19 A quartile is a measure of relative standing and are the cut points for breaking a distribution of values into four equal parts. # Calculate the 10th and 90th percentile of Peyton Manning&#39;s passing yards # season totals with Colts quantile(peyton.colts,0.10) ## 10% ## 3798 quantile(peyton.colts,0.90) ## 90% ## 4545.6 quantile(peyton.colts,c(0.1,0.9)) ## 10% 90% ## 3798.0 4545.6 Special percentiles: 1. 25th percentile = 1st quartile = \\(Q_1\\) 2. 50th percentile = 2nd quartile = \\(Q_2\\) = \\(\\tilde{x}\\) 3. 75th percentile = 3rd quartile = \\(Q_3\\) Definition 1.20 Range is a measure of spread, measures the full width of a dataset, and is given by: \\(Range = Max - Min\\). Definition 1.21 Interquartile range is a measure of spread, measures the width of the middle 50% of a dataset, and is given by: \\(IQR = Q_3 - Q_1\\). Definition 1.22 A five number summary describes the center, spread, and edges of a dataset and is given by: \\((Min,Q_1,Q_2,Q_3,max)\\). summary(peyton.colts) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 3739 4040 4200 4218 4413 4700 quantile(peyton.colts,c(0,0.25,0.5,0.75,1)) ## 0% 25% 50% 75% 100% ## 3739 4040 4200 4413 4700 1.1.2.2 Qualitative Data In sports statistics, we also encounter qualitative (categorical) data which is names or labels which has its own descriptive statistics. To begin, let \\(x_1, x_2, \\ldots, x_n\\) represent a categorical dataset with a sample of size \\(n\\), where \\(x_i\\) is the \\(i^\\text{th}\\) value in the dataset. Definition 1.23 The proportion of sampled data that fall into a category is given by: \\(p = \\frac{\\#\\text{ in category}}{\\#\\text{ total}}\\) ’’Proportion” and “Probability” are often used interchangeably. Both have a minimum value of 0 and a maximum value of 1. Definition 1.24 The percentage of sampled data that fall into a category is given by: \\(P\\% = 100 \\cdot p = 100 \\cdot \\frac{\\#\\text{ in category}}{\\#\\text{ total}}\\) Percentages in this context can have a minimum value of 0% and a maximum value of 100%. Example 1.6 In 2014, Peyton Manning started as quarterback for the Denver Broncos. The result of the Broncos’ 16-game season was: Win, Win, Loss, Win, Win, Win, Win, Loss, Win, Loss, Win, Win, Win, Win, Loss, Win Calculate the proportion and percentage of Broncos’ winning games in 2014. broncos2014 &lt;- c(&quot;Win&quot;, &quot;Win&quot;, &quot;Loss&quot;, &quot;Win&quot;, &quot;Win&quot;, &quot;Win&quot;, &quot;Win&quot;, &quot;Loss&quot;, &quot;Win&quot;, &quot;Loss&quot;, &quot;Win&quot;, &quot;Win&quot;, &quot;Win&quot;, &quot;Win&quot;, &quot;Loss&quot;, &quot;Win&quot;) broncos.prop &lt;- sum(broncos2014 == &quot;Win&quot;)/length(broncos2014); broncos.prop ## [1] 0.75 broncos.perc &lt;- 100*broncos.prop; broncos.perc ## [1] 75 We can also build a frequency table that summarizes the categories and their occurrences using table() in R. Note that table() works for quantitative and qualitative data. table(broncos2014) ## broncos2014 ## Loss Win ## 4 12 1.2 Visualizations Conveying information visually is also an important part in providing a description of a dataset. R provides some basic plotting functions such as plot, hist, and barplot. These plotting functions are simple and not always very clean looking. In this class, we will use analogous plotting functions in ggplot2 that are much improved plotting functions. If you have already installed the tidyverse package, it should have also installed the ggplot2 package. # Load the tidyverse package (which includes ggplot2) library(tidyverse) Let’s load the file ``NFL_2021_Team_Passing.csv” which contains NFL Team Passing Statistics, 2021 from https://www.pro-football-reference.com/years/2021/index.htm#passing library(readr) NFL_2021_Team_Passing &lt;- read_csv(&quot;data/NFL_2021_Team_Passing.csv&quot;) head(NFL_2021_Team_Passing) ## # A tibble: 6 × 25 ## Rk Tm G Cmp Att `Cmp%` Yds TD `TD%` Int `Int%` Lng ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 Tampa Bay… 17 492 731 67.3 5229 43 5.9 12 1.6 62 ## 2 2 Los Angel… 17 443 674 65.7 4800 38 5.6 15 2.2 72 ## 3 3 Dallas Co… 17 444 647 68.6 4800 40 6.2 11 1.7 73 ## 4 4 Kansas Ci… 17 448 675 66.4 4791 37 5.5 13 1.9 75 ## 5 5 Los Angel… 17 406 607 66.9 4642 41 6.8 18 3 79 ## 6 6 Las Vegas… 17 429 628 68.3 4567 23 3.7 14 2.2 61 ## # … with 13 more variables: `Y/A` &lt;dbl&gt;, `AY/A` &lt;dbl&gt;, `Y/C` &lt;dbl&gt;, ## # `Y/G` &lt;dbl&gt;, Rate &lt;dbl&gt;, Sk &lt;dbl&gt;, SKYds &lt;dbl&gt;, `Sk%` &lt;dbl&gt;, `NY/A` &lt;dbl&gt;, ## # `ANY/A` &lt;dbl&gt;, `4QC` &lt;dbl&gt;, GWD &lt;dbl&gt;, EXP &lt;dbl&gt; 1.2.1 Histograms Histograms are one of the most common and basic ways to visualize a dataset’s distribution of values. To make a histogram, you will use ggplot and geom_histogram. Example 1.7 Create a histogram of the NFL Team Passing Yards in 2021. NFL_2021_Team_Passing %&gt;% ggplot(aes(x=Yds)) + geom_histogram() Notice how %&gt;% is used to pipe the dataset into ggplot. This is using the pipe function from the dplyr package. By default, geom_histogram uses 30 bins but this is customizable. Let’s make the bins have a width of 200. All good visualizations have good labels. Let’s improve the axis labels and give the figure a title. NFL_2021_Team_Passing %&gt;% ggplot(aes(x=Yds)) + geom_histogram(binwidth = 200) + labs(x=&quot;Team Passing Yards&quot;, y=&quot;Team Passing Touchdowns&quot;, title=&quot;NFL Team Passing Yards, 2021&quot;) We also have numerous options to change the appearance of plots when using ggplot. Let’s change the bins color to blue and change the bin borders to white. NFL_2021_Team_Passing %&gt;% ggplot(aes(x=Yds)) + geom_histogram(color = &quot;white&quot;, fill = &quot;blue&quot;, binwidth = 200) + labs(x=&quot;Team Passing Yards&quot;, y=&quot;Team Passing Touchdowns&quot;, title=&quot;NFL Team Passing Yards, 2021&quot;) 1.2.2 Bar Plots We can also create bar plots using ggplot using the geom_bar function. Example 1.8 Create a bar plot with teams on the horizontal axis and passing touchdowns on the vertical axis. NFL_2021_Team_Passing %&gt;% ggplot(aes(x=Tm,y=Yds)) + geom_bar(stat=&quot;identity&quot;) The team labels are a complete mess. Let’s fix this and make some adjustments to the axis labels and figure title. NFL_2021_Team_Passing %&gt;% ggplot(aes(x=Tm,y=Yds)) + geom_bar(stat=&quot;identity&quot;) + labs(x=&quot;Team&quot;, y=&quot;Team Passing Yards&quot;, title=&quot;NFL Team Passing Yards, 2021&quot;) + theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1)) We can flip this graph if we like as well. Note that when we flip the graph, our labels get in reverse ordering, so this can be fixed using fct_rev() which is part of the forcats package. NFL_2021_Team_Passing %&gt;% ggplot(aes(x=fct_rev(Tm),y=Yds)) + geom_bar(stat=&quot;identity&quot;) + labs(x=&quot;Team Passing Yards&quot;,y=&quot;Team&quot;,title=&quot;NFL Team Passing Yards, 2021&quot;) + coord_flip() We can also order the teams from most team passing touchdowns to least using the forcats package. NFL_2021_Team_Passing %&gt;% mutate(Tm = fct_reorder(Tm,Yds)) %&gt;% ggplot(aes(x=Tm,y=Yds)) + geom_bar(stat=&quot;identity&quot;) + labs(x=&quot;Team Passing Yards&quot;, y=&quot;Team Passing Yards&quot;, title=&quot;NFL Team Passing Yards, 2021&quot;) + coord_flip() 1.2.3 Scatter Plots Another common and useful visualization is a scatterplot which shows the relationship between two numeric variable. In ggplot, you use geom_point(). Example 1.9 Create a scatterplot of Team Passing Yards and Team Passing Touchdowns from the NFL 2021 dataset. NFL_2021_Team_Passing %&gt;% ggplot(aes(x=Yds,y=TD,label=Tm)) + geom_point() + labs(x=&quot;Team Passing Yards&quot;, y=&quot;Team Passing Touchdowns&quot;, title=&quot;NFL Team Passing Yards, 2021&quot;) We may want to include team labels on this plot, however, it can get messy very quickly with a lot of points. NFL_2021_Team_Passing %&gt;% ggplot(aes(x=Yds,y=TD,label=Tm)) + geom_point() + labs(x=&quot;Team Passing Yards&quot;, y=&quot;Team Passing Touchdowns&quot;, title=&quot;NFL Team Passing Yards, 2021&quot;) + geom_text() Many sports leagues have around 30 teams, so a clean scatterplot with labels can be tricky to make. Here are some options below. # install ggrepel package library(ggrepel) NFL_2021_Team_Passing %&gt;% ggplot(aes(x=Yds,y=TD,label=Tm)) + geom_point() + labs(x=&quot;Team Passing Yards&quot;, y=&quot;Team Passing Touchdowns&quot;, title=&quot;NFL Team Passing Yards, 2021&quot;) + geom_text_repel() ## Warning: ggrepel: 6 unlabeled data points (too many overlaps). Consider ## increasing max.overlaps NFL_2021_Team_Passing$Abbr &lt;- c(&quot;TB&quot;,&quot;LAC&quot;,&quot;DAL&quot;,&quot;KC&quot;,&quot;LAR&quot;,&quot;LV&quot;,&quot;CIN&quot;,&quot;GB&quot;,&quot;BUF&quot;,&quot;AZ&quot;,&quot;MN&quot;,&quot;SF&quot;, &quot;BAL&quot;,&quot;NE&quot;,&quot;PIT&quot;,&quot;ATL&quot;,&quot;MIA&quot;,&quot;DET&quot;,&quot;DEN&quot;,&quot;NYJ&quot;,&quot;WAS&quot;,&quot;JAC&quot;,&quot;SEA&quot;, &quot;TEN&quot;,&quot;PHI&quot;,&quot;IND&quot;,&quot;CLE&quot;,&quot;HOU&quot;,&quot;CAR&quot;,&quot;CHI&quot;,&quot;NYG&quot;,&quot;NO&quot;) NFL_2021_Team_Passing %&gt;% ggplot(aes(x=Yds,y=TD,label=Abbr)) + geom_point() + scale_x_continuous(limits=c(2750,5250)) + labs(x=&quot;Team Passing Yards&quot;,y=&quot;Team Passing Touchdowns&quot;, title=&quot;NFL Team Passing Yards, 2021&quot;) + geom_text_repel(box.padding = 0.3) 1.2.4 Kable Tables We can build nice tables using kableR and kableExtra. Let’s look at a few options. # Use a smaller dataset as an example NFL21 &lt;- NFL_2021_Team_Passing %&gt;% select(2:8) %&gt;% slice_head(n = 5) # Default output for tabular data NFL21 ## # A tibble: 5 × 7 ## Tm G Cmp Att `Cmp%` Yds TD ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Tampa Bay Buccaneers 17 492 731 67.3 5229 43 ## 2 Los Angeles Chargers 17 443 674 65.7 4800 38 ## 3 Dallas Cowboys 17 444 647 68.6 4800 40 ## 4 Kansas City Chiefs 17 448 675 66.4 4791 37 ## 5 Los Angeles Rams 17 406 607 66.9 4642 41 You can find additional details on customizing kable tables at  https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_pdf.pdf # Output using Kable (with no additional options) library(kableExtra) # Output using Kable and Kable-Styling and some additional options NFL21 %&gt;% kable() %&gt;% kable_styling(latex_options=&quot;hold_position&quot;) Tm G Cmp Att Cmp% Yds TD Tampa Bay Buccaneers 17 492 731 67.3 5229 43 Los Angeles Chargers 17 443 674 65.7 4800 38 Dallas Cowboys 17 444 647 68.6 4800 40 Kansas City Chiefs 17 448 675 66.4 4791 37 Los Angeles Rams 17 406 607 66.9 4642 41 # More options NFL21 %&gt;% kable(booktabs=TRUE) %&gt;% kable_styling(latex_options=&quot;hold_position&quot;) Tm G Cmp Att Cmp% Yds TD Tampa Bay Buccaneers 17 492 731 67.3 5229 43 Los Angeles Chargers 17 443 674 65.7 4800 38 Dallas Cowboys 17 444 647 68.6 4800 40 Kansas City Chiefs 17 448 675 66.4 4791 37 Los Angeles Rams 17 406 607 66.9 4642 41 If you are going to use kable tables frequently in a document, you can write a short function to set your default options. After I ran the function below, the function kt will produce a kable table with my options set. # kable table global setup kt &lt;- function(data) { knitr::kable(data, digits=3,linesep=&#39;&#39;,booktabs=TRUE) %&gt;% kable_styling(bootstrap_options=&#39;striped&#39;, latex_options=&#39;HOLD_position&#39;, full_width = F, position = &quot;center&quot;) } NFL21 %&gt;% kt() Tm G Cmp Att Cmp% Yds TD Tampa Bay Buccaneers 17 492 731 67.3 5229 43 Los Angeles Chargers 17 443 674 65.7 4800 38 Dallas Cowboys 17 444 647 68.6 4800 40 Kansas City Chiefs 17 448 675 66.4 4791 37 Los Angeles Rams 17 406 607 66.9 4642 41 1.3 Baseball Baseball rules YouTube video: https://www.youtube.com/watch?v=skOsApsF0jQ&amp;t=63s 1.3.1 Hitting Statistics 1.3.1.1 Basic Hitting Statistics Plate Appearances (PA): number of completed batting appearances At-Bats (AB): Batting appearances, not including bases on balls, hit by pitch, sacrifices, interference, or obstruction Hits (H): Times reached base because of a batted, fair ball without error by the defense Singles (1B): Hits on which the batter reached first base safely without the contribution of a fielding error Doubles (2B): Hits on which the batter reached second base safely without the contribution of a fielding error Triples (3B): Hits on which the batter reached third base safely without the contribution of a fielding error Home Runs (HR): Hits on which the batter successfully touched all four bases, without the contribution of a fielding error Total Bases (TB): One for each single, two for each double, three for each triple, and four for each home run Hit by Pitch (HBP): Times touched by a pitch and awarded first base as a result Sacrifice Fly (SF): Number of fly ball outs which allow another runner to advance on the basepaths or score Base on Balls (BB or Walk): Times receiving four balls and advancing to first base Intentional Base on Balls (IBB or Intentional Walk): Times receiving four balls intentionally and advancing to first base Strikeout (K): Number of times that strike three is taken or swung at and missed, or bunted foul Runs (R): Times reached home base legally and safely Runs Batted In (RBI): Number of runners who scored due to a batters’s action, except when batter grounded into double play or reached on an error Batting Average (AVG or BA): Hits divided by at bats On Base Percentage/Average (OBP or OBA): Times reached base (H + BB + HBP) divided by at bats plus walks plus hit by pitch plus sacrifice flies (AB + BB + HBP + SF) Slugging Percentage/Average (SLG): Total bases divided by at-bats On-base Plus Slugging (OPS): On-base percentage plus slugging average 1.3.1.2 Advanced Baseball Hitting Statistics Isolated Power (ISO): Slugging percentage minus Batting average On-base Plus Slugging Plus (OPS+): OPS normalized for park effects with 100 being league average Weighted On-Base Average (wOBA): Hitting rate statistic that attempts to credit the hitter for the value of each outcome. The following formula can be updated each year based on the scoring environment. The following formula was updated for the 2021 season. \\[wOBA = \\frac{0.69 \\cdot (BB - IBB) + 0.719 \\cdot HBP + 0.87 \\cdot 1B + 1.217 \\cdot 2B + 1.529 \\cdot 3B + 1.94 \\cdot HR}{AB + BB - IBB + SF + HBP}\\] Expected Weighted On-Base Average (xwOBA): Hitting rate statistic that attempts to credit the hitter for the value of each expected outcome based on Statcast data. 1.3.2 Pitching Statistics 1.3.2.1 Basic Pitching Statistics Innings Pitched (IP): Number of outs recorded while pitching divided by three Strikeout (K): Number of batters who received strike three Base on Balls (BB or Walk): Times pitching four balls, allowing the batter-runner to advance to first base Hits Allowed (H): Total hits allowed Wins (W): Number of games where pitcher was pitching while his team took the lead and went on to win Losses (L): Number of games where pitcher was pitching while the opposing team took the lead, never lost the lead, and went on to win Earned Runs (ER): Number of runs that did not occur as a result of errors or passed balls Earned Run Average (ERA): Earned runs times innings in a game (usually nine) divided by innings pitched Walks and Hits Per Inning Pitched (WHIP): Walks plus hits allowed divided by innings pitched 1.3.2.2 Advanced Pitching Statistics Fielding Independent Pitching (FIP): Statistic that estimates a pitcher’s run prevention independent of the performance of the defense \\[FIP = \\frac{13 \\cdot HR + 3 \\cdot (BB + HBP) - 2 \\cdot K}{IP} + FIP_{constant}\\] The \\(FIP_{constant}\\) is generally around 3.10 and is put FIP on a scale similar to ERA. Expected Fielding Independent Pitching (xFIP): Statistic that estimates a pitcher’s expected run prevention independent of the performance of the defense \\[xFIP = \\frac{13 \\cdot (Fly Balls \\cdot LgHR/FB\\%)+3 \\cdot (BB + HBP) - 2 \\cdot K}{IP} + FIP_{constant}\\] 1.3.3 Wins Above Replacement Wins Above Replacement (WAR): Estimated number of wins that a player has outperformed a replacement player by with the same playing time. This is one of the most crucial statistics in Sabermetrics. More about WAR from Fangraphs: https://library.fangraphs.com/misc/war/ References: https://www.baseball-reference.com/bullpen/Baseball_statistics https://blogs.fangraphs.com/glossary/ https://library.fangraphs.com/fangraphs-library-glossary/ 1.3.4 Calculating Hitting Statistics Example 1.10 Using the Colorado Rockies 2021 individual hitting statistics, calculate the AVG, OBA, SLG, OPS, ISO, wOBA. # load data file and look at the header rox21 &lt;- read_csv(&quot;data/rockies_hitting2021.csv&quot;) rox21 %&gt;% slice_head(n=5) %&gt;% kt() Name PA AB R H 2B 3B HR RBI BB IBB SO HBP SF oWAR Elias Diaz 371 338 52 83 18 1 18 44 30 1 60 2 1 1.1 C.J. Cron 547 470 70 132 31 1 28 92 60 3 117 13 4 3.1 Brendan Rodgers 415 387 49 110 21 3 15 51 19 0 84 7 2 1.9 Trevor Story 595 526 88 132 34 5 24 75 53 2 139 11 5 3.4 Ryan McMahon* 596 528 80 134 32 1 23 86 59 2 147 4 5 1.7 # Create new variables using the mutate function rox21 &lt;- rox21 %&gt;% mutate(AVG = H/AB,3) %&gt;% mutate(OBA = (H + BB + HBP)/(AB + BB + HBP + SF)) %&gt;% mutate(SLG = ((H-`2B`-`3B`-HR) + 2*`2B` + 3*`3B` + 4*HR)/AB) %&gt;% mutate(OPS = SLG + OBA) %&gt;% mutate(wOBA = (0.692 * (BB - IBB) + 0.722 * HBP + 0.879 * (H-`2B`-`3B`-HR) + 1.242 * `2B` + 1.568 * `3B` + 2.007 * HR)/(AB + BB - IBB + SF + HBP)) %&gt;% mutate(ISO = SLG-AVG) rox21 %&gt;% slice_head(n=5) %&gt;% select(Name,PA,AVG,OBA,SLG,OPS,wOBA,ISO) %&gt;% kt() Name PA AVG OBA SLG OPS wOBA ISO Elias Diaz 371 0.246 0.310 0.464 0.774 0.330 0.219 C.J. Cron 547 0.281 0.375 0.530 0.905 0.383 0.249 Brendan Rodgers 415 0.284 0.328 0.470 0.798 0.341 0.186 Trevor Story 595 0.251 0.329 0.471 0.801 0.341 0.221 Ryan McMahon* 596 0.254 0.331 0.449 0.779 0.334 0.195 Example 1.11 oWAR is Baseball Reference’s offensive WAR statistic. Note that Baseball Reference and Fangraphs use different formulas when calculating WAR though their results are typically similar. For Rockies players with at least 100 at-bats in 2021, what hitting statistics are most and least correlated to oWAR? # Let&#39;s remove players with less than 100 ABs rox21_100 &lt;- rox21 %&gt;% filter(AB &gt;= 100) # GGally package has a nice pairs plotting function library(&quot;GGally&quot;) # Standard hitting statistics rox21_100 %&gt;% select(oWAR,H,`2B`,`3B`,HR,R,RBI) %&gt;% ggpairs() + theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Rate statistics rox21_100 %&gt;% select(oWAR,AVG,OBA,SLG,OPS,wOBA) %&gt;% ggpairs() 1.3.5 Evaluating Pitching Statistics Earned run average (ERA) has been traditionally used to evaluate a pitcher, however, it has some flaws. First of all, it is highly dependent on the fielders playing behind the pitcher. If a pitcher’s shortstop has poor range, he won’t convert as many groundballs into outs as a shortstop with good range. ERA is also a noisy measurement in that can be affected easily by random luck. To overcome some of the downsides of ERA, FIP and xFIP were developed to help reduce the variance (noise) of the measurement and to remove factors, like defense, that are not a function of the pitcher’s ability. Let’s look at the twenty starting pitchers that had the most innings pitched in MLB for the total of the 2020 and 2021 seasons. We want to examine the year-to-year correlation between ERA, FIP, and xFIP. pitchers2021 &lt;- read_csv(&quot;data/MLBpitchers20-21.csv&quot;) pitchers2021 %&gt;% slice_head(n=5) %&gt;% kt() Player ERA20 FIP20 xFIP20 ERA21 FIP21 xFIP21 Zack Wheeler 2.92 3.22 3.76 2.78 2.59 2.84 Adam Wainwright 3.15 4.11 4.23 3.05 3.66 3.87 Kyle Hendricks 2.88 3.55 3.78 0.77 4.89 4.61 German Marquez 3.75 3.28 3.83 4.40 3.86 3.64 Luis Castillo 3.21 2.65 2.82 3.98 3.75 3.63 Let’s look at the correlations between these variables, paying close attention to what variables are most correlated with ERA20, a pitcher’s ERA in 2020. pitchers2021 %&gt;% select(-Player) %&gt;% ggpairs(title=&quot;Correlation plot of pitching statistics, MLB 2020-2021&quot;) This is a small dataset that only contains twenty pitchers (samples), but you will notice that ERA20 is more highly correlated with FIP21 and xFIP21 than ERA21. In other words, FIP and xFIP are likely better predictors of ERA success in the future rather than ERA success in the past. 1.4 Football Link to YouTube video describing football rules 1.4.1 Basic Football Statistics Yards (Yd): Number of yards gained from the line of scrimmage (can be broken down into Offense: Rushing and Passing Yards, Defense: Rushing and Passing Yards Allowed, and Special Teams: Kick and Punt Return Yards) Touchdowns (TD): Number of times the offense carries or passes the ball successfully into the end zone of the opposing side (can be broken down into: Offensive TDs: Rushing and Passing TDs, Defensive TDs: interception or fumble recovery for a touchdown, and Special Teams TDs: kick or punt return touchdowns) Sacks (Sk): Number of times a player or a team tackles the quarterback behind the line of scrimmage before he can throw a pass Interceptions (INT): Number of times a player or a team catches an opponent’s pass 1.4.2 Advanced Football Statistics Passer Rating (or Passing Efficiency): Measure of performance of a quarterback For NFL, the formula is as follows: \\[Passer Rating_{NFL} = \\left(\\frac{a+b+c+d}{6}\\right) \\cdot 100\\] where: \\[a = \\left(\\frac{COMP}{ATT}-0.3\\right) \\cdot 5\\] \\[b = \\left(\\frac{YDS}{ATT} - 3\\right) \\cdot 0.25\\] \\[c = \\left(\\frac{TD}{ATT}\\right) \\cdot 20\\] \\[d = 2.375 - \\left(\\frac{INT}{ATT} \\cdot 25\\right)\\] ATT = Number of passing attempts, COMP = Number of completions, YDS = Passing yards, TD = Touchdown passes, INT = Interceptions Note: If the result of any calculation is greater than 2.375, it is set to 2.375. If the result is a negative number, it is set to zero. For College Football, the formula is as follows: \\[Passer Rating_{NCAAF} = \\frac{(8.4 \\cdot YDS) + (330 \\cdot TD) + (100 \\cdot COMP) - (200 \\cdot INT)}{ATT}\\] Total Quarterback Rating (QBR): Proprietary measure of performance of a quarterback developed by ESPN in 2011. This is a more comprehensive measurement of quarterback performance that accounts for the quarterback’s impact on his team’s passes, rushes, turnovers, and penalties in terms of expected points added. Expected Points Added (EPA): Measure of how many points a player or a play is worth to a team. References: https://www.pro-football-reference.com/about/glossary.htm https://en.wikipedia.org/wiki/Passer_rating Example 1.12 Individual NFL quarterback passing statistics for the 2021 season are provided in NFL_Ind_Passing_2021.csv. Note that this dataset only includes quarterbacks with at least 100 passing yards in 2021. Passer efficiency is given in the RTG column. # Data: https://www.espn.com/nfl/stats/player QB_21 &lt;- read_csv(&quot;data/NFL_Ind_Passing_2021.csv&quot;) QB_21 %&gt;% select(1,3:8,11:12,15:16) %&gt;% slice_head(n=10) %&gt;% kt() Name GP CMP ATT CMP% YDS AVG TD INT QBR RTG Tom Brady 17 485 719 67.5 5316 7.4 43 12 68.1 102.1 Justin Herbert 17 443 672 65.9 5014 7.5 38 15 65.6 97.7 Patrick Mahomes 17 436 658 66.3 4839 7.4 37 13 62.2 98.5 Josh Allen 17 409 646 63.3 4407 6.8 36 15 60.7 92.2 Derek Carr 17 428 626 68.4 4804 7.7 23 14 52.4 94.0 Ben Roethlisberger 16 390 605 64.5 3740 6.2 22 10 35.6 86.8 Trevor Lawrence 17 359 602 59.6 3641 6.0 12 17 33.5 71.9 Matthew Stafford 17 404 601 67.2 4886 8.1 41 17 63.8 102.9 Dak Prescott 16 410 596 68.8 4449 7.5 37 10 54.6 104.2 Kirk Cousins 16 372 561 66.3 4221 7.5 33 7 52.3 103.1 names(QB_21) ## [1] &quot;Name&quot; &quot;Team&quot; &quot;GP&quot; &quot;CMP&quot; &quot;ATT&quot; &quot;CMP%&quot; &quot;YDS&quot; &quot;AVG&quot; &quot;YDS/G&quot; ## [10] &quot;LNG&quot; &quot;TD&quot; &quot;INT&quot; &quot;SACK&quot; &quot;SYL&quot; &quot;QBR&quot; &quot;RTG&quot; Confirm this is passer rating by creating a new variable to calculate passer rating using the provided statistics. # Create intermediate variables QB_21 &lt;- QB_21 %&gt;% mutate(a = (CMP/ATT-0.3)*5) %&gt;% mutate(b = (YDS/ATT-3)*0.25) %&gt;% mutate(c = (TD/ATT)*20) %&gt;% mutate(d = 2.375 -(INT/ATT*25)) # Check to see if a,b,c,d are less than 0 or greater than 2.375 QB_21 %&gt;% summarize(min(a),max(a),min(b),max(b),min(c),max(c),min(d),max(d)) ## # A tibble: 1 × 8 ## `min(a)` `max(a)` `min(b)` `max(b)` `min(c)` `max(c)` `min(d)` `max(d)` ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1.19 2.02 0.433 1.47 0.319 1.74 0.860 2.19 QB_21 &lt;- QB_21 %&gt;% mutate(PR = (a+b+c+d)/6*100) QB_21 %&gt;% select(Name,RTG,PR) %&gt;% slice_head(n=5) %&gt;% kt() Name RTG PR Tom Brady 102.1 102.083 Justin Herbert 97.7 97.656 Patrick Mahomes 98.5 98.455 Josh Allen 92.2 92.170 Derek Carr 94.0 93.963 What counting statistics are most correlated with passer rating and with QBR? # Grab the counting statistics and create a correlation plot with PR and QBR QB_21 %&gt;% select(PR,QBR,CMP,ATT,YDS,TD,INT,SACK,SYL) %&gt;% ggpairs() What rate statistics are most correlated with passer efficiency and with QBR? Use CMP% (completion percentage, completions per attempt), AVG (average yards per attempt), YDS/G (yards per game), and create new variables for interceptions per attempt, touchdowns per attempt, and sacks per attempt. # Grab the counting statistics and create a correlation plot with PR and QBR QB_21 &lt;- QB_21 %&gt;% mutate(INTp = INT/ATT) %&gt;% mutate(TDp = TD/ATT) %&gt;% mutate(SACKp = SACK/ATT) QB_21 %&gt;% select(PR,QBR,`CMP%`,AVG,`YDS/G`,INTp,TDp,SACKp) %&gt;% ggpairs() 1.5 Basketball Link to YouTube video describing basketball rules 1.5.1 Basic Basketball Statistics Field Goal (FG): A made shot from either 2- or 3-point range. Free throws, worth 1 point, are not considered field goals. Field goal statistics often include attempts, makes, and percentage. Free Throw (FT): After certain fouls, the clock stops and a player shoots an uncontested shot from the foul line. These free throws are worth 1 point each; like with field goals, FT statistics often include attempts, makes, and percentage. Assists (AST): A player is credited with an assist if they pass the ball to a teammate and the teammate scores a field goal after zero or one dribbles. No more than one assist can be recorded per field goal. Turnover (TO): A player or team can be charged with a turnover for an action or violation that ends their offensive possession before being able to attempt a field goal. For a player (especially a guard), TOs can be compared to assists using Assist:Turnover ratio. Rebound (REB): The first player to gain control of the ball following a missed field goal is credited with a rebound. If the player is on the same team as the field goal shooter, it is an offensive rebound; otherwise, a defensive rebound. Points per Possession (PPP): Divides a team’s points by number of possessions to account for a team’s pace. 1.5.2 Advanced Basketball Statistics True Shooting Percentage (TS%): Unlike traditional shooting percentage, this statistic considers both field goals and free throws. It also gives more weight to shots that are worth more points. Win Shares: Win shares give each player points for actions that contribute to a team’s success. Win shares take into account a variety of offensive and defensive statistics, but can be calculated using different methods on different platforms. Value Over Replacement Player (VORP): This is basketball’s response to baseball’s WAR. VORP is a rate statistic that estimates a player’s offensive output as compared to an “average” player. Player Efficiency Rating (PER): According to its creator John Hollinger, “The PER sums up all a player’s positive accomplishments, subtracts the negative accomplishments, and returns a per-minute rating of a player’s performance.” This statistic rewards great offensive performance more than great defensive plays. References: https://www.basketball-reference.com/about/per.html https://www.basketball-reference.com/about/ws.html https://www.basketball-reference.com/about/glossary.html 1.5.3 Four Factors Tibbles are a type of data frame supported by the tidyverse package. The following tibble contains data from a Mountain West tournament game played between the CSU and Wyoming women’s basketball teams during the 2021-2022 season, which CSU won 51-38. (Here’s the link to the box score on the CSU athletics website.) basketball_data &lt;- tibble(team = c(&quot;CSU&quot;,&quot;WYO&quot;), FG = c(14,15), FGA = c(48,60), THREEP = c(5,4), FT = c(10,4), FTA = c(14,4), ORB = c(2,14), DRB = c(31,30), TOV = c(5,12)) basketball_data %&gt;% kt() team FG FGA THREEP FT FTA ORB DRB TOV CSU 14 48 5 10 14 2 31 5 WYO 15 60 4 4 4 14 30 12 This tibble contains all the data needed to calculate the Four Factors. The Four Factors of a basketball game are statistics formulated by Dean Oliver, former Director of Quantitative Analysis for the Denver Nuggets (among other roles). These statistics are also promoted by sports data platforms like Hudl.com. The Four Factors each have offensive and defensive versions; for this example, we’ll focus on the offensive perspective. Scoring: Effective Field Goal Percentage (eFG%) \\(eFG\\% = \\frac{FG\\ +\\ 0.5(3P)}{FGA}\\) Crashing: Turnover Percentage (TOV%) \\(TOV\\% = \\frac{TOV}{FGA\\ +\\ 0.44(FTA)\\ +\\ TOV}\\) Protecting: Rebounding Percentage (ORB%) \\(ORB\\% = \\frac{ORB}{ORB\\ +\\ Opponent\\ DRB}\\) Attacking: Free Throw Factor (FT Factor) \\(FT\\ factor = \\frac{FT}{FGA}\\) Let’s calculate the values of eFG%, TOV%, ORB%, and Free Throw Factor for both CSU and Wyoming and add them as new columns in the tibble using the add_column function. basketball_data &lt;- basketball_data %&gt;% mutate(eFG = 100*(FG + .5 * THREEP)/FGA) %&gt;% mutate(TOVPCT = 100*(FG + .5 * THREEP)/FGA) %&gt;% mutate(ORBPCT = 100*c(ORB[1]/(ORB[1]+DRB[2]), ORB[2]/(ORB[2]+DRB[1]))) %&gt;% mutate(FTFACTOR = 100*FT/FGA) basketball_data %&gt;% select(team,eFG, TOVPCT, ORBPCT, FTFACTOR) %&gt;% kt() team eFG TOVPCT ORBPCT FTFACTOR CSU 34.375 34.375 6.250 20.833 WYO 28.333 28.333 31.111 6.667 While this method does produce Four Factors data, it could be difficult to scale for calculating the same statistics for a sample of several games. In the next section, we will introduce an R package that aids in the calculation of Four Factors. 1.5.3.1 BasketballAnalyzeR Four Factors The authors of “Basketball Data Science With Applications in R” developed the BasketballAnalyzeR package to be used in conjunction with the book. BasketballAnalyzeR includes built-in datasets from the 2017-18 NBA season and provides many functions for analyzing and plotting basketball data. One such function is fourfactors, which offers a simpler way to perform a four factors analysis. library(&quot;BasketballAnalyzeR&quot;) teams &lt;- c(&quot;DEN&quot;, &quot;CLE&quot;, &quot;GSW&quot;) #Nuggets, Cavaliers, Warriors team_data &lt;- which(Tadd$team %in% teams) four_factors_teams &lt;- fourfactors(Tbox[team_data, ], Obox[team_data, ]) four_factors_teams %&gt;% select(1,8:15) %&gt;% kt() Team F1.Off F2.Off F3.Off F4.Off F1.Def F2.Def F3.Def F4.Def Cleveland Cavaliers 54.70 13.70 20.06 21.41 53.98 13.43 77.27 16.58 Denver Nuggets 53.62 14.90 25.66 19.77 53.88 13.83 77.45 17.35 Golden State Warriors 56.91 15.26 21.05 19.48 50.44 13.89 76.31 18.55 This is a much simpler and neater way to calculate Four Factors. In the 2017-18 season, the Warriors and Cavaliers met in the NBA Finals, while the Nuggets just missed the playoffs. It would be expected that the two Finals teams would have higher values for the Four Factors. While this is mostly true, for which of the Four Factors did the Nuggets have the highest value? A: Factor 3 (rebounding percentage), both offensive and defensive. 1.5.4 Shot Charts The BasketballAnalyzeR package includes shot location data for all players for the 2017-18 NBA season and has a function called shotchart that allows for the plotting of shot data. Let’s plot shot location data for Nikola Jokic. First, the coordinates must be transformed so that the point (0,0) is located at the corner of the court; the original coordinates place the origin at the center of the hoop. PbP &lt;- PbPmanipulation(PbP.BDB) jokic_data &lt;- subset(PbP, player == &quot;Nikola Jokic&quot;) jokic_data$xx &lt;- jokic_data$original_x/10 #transformation jokic_data$yy &lt;- jokic_data$original_y/10 - 41.75 #transformation BasketballAnalyzeR supports three types of density visualizations within shotchart, one being density-polygons. Since shotchart is a ggplot object, a chart title can be added using ggtitle. shotchart(data = jokic_data, x=&quot;xx&quot;, y=&quot;yy&quot;, type=&quot;density-polygons&quot;) + ggtitle(&quot;Nikola Jokic Shot Data, 2017-18&quot;) ## Warning: The dot-dot notation (`..level..`) was deprecated in ggplot2 3.4.0. ## ℹ Please use `after_stat(level)` instead. ## ℹ The deprecated feature was likely used in the BasketballAnalyzeR package. ## Please report the issue to the authors. It seems most shots attempts from Jokic were in the paint; this is hardly surprising, since he plays the center position. Here’s the same chart with density-hexbin: shotchart(data = jokic_data, x=&quot;xx&quot;, y=&quot;yy&quot;, type=&quot;density-hexbin&quot;) + ggtitle(&quot;Nikola Jokic Shot Data, 2017-18&quot;) The same chart with density-raster: shotchart(data = jokic_data, x=&quot;xx&quot;, y=&quot;yy&quot;, type=&quot;density-raster&quot;) + ggtitle(&quot;Nikola Jokic Shot Data, 2017-18&quot;) Within the shotchart function, setting scatter=TRUE overlays the shots on the chart. Point size and transparency can also be customized. shotchart(data = jokic_data, x=&quot;xx&quot;, y=&quot;yy&quot;, type=&quot;density-raster&quot;, scatter=TRUE) + ggtitle(&quot;Nikola Jokic Shot Data, 2017-18&quot;) Let’s now compare shot charts of Nikola Jokic, Steph Curry, and Lebron James. This group of players includes one member of each team for which we calculated Four Factors. curry_data &lt;- subset(PbP, player == &quot;Stephen Curry&quot;) curry_data$xx &lt;- curry_data$original_x/10 #transformation curry_data$yy &lt;- curry_data$original_y/10 - 41.75 #transformation james_data &lt;- subset(PbP, player == &quot;LeBron James&quot;) james_data$xx &lt;- james_data$original_x/10 #transformation james_data$yy &lt;- james_data$original_y/10 - 41.75 #transformation shotchart(data = jokic_data, x=&quot;xx&quot;, y=&quot;yy&quot;, type=&quot;density-raster&quot;) + ggtitle(&quot;Nikola Jokic Shot Data, 2017-18&quot;) shotchart(data = curry_data, x=&quot;xx&quot;, y=&quot;yy&quot;, type=&quot;density-raster&quot;) + ggtitle(&quot;Steph Curry Shot Data, 2017-18&quot;) shotchart(data = james_data, x=&quot;xx&quot;, y=&quot;yy&quot;, type=&quot;density-raster&quot;) + ggtitle(&quot;Lebron James Shot Data, 2017-18&quot;) Q: Of the three players (Jokic, Curry, James), which took the highest percentage of their three-point shots from the right side of the court (when facing the basket)? A: Nikola Jokic shot almost all of his attempts from the right side. Steph Curry took many shots from beyond the arc and tended toward the left side, while James was split between the right side and the center. Now, let’s focus on Steph Curry’s shooting. The following chart splits the court into zones based on angle and distance from the basket. The color in each zone represents the average length of the play leading up to that shot among shots taken in that zone. shotchart(data = curry_data, x=&quot;xx&quot;, y=&quot;yy&quot;, z=&quot;playlength&quot;, type=&quot;sectors&quot;, num.sect = 7, scatter=TRUE, pt.alpha=.3) + ggtitle(&quot;Steph Curry Shot Data, 2017-18&quot;) Q: In general, did Steph Curry tend to shoot closer to the basket during plays of a longer duration or a shorter duration? A: There is not a perfect correlation, but it seems that two-point field goals were attempted more often during longer plays, while shots taken outside the three-point arc were taken during plays of a shorter duration. References: https://rdrr.io/cran/BasketballAnalyzeR/ Basketball Data Science (Zuccolotto and Manisera, 2020) 1.6 Hockey Link to YouTube video describing hockey rules 1.6.1 Basic Hockey Statistics Here are some basic statistics that are used often to describe hockey games. Goals (G): If a team scores, the skater on the scoring team who last touched the puck is credited with a goal. Assists (A): The players (up to two) on the scoring team who last touch the puck before the goalscorer are credited with assists, unless the opposing team has possession of the puck in between. Points (PTS): Goals plus assists. [Not to be confused with team points awarded in the regular season standings by the many hockey leagues, including the NHL (two points for a win, one point for an overtime/shootout loss, zero points for a regulation loss)]. Shots On Goal (SOG): Shot attempts in which the puck has been shot directly on goal. Shot attempts which are blocked or miss the goal are not considered SOGs. A team’s shots on goal should equal the opposing goaltender’s saves plus the team’s goals scored. Goals Against Average (GAA): Of a goaltender, the number of goals allowed by that goaltender adjusted to a per-60 minute rate. Penalty Minutes (PIM): The amount of penalty time an individual player is assigned for their infractions. PIM may be different than the amount of time the player actually spends in the penalty box. Reference: https://www.milehighhockey.com/pages/stats 1.6.2 Advanced Hockey Statistics CORSI: CORSI only applies to 5 on 5 (“even-strength”) situations. It is calculated as the difference between shot attempts on offense (shots on goal + blocked shots + missed shots) minus shot attempts allowed on defense. CORSI can also be expressed as a percentage, with percentages over 50% indicating that the player is on ice for more offensive shots than defensive shots. Expected Goals (xG): Expected Goals statistics give each shot an estimated probability of scoring a goal based on factors such as shot location and game situation. xG cannot be less than 0 or greater than 1 for any particular shot, and different platforms may have different methods of calculating expected goals. Fenwick/Unblocked Shot Attempts (USAT): Similar to CORSI, but omits blocked shots from the calculation. This statistic is used in many Expected Goals calculations. Because the flow of a hockey game is usually quite different in situations other than the normal 5 on 5, such as a power play (5 on 4) or concurrent penalties (4 on 4), many hockey databases separate data by the type of game situation. We will see this below with a dataset from MoneyPuck, but it is also present on Natural Stat Trick, QuantHockey, and hockey-reference. References: https://www.nhl.com/lightning/news/hockey-analytics-101-understanding-advanced-stats-and-how-theyre-measured/c-735819 https://theathletic.com/121980/2017/10/09/an-advanced-stat-primer-understanding-basic-hockey-metrics/ 1.6.3 Actual vs. Expected Goals Example 1.13 For this example, we’ll use a set of NHL data from moneypuck.com. First, let’s load the data into R and open the data frame. url &lt;- &quot;https://moneypuck.com/moneypuck/playerData/seasonSummary/2021/regular/teams.csv&quot; nhl_2022_data &lt;- read_csv(url) nhl_2022_data %&gt;% slice_head(n=10) %&gt;% select(3,6,8,9,10) %&gt;% kt() name situation xGoalsPercentage corsiPercentage fenwickPercentage WPG other 0.49 0.50 0.47 WPG all 0.49 0.50 0.50 WPG 5on5 0.49 0.49 0.50 WPG 4on5 0.16 0.14 0.15 WPG 5on4 0.86 0.86 0.85 CBJ other 0.52 0.49 0.49 CBJ all 0.45 0.48 0.47 CBJ 5on5 0.45 0.48 0.47 CBJ 4on5 0.14 0.18 0.21 CBJ 5on4 0.81 0.84 0.82 We can create nice looking tables using the ``kableExtra’’ package. Let’s look at the first eight rows and a small selection of columns of the data frame and format the table output using a kable table. library(&quot;kableExtra&quot;) nhl_2022_data[1:8, c(3,6:9)] %&gt;% kt() name situation games_played xGoalsPercentage corsiPercentage WPG other 82 0.49 0.50 WPG all 82 0.49 0.50 WPG 5on5 82 0.49 0.49 WPG 4on5 82 0.16 0.14 WPG 5on4 82 0.86 0.86 CBJ other 82 0.52 0.49 CBJ all 82 0.45 0.48 CBJ 5on5 82 0.45 0.48 This dataset includes a lot of covariates. It also splits these data by different game situations: even-strength (5 on 5), power play (5 on 4), etc. Let’s subset the data to include all game situations. Use the nrow command to check the number of columns in the new data frame. Check: Is it the same as the number of teams in the league for the 2021-2022 season? nhl_data_all &lt;- filter(nhl_2022_data, situation == &quot;all&quot;) nrow(nhl_data_all) ## [1] 32 The dataset includes an Expected Goals statistic for each team in the xGoalsFor column. Let’s plot this quantity against the team’s actual number of goals scored; this is given by the goalsFor column. (Remember to always have a good title and axis labels!) ggplot(data=nhl_data_all, aes(x=xGoalsFor, y=goalsFor)) + geom_point() + ggtitle(&quot;NHL Teams: Expected vs. Actual Goals, 2021-22&quot;) + xlab(&quot;Expected Goals Scored&quot;) + ylab(&quot;Actual Goals Scored&quot;) As expected, there is a general positive correlation between expected and actual goals (\\(r \\approx 0.8\\)). However, there is some variability - for example, the Kings only scored 7 more actual goals than the Ducks, despite having 56.6 more expected goals. Let’s add a line to the graph using the geom_abline function corresponding to the line \\(y=x\\), the line on which data points would fall if expected goals were equal to actual goals. We can also customize the line’s color and type. ggplot(data=nhl_data_all, aes(x=xGoalsFor, y=goalsFor)) + geom_point() + geom_abline(intercept=0, slope=1, color=&quot;red&quot;, linetype=&quot;dashed&quot;) + ggtitle(&quot;NHL Teams: Expected vs. Actual Goals, 2021-22&quot;) + xlab(&quot;Expected Goals Scored&quot;) + ylab(&quot;Actual Goals Scored&quot;) Note: A slope of 0 and an intercept of 1 are actually the default parameters for the function. What does it mean for a team’s data point to fall below this line? Above it? Do you think that a team’s expected goals would be more likely to be closer to its actual goals for a ten-game stretch, an entire season, or five consecutive seasons? Why? 1.6.4 Goalie Statistics Example 1.14 For this next example, let’s use goalie data from the 2021-2022 season from Natural Stat Trick. goalie_data &lt;- read.csv(&quot;data/GoalieTotals_NaturalStatTrick.csv&quot;) goalie_data %&gt;% select(2,3,4,5,6,7,8,12) %&gt;% arrange(-TOI) %&gt;% slice_head(n=10) %&gt;% kt() Player Team GP TOI Shots.Against Saves Goals.Against xG.Against Juuse Saros NSH 67 3931.383 2107 1934 173 180.69 Connor Hellebuyck WPG 66 3903.500 2155 1962 193 199.26 Andrei Vasilevskiy T.B 63 3760.750 1869 1713 156 165.89 Thatcher Demko VAN 64 3699.550 1967 1799 168 173.26 Jacob Markstrom CGY 63 3695.833 1754 1617 137 152.26 Tristan Jarry PIT 58 3414.717 1711 1573 138 143.92 Elvis Merzlikins CBJ 59 3320.400 1922 1744 178 164.94 Marc-Andre Fleury CHI, MIN 56 3284.867 1732 1573 159 148.00 Darcy Kuemper COL 57 3258.117 1755 1617 138 154.23 John Gibson ANA 56 3235.583 1789 1617 172 163.53 The dataset includes 119 goalies, but many of them didn’t play very much. We can subset the data to include only goaltenders that faced at least 500 shots. Which player among qualified goalies had the best goals against average? On which team did he play, and what was his GAA? Which goalie had the most playing time? What was his team, and how much time did he spend on the ice? filtered_goalie_data &lt;- filter(goalie_data, Shots.Against &gt;= 500) filtered_goalie_data %&gt;% filter(GAA == min(GAA)) %&gt;% select(Player, Team, GAA) %&gt;% kt() Player Team GAA Igor Shesterkin NYR 2.07 filtered_goalie_data %&gt;% filter(TOI == max(TOI)) %&gt;% select(Player, Team, TOI) %&gt;% kt() Player Team TOI Juuse Saros NSH 3931.383 The following plot compares save percentage to the number of shots on goal faced for the qualified goalies. The dashed horizontal line is placed at the average shots on goal faced among qualified players, and the dashed vertical line is placed at the average save percentage among qualified players. Which quadrant of the graph represents goalies that faced a higher than average number of shots, but had a below-average save percentage? Which quadrant represents goalies that had a high save percentage and faced a high volume of shots? 1.6.5 Correlation Plots When analyzing sports data, there may be many circumstances where statisticians consider which of several variables are most highly correlated to an outcome variable of interest. In this case, it can be useful to use a correlation plot (also known as a correlation matrix or correlogram). Tidyverse and related packages provide many options for creating correlation plots. Suppose a statistician has recently learned about some advanced hockey statistics and is interested in researching which stat has the highest correlation with goals scored. The statistician wants to compare team shots on goal, CORSI, and Fenwick to observe the association with goals scored for NHL teams. Example 1.15 The following plot uses the same 2021-2022 data from Moneypuck.com; it gives the pairwise scatterplots and correlation values for each of the variables, as well as smoothed plots of each individual variable along the diagonals. goal_stats &lt;- nhl_data_all %&gt;% select(shotsOnGoalFor, corsiPercentage, fenwickPercentage, goalsFor) ggpairs(goal_stats, title=&quot;Correlation plot of goals and relevant predictors, NHL 2021-22&quot;) Which of the variables has the strongest correlation with goals scored? In the article “An advanced stat primer: Understanding basic hockey metrics”, Charlie O’Connor states, “Generally speaking, Corsi is more predictive of future goal differential than Fenwick… however, Fenwick forms the basis for the most widely-used Expected Goals models.” Let’s use the same predictors in a correlation plot with Expected Goals percentage. Does Fenwick have the strongest correlation with xGoal percentage? xGoal_stats &lt;- nhl_data_all %&gt;% select(shotsOnGoalFor, corsiPercentage, fenwickPercentage, xGoalsPercentage) ggpairs(xGoal_stats, title=&quot;Correlation plot of expected goals and relevant predictors, NHL 2021-22&quot;) 1.7 Volleyball Volleyball rules Youtube video: https://www.youtube.com/watch?v=9g7nYQv-kPM 1.7.1 Basic Volleyball Statistics A Service Ace (SA) occurs when a player’s serve touches the ground on the other team’s side without being touched by a player on that side. A Kill (K) occurs when a player gets the ball over the net without it being returned by the opponent. An Assist (AST) is a pass made directly before a player makes a kill. Hitting Percentage (PCT) is the number of attempted kills (minus errors) divided by the total number of kill attempts. This helps determine how well a player or team is succeeding at their kill attempts. A Dig is a pass of a hard-driven ball from the other team. Reference: www.rookieroad.com For Volleyball EDA, we will be using CSU Women’s Volleyball data from the last five seasons. # Load CSU Women&#39;s Volleyball Data csu_vb &lt;- read_csv(&quot;data/csu_volleyball.csv&quot;) colnames(csu_vb)[3] &lt;- &quot;W_L&quot; csu_vb %&gt;% slice_head(n=10) %&gt;% select(1:13) %&gt;% kt() Date Opponent W_L SP K E TA PCT AST SA SE RE DIG 8/25/17 Duke L 5 66 28 179 0.212 64 5 13 6 84 8/26/17 Central Florida W 4 56 18 126 0.302 52 7 10 7 49 8/29/17 Northern Colorado W 3 39 8 77 0.403 38 5 12 4 29 9/1/17 vs TCU W 5 62 20 149 0.282 59 6 10 7 65 9/1/17 vs UNC Asheville W 3 41 7 80 0.425 39 8 8 5 28 9/2/17 at Florida State W 3 48 12 95 0.379 45 6 4 1 42 9/8/17 Ball State W 4 59 24 145 0.241 56 6 8 3 44 9/8/17 Michigan W 3 48 8 101 0.396 46 3 6 4 37 9/10/17 Idaho State W 3 46 11 92 0.380 46 4 3 4 48 9/15/17 UAlbany W 3 41 7 73 0.466 36 5 5 1 30 Let’s look at a scatter plot of hitting percentage and the number of digs. While no conclusions can be drawn from such a plot, it can give us some insight into relationships worthy of further analysis. Before creating the plot using the code below, think about what you might expect the outcome to be. 1.7.2 Scatter Plot # Digs, Hitting Percentage, Win/Lose dig_pct_viz &lt;- ggplot(data = csu_vb, aes(x = DIG, y = PCT, color = W_L)) + geom_point() dig_pct_viz Let’s change the axis titles, legend title, and add a main title. dig_pct_viz + labs(title = &quot;Wins and Losses by Number of Digs and Hitting Percentage&quot;, x = &quot;Number of Digs (DIG)&quot;, y = &quot;Hitting Percentage (PCT)&quot;, color = &quot;Win or Loss&quot;) What can we learn from this visual? Well, we can see that there is a weak linear relationship between the number of digs and hitting percentage. To an extent, hitting percentage decreases as the number of digs increases. Why is this the case? Maybe if a team has a really high hitting percentage, this means that the opposing team does not have as many opportunities to attack the other team offensively, reducing the number of opportunities for digs. It also seems that while wins and losses are somewhat evenly spread across the number of digs, there is a more clear cutoff for hitting percentage. It seems that the majority of wins are associated with a hitting percentage of at least 0.2, while the majority of losses are associated with a hitting percentage of less than 0.3. 1.7.3 Box Plot Now let’s take a closer look at the distribution of hitting percentage and digs for wins and losses. To do this, we will create box plots for each statistic. pct_viz &lt;- ggplot(data = csu_vb, aes(x = PCT, y = W_L)) + geom_boxplot() pct_viz dig_viz &lt;- ggplot(data = csu_vb, aes(x = DIG, y = W_L)) + geom_boxplot() dig_viz Let’s modify these plots to make them more complete and visually appealing. pct_viz + labs(title = &quot;Hitting Percentage for Wins and Losses&quot;, x = &quot;Hitting Percentage (PCT)&quot;, y = &quot;Win or Loss&quot;) + geom_boxplot(fill = &quot;slateblue&quot;, alpha = 0.2) dig_viz + labs(title = &quot;Number of Digs for Wins and Losses&quot;, x = &quot;Number of Digs (DIG)&quot;, y = &quot;Win or Loss&quot;) + geom_boxplot(fill = &quot;slateblue&quot;, alpha = 0.2) Box plots allow us to isolate each statistic (number of kills and hitting percentage) so we can more clearly determine the center and spread of each between wins and losses. 1.8 Soccer Rules of Soccer YouTube video: https://www.youtube.com/watch?v=dFLaabgXhpc 1.8.1 Basic Soccer Statistics Shots (SH) represent all shots taken by a team throughout the game. This is simply an attempt by a player to shoot the ball toward the net, even if they miss or the shot is saved (Rookie Road). Shots on Goal (SOG) represent all shots that would have gone into the goal if not saved by a defender or goalkeeper (Rookie Road). Assist (A) occur when a player passes the ball to someone, and the next shot results in a goal. Possession refers to the percentage of time a team had control of the ball during a game. 1.8.2 Advanced Soccer Statistics Expected Goals (xG) “indicates how many goals a team could have expected to score based on the quantity and quality of chances that they created in a match” (Tippett 2019, 4). These definitions come from www.rookieroad.com and “The Expected Goals Philosophy” by James Tippett. To learn more about expected goals, check out this YouTube video: https://www.youtube.com/watch?v=w7zPZsLGK18 1.8.3 Bar Plot Now that we have an understanding of some basic shooting statistics, let us go through some EDA examples. For this first example, we will need to install the “worldfootballR” package. library(worldfootballR) Next we will look at some data specific to La Liga, which is a soccer league in the men’s top professional soccer division. # Get &quot;Squad Standard Stats&quot; Data big5_2021_stats &lt;- fb_big5_advanced_season_stats( season_end_year = 2021, stat_type = &quot;standard&quot;, team_or_player = &quot;team&quot;) liga_2021_stats &lt;- big5_2021_stats[which((big5_2021_stats$Comp == &quot;La Liga&quot;)),] # look at the first ten entries and a selection of columns liga_2021_stats %&gt;% select(Squad,Team_or_Opponent,Poss,Gls,Ast,xG_Expected,xA_Expected) %&gt;% slice_head(n=10) %&gt;% kt() # Create visual for each team&#39;s goals per game team_goals_viz &lt;- ggplot(data = liga_2021_stats[which(liga_2021_stats$Team_or_Opponent == &quot;team&quot;),], aes(x = Squad, y = Gls_Per)) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + geom_bar(stat = &quot;identity&quot;) team_goals_viz This plot is a good starting point, but still looks pretty messy. Let’s add a title, change the axis titles, and rotate the axis labels so they are not overlapping over one another. team_goals_viz &lt;- team_goals_viz + xlab(&quot;Team&quot;) + ylab(&quot;Goals Per Game&quot;) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + ggtitle(&quot;Goals Per Game by Team&quot;) team_goals_viz This is already looking a lot better. Now, we will add the goals scored per game against each team. Why is this of interest? Well, at first glance, Barcelona seems like a pretty impressive team, as they score more goals per game than any other team in the league. However, what if they also have more goals scored against them than any other team in the league? This could be important context, so we will include it in the graph below. all_goals_viz &lt;- ggplot(data = liga_2021_stats, aes(x = Squad, y = Gls_Per)) + geom_bar(stat = &quot;identity&quot;, aes(fill = Team_or_Opponent), position = &quot;stack&quot;) + xlab(&quot;Team&quot;) + ylab(&quot;Goals Per 90 Minutes&quot;) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + ggtitle(&quot;Goals Per Game by Team&quot;) all_goals_viz This is looking pretty good, but let’s clean it up just a bit by changing the legend title and labels. all_goals_viz + scale_fill_discrete(name = &quot;Team or Opponent&quot;, labels = c(&quot;Opponent&quot;,&quot;Team&quot;)) What does this graph show us? Well, we are able to see the average number of goals scored for and against each team per game. It looks like Barcelona is scoring a lot more goals than they are letting be scored against them, while other teams like Valladolid tend to have a higher proportion of goals scored for the opposing team. 1.8.4 Scatter Plot In addition to simply knowing the average actual number of goals scored for and against each team per game, we may be interested in how this compares to the expected number of goals scored per game, as well. library(ggExtra) act_exp_viz &lt;- ggplot(data = liga_2021_stats, aes(x = xG_Per, y = Gls_Per, label = Squad)) + geom_point() + scale_x_continuous(limits = c(0.75,2.25)) + scale_y_continuous(limits = c(0.75,2.25)) + ggtitle(&quot;Expected vs. Actual Goals Per Game&quot;) + xlab(&quot;Expected Goals Per Game&quot;) + ylab(&quot;Actual Goals Per Game&quot;) + geom_smooth(method = &quot;lm&quot;, se = FALSE) + theme(aspect.ratio = 2/2) ggMarginal(act_exp_viz, type = &quot;density&quot;) As you can see, we fit a line to the data. At first glance, it seems to have a positive slope slightly greater than 1. What does this mean in the scenario of actual and expected goals per game? Example 1.16 Use the worldfootballR package to collect team shooting data from the Women’s 1st Tier League (Women’s Super League) in England for 2020-2021. Plot goals vs. shots, shots on target, and expected goals. Comment on the relationships. wsl_2021_shooting &lt;- get_season_team_stats( country = &quot;ENG&quot;, gender = &quot;F&quot;, season_end_year = &quot;2021&quot;, tier = &quot;1st&quot;, stat_type = &quot;shooting&quot;) ## Warning: &#39;get_season_team_stats&#39; is deprecated. ## Use &#39;fb_season_team_stats&#39; instead. ## See help(&quot;Deprecated&quot;) wsl_2021_shooting &lt;-wsl_2021_shooting %&gt;% select(Squad,Gls_Standard,Sh_Standard,SoT_Standard,xG_Expected) %&gt;% rename(Goals=Gls_Standard,Shots=Sh_Standard, `Shots on Target`=SoT_Standard,`Expected Goals` = xG_Expected) wsl_2021_shooting %&gt;% kt() Squad Goals Shots Shots on Target Expected Goals Arsenal 62 374 152 48.2 Aston Villa 14 156 46 13.5 Birmingham City 14 97 34 10.6 Brighton 20 196 71 17.8 Bristol City 17 186 58 15.4 Chelsea 68 418 151 53.6 Everton 39 245 82 29.4 Manchester City 62 426 143 54.1 Manchester Utd 43 364 126 38.9 Reading 24 283 95 26.0 Tottenham 16 187 63 16.5 West Ham 18 224 84 19.8 vs Arsenal 14 165 51 14.5 vs Aston Villa 45 362 129 35.3 vs Birmingham City 43 363 127 35.0 vs Brighton 41 304 89 35.8 vs Bristol City 68 417 162 49.7 vs Chelsea 9 132 36 12.7 vs Everton 29 233 81 27.1 vs Manchester City 13 124 41 11.0 vs Manchester Utd 17 203 69 18.8 vs Reading 41 281 104 33.3 vs Tottenham 40 279 103 32.5 vs West Ham 37 293 113 38.2 wsl_2021_shooting &lt;- wsl_2021_shooting %&gt;% slice_head(n=12) wsl_2021_shooting %&gt;% select(Goals,Shots,`Shots on Target`,`Expected Goals`) %&gt;% ggpairs() "],["probability.html", "Chapter 2 Probability 2.1 Definitions 2.2 Set Theory 2.3 Axioms, Properties, and Laws 2.4 Combinatorics 2.5 Random Variables 2.6 Common Random Variables 2.7 Win Probability Models", " Chapter 2 Probability 2.1 Definitions Definition 2.1 An experiment is any activity or process whose outcome is subject to uncertainty. Definition 2.2 The sample space of an experiment, denoted by \\(\\Omega\\) or \\(\\mathcal{S}\\), is the set of all possible outcomes of that experiment. Definition 2.3 An event is any collection (subset) of outcomes contained in the sample space, \\(\\Omega\\). Example 2.1 Give some examples of discrete random variables in sports. Example 2.2 Give some examples of continuous random variables in sports.   2.2 Set Theory For the following examples, suppose that we are interested in the batting outcomes of a plate appearance in baseball. Let \\(A\\) be the event that the batter gets walked, let \\(B\\) be the event that the batter gets a hit, let \\(C\\) be the event that the batter strikes out, and let \\(D\\) be the event that the batter makes it to first base at the end of their at bat. We will define a handful of set operations to help us when we begin calculating the probability of different events occurring. Definition 2.4 The compliment of an event \\(A\\), denoted by \\(A^c\\) or \\(A&#39;\\), is the set of all outcomes in \\(\\Omega\\) that are not contained in \\(A\\). Example 2.3 Draw a Venn diagram illustrating \\(A^c\\) and describe the event. Definition 2.5 The union of two events \\(A\\) and \\(B\\), denoted by \\(A \\cup B\\) and read “\\(A\\) or \\(B\\)”, is the event consisting of all outcomes that are either in \\(A\\) or \\(B\\) or in both. Example 2.4 Draw a Venn diagram illustrating \\(A \\cup D\\) and describe the event. Definition 2.6 The intersection of two events \\(A\\) and \\(B\\), denoted by \\(A \\cap B\\) and read “\\(A\\) and \\(B\\)”, is the event consisting of all outcomes that are in both \\(A\\) and \\(B\\). Example 2.5 Draw a Venn diagram illustrating \\(A \\cap D\\) and describe the event. Definition 2.7 The difference of two events \\(A\\) and \\(B\\), denoted by \\(A \\mathbin{/} B\\) and read “difference of \\(A\\) and \\(B\\)”, is the event consisting of all outcomes that are in \\(A\\) but not in \\(B\\). Example 2.6 Draw a Venn diagram illustrating \\(D \\mathbin{/} A\\) and describe the event. Definition 2.8 Two events \\(A\\) and \\(B\\) are said to be disjoint (or mutually exclusive) if \\(A \\cap B = \\emptyset\\) Example 2.7 Are the events \\(A\\) and \\(B\\) disjoint? How about \\(A\\) and \\(D\\)? 2.3 Axioms, Properties, and Laws There are some basic assumptions or “axioms” which are the foundation of the theory of probability. Andrey Kolmogorov first described these axioms in 1933. 2.3.1 Axioms of Probability \\(P(A) \\geq 0\\), for any event \\(A\\) \\(P(\\Omega) = 1\\) If \\(A_1, A_2, A_3, \\ldots\\) is a collection of disjoint events, then: \\(P(\\cup_{i=1}^{\\infty} A_i) = P(A_1 \\cup A_2 \\cup \\ldots ) = \\sum_{i=1}^{\\infty} P(A_i)\\) Note that all probabilities are between 0 and 1, that is, for any event \\(A\\), \\(0 \\leq P(A) \\leq 1\\). We can convert to percentages by multiplying probabilities by 100, however, this is a set that is only done after all calculations have been completed. 2.3.2 Properties of Probability \\(P(\\emptyset) = 0\\) \\(P(A^c) = 1 - P(A)\\) \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\) \\(P(A \\cup B \\cup C) = \\\\ P(A) + P(B) + P(C) - P(A \\cap B) - P(A \\cap C) - P(B \\cap C) + P(A \\cap B \\cap C)\\) \\(P([A \\cup B]^c) = P(A^c \\cap B^c)\\) \\(P([A \\cap B]^c) = P(A^c \\cup B^c)\\) Example 2.8 In 2001, Barry Bonds broke the single season home run record with 73 home runs. In this season, he had 664 plate appearances (476 at-bats), 156 hits, 177 walks, 9 hit by pitches, and 2 sacrifice flies. Use this information to answer the following questions. Plate appearances that result in a walk, hit by pitch, or sacrifice fly are not counted towards a player’s at-bats. Confirm that Bonds had 476 official at-bats. Suppose an at-bat is chosen at random. What is the probability that Bonds got a hit? (This is his batting average.) For the following examples, assume that one of Bonds’ plate appearances is chosen at random. What is the probability that Bonds reached base via a hit, walk, or hit by pitch? (This is his on-base average/percentage.) What is the probability that Bonds did not reach base? Calculate \\(P\\left(HBP \\cup Walk\\right)\\) Calculate \\(P\\left(HBP^c \\cap Walk^c\\right)\\) 2.3.3 Laws of Probability Definition 2.9 Let \\(A\\) and \\(B\\) be two events such that \\(P(B)&gt;0\\). Then the conditional probability of \\(A\\) given \\(B\\), written \\(P(A|B)\\), is given by: \\(P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\) Example 2.9 In 1998, Sammy Sosa hit 66 home runs in 722 plate appearances, the third highest single season homework total ever. During June 1998, Sosa 20 home runs in 121 plate appearances. Suppose a randomly selected plate appearance is selected. Calculate the following probabilities. \\(P(HR)\\) \\(P(HR \\cap June)\\) \\(P(June)\\) \\(P(HR|June)\\) \\(P(June|HR)\\) \\(P(HR|June^c)\\) Theorem 2.1 (Multiplication Rule) For any two events \\(A\\) and \\(B\\), \\(P(A \\cap B) = P(B|A) \\cdot P(A)\\). Example 2.10 Calculate the probability that a randomly selected plate appearance from Sosa’s 1998 season is a home run in June. Definition 2.10 Events \\(A_1, A_2, \\ldots, A_n\\) are said to form a partition of a sample space \\(\\Omega\\) if both: (i) \\(A_i \\cap A_j = \\emptyset\\) (\\(i \\neq j\\)) (ii) \\(\\cup_{i=1}^n A_i = \\Omega\\) Theorem 2.2 (Law of Total Probability) Suppose events \\(A_1, A_2, \\ldots, A_n\\) form a partition of \\(\\Omega\\), then: \\(P(B) = P(B|A_1)P(A_1) + P(B|A_2)P(A_2) + \\ldots P(B|A_n)P(A_n)\\) Example 2.11 What is one possible way to partition Sosa’s plate appearances in 1998? Theorem 2.3 (Bayes Theorem: simple version) Suppose events \\(B\\) and \\(C\\) form a partition of \\(\\Omega\\), then: \\(P(B|A) = \\frac{P(B \\cap A)}{P(A)} = \\frac{P(A|B)P(B)}{P(A|B)P(B)+P(A|C)P(C)}\\) Theorem 2.4 (Bayes Theorem) Suppose events \\(B_1, B_2, \\ldots, B_n\\) form a partition of \\(\\Omega\\), then: \\(P(B_k|A) = \\frac{P(B_k \\cap A)}{P(A)} = \\frac{P(A|B_k)P(B_k)}{P(A|B_1)P(B_1)+P(A|B_2)P(B_2) + \\ldots + P(A|B_n)P(B_n)}\\) Example 2.12 Given that Sosa hit a home run in 1998, what is the probability that he hit it in June? Example 2.13 Over the course of a season, a hockey player scored a goal 30% of the time during a home game, and 18%. Assume all games are either home or away. Use this information to answer the following questions. What is the probability the player scored a goal in any game if there were an equal number of home and away games? What is the probability the player scored a goal in any game if there were twice as many home games as away games? What is the probability the player scored a goal in any game if the ratio of home games to away games is 2:3? 2.4 Combinatorics Combinatorics is the mathematical study of counting, particularly with respect to permutations and combinations. Definition 2.11 The factorial function (\\(n!\\)) is defined for all positive integers by: \\(n! = n \\cdot (n-1) \\cdot \\ldots 2 \\cdot 1\\) Note that \\(0! \\equiv 1\\) and \\(1! \\equiv 1\\). Example 2.14 A baseball/softball batting lineup has nine ordered players. Suppose the manager has selected the nine players to bat. How many different batting orders are there possible? Definition 2.12 An ordered subset is called a permutation. The number of permutations of size \\(k\\) that can be formed from the \\(n\\) elements in a set is given by: \\(P_{n,k} = \\frac{n!}{(n-k)!}\\) Example 2.15 In MLB, each team has a 26-person roster, of which about 13 are hitters. Assuming one of the batters is the designated hitter, how many different batting lineups of 9 players can a manager create? Definition 2.13 An unordered subset is called a combination. The number of combinations of size \\(k\\) that can be formed from the \\(n\\) elements in a set is given by: \\(C_{n,k} = {n \\choose k} = \\frac{n!}{k! \\cdot (n-k)!}\\) Example 2.16 Suppose a manager has 13 hitters to choose from to fill out a starting lineup of 9 players. Ignoring positions, how many different ways can the manager pick a 9-person lineup from 13 possible hitters? Theorem 2.5 (Product Rule for Ordered Pairs) If the first element of an ordered pair can be selected in \\(n_1\\) ways and for each of the these \\(n_1\\) ways the second element of the pair can be selected in \\(n_2\\) ways, then the number of pairs is \\(n_1 \\cdot n_2\\). Theorem 2.6 (Generalized Product Rule) Suppose a set consists of \\(k\\) elements (k-tuples) and that there are \\(n_1\\) possible choices for the first element, \\(n_2\\) possible choices for the second element, … , and \\(n_k\\) possible choices for the \\(k^\\text{th}\\) element, then there are \\(n_1 \\cdot n_2 \\cdot \\ldots \\cdot n_k\\) possible k-tuples. Example 2.17 A baseball manager selects nine hitters and one pitcher for a starting lineup. Suppose they can choose from 13 hitters and 13 hitters. How many different possible lineups can the manager choose from? 2.5 Random Variables Definition 2.14 Let \\(\\Omega\\) be the sample space of an experiment. A random variable is a rule that associates a number with each outcome in \\(\\Omega\\). In other words, a random variable is a function whose domain is \\(\\Omega\\) and whose range is the set of real numbers. Random variables are be broken down into subcategories: 1. Discrete random variables - random variables which have a sample space that is finite or countably infinite. 2. Continuous random variables - random variables which have a sample space that is uncountably infinite (such as an interval of real numbers) Discrete and Continuous random variables use similar yet slightly different mathematical tools. Discrete random variables involve working with “sums” and continuous random variables involve working with “integrals”. Example 2.18 Give an example of a discrete random variable in hockey. Example 2.19 Give an example of a continuous random variable in hockey. Definition 2.15 A probability distribution is a function that gives probabilities of different possible outcomes for a given experiment. The probability distribution for a discrete random variable, \\(p(x)\\), is called a probability mass function (pmf). The probability distribution for a continuous random variable, \\(f(x)\\), is called a probability density function (pdf). Example 2.20 Suppose the Colorado Rockies are playing a four game series against the Chicago Cubs and that the Rockies have a 65% chance of winning an individual game. Further, assume that the games are independent. The following PMF describes the outcomes (number of Rockies wins) and their probabilities. Rockies wins, X 0.000 1.000 2.000 3.000 4.000 Probability, p(X) 0.015 0.111 0.311 0.384 0.179 What is the probability that the Rockies win zero games? What is the probability that the Rockies win at least two games? Why might the independence assumption be false? We may be interested in describing the center or average value of our random variable. We can do this with the following definitions. Definition 2.16 The expected value (or population mean or average) of a random variable \\(X\\) is given by: \\(E[X] = \\mu = \\sum_{x \\in \\Omega} x \\cdot p(x)\\) (for discrete random variables) \\(E[X] = \\mu = \\int_{x \\in \\Omega} x \\cdot f(x) dx\\) (for continuous random variables) For this class, evaluating integrals is not essential, so we will avoid using Calculus (integrals and derivatives) when possible. Sometimes, it makes sense to calculate the expected value of a function of a random variable. This can be easily done with a slight modification to the previous definition. Let \\(h(X)\\) be some function of a random variable \\(X\\). The expected value of \\(h(X)\\), \\(E[h(X)]\\), is given by: \\(E[h(X)] = \\sum_{x \\in \\Omega} h(x) \\cdot p(x)\\) (for discrete random variables) \\(E[h(X)] = \\int_{x \\in \\Omega} h(x) \\cdot f(x) dx\\) (for continuous random variables) Example 2.21 For the Rockies/Cubs four game series example, calculate \\(E[X]\\) and \\(E[X^2]\\). The spread or variability associated with a random variable can be calculated using expected values as well. Definition 2.17 The population variance of a random variable \\(X\\) is given by: \\(Var(X) = \\sum_{x \\in \\Omega} (x-\\mu)^2 \\cdot p(x)\\) (for discrete random variables) \\(Var(X) = \\int_{x \\in \\Omega} (x-\\mu)^2 \\cdot f(x) dx\\) (for continuous random variables) There is also a shortcut formula for calculating variance: Theorem 2.7 \\(Var(X) = E[X^2] - (E[X])^2\\) Definition 2.18 The population standard deviation of a random variable \\(X\\) is given by: \\(SD(X) = \\sigma = \\sqrt{Var(X)} = \\sqrt{E[X^2]-(E[X])^2}\\) Example 2.22 For the Rockies/Cubs four game series example, calculate \\(Var(X)\\). Definition 2.19 A quantile-quantile plot (QQ plot) can be used to compare an empirical probability distribution against a theoretical distribution. Example 2.23 Let’s generate two simulated datasets. The first dataset will follow a normal distribution with mean 10 and variance 4 and the second dataset will follow a Poisson distribution with rate 5. We’ll use QQ-plots to match each simulation with the correct distribution. set.seed(2022) sim1.df &lt;- data.frame(x=rnorm(n = 1000,mean = 10,sd = 2)) sim2.df &lt;- data.frame(x=rpois(n = 1000,lambda = 5)) jitter_width &lt;- 0.2 fig1 &lt;- ggplot(sim1.df, aes(sample = x)) + stat_qq(position=position_jitter(width = jitter_width,height = jitter_width)) + stat_qq_line() + ggtitle(&quot;Sim 1 vs. Normal&quot;) + xlab(&quot;Theoretical Quantiles&quot;) + ylab(&quot;Empirical Quantiles&quot;) fig2 &lt;- ggplot(sim2.df, aes(sample = x)) + stat_qq(position=position_jitter(width = jitter_width,height = jitter_width)) + stat_qq_line() + ggtitle(&quot;Sim 2 vs. Normal&quot;) + xlab(&quot;Theoretical Quantiles&quot;) + ylab(&quot;Empirical Quantiles&quot;) fig3 &lt;- ggplot(sim1.df, aes(sample = x)) + stat_qq(distribution = qpois, dparams = 5,position=position_jitter(width = jitter_width,height = jitter_width)) + stat_qq_line(distribution = qpois, dparams = 5) + ggtitle(&quot;Sim 1 vs. Poisson&quot;) + xlab(&quot;Theoretical Quantiles&quot;) + ylab(&quot;Empirical Quantiles&quot;) fig4 &lt;- ggplot(sim2.df, aes(sample = x)) + stat_qq(distribution = qpois, dparams = 5,position=position_jitter(width = jitter_width,height = jitter_width)) + stat_qq_line(distribution = qpois, dparams = 5) + ggtitle(&quot;Sim 2 vs. Poisson&quot;) + xlab(&quot;Theoretical Quantiles&quot;) + ylab(&quot;Empirical Quantiles&quot;) library(gridExtra) ## ## Attaching package: &#39;gridExtra&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## combine grid.arrange(fig1,fig2,fig3,fig4,ncol=2) What do you conclude from the four QQ plots? 2.6 Common Random Variables There are several families of random variables that show up frequently in applications. Some of these random variables include: - Binomial - Geometric - Poisson - Normal 2.6.1 Binomial RVs Definition 2.20 A binomial(n,p) random variable is a discrete random variable that counts the numbers of “successes” over a fixed number of trials, \\(n\\), with each trial having an equal probability of success, \\(p\\). \\(P(X=k) = \\binom{n}{k} p^k(1-p)^{n-k} = \\frac{n!}{k!\\ \\cdot\\ (n-k)!} p^k(1-p)^{n-k}\\), where \\(0 \\leq k \\leq n, 0 \\leq p \\leq 1\\) If \\(X \\sim Binomial(n,p)\\), then \\(E[X]=np\\) and \\(Var(X)=np(1-p)\\) Example 2.24 The Cubs and Rockies are playing a 4-game series. The Rockies have a 0.65 probability of winning each game, and the Cubs have a 0.35 probability. Assume each game is independent. Solve for the following quantities. The Cubs win exactly 1 game. The Rockies win exactly 2 games. The Cubs win at least 2 games. The series ends in a sweep. The expected number of wins for the Rockies. The variance and standard deviations of wins for the Rockies. Example 2.25 Complete 10,000 simulations of the four game series between the Rockies and Cubs. For the number of Rockies wins, calculate the sample mean and sample variance and compare these to the population values. Also, plot a histogram of the sample data. set.seed(2022) rockies_wins &lt;- rbinom(n=10000,size=4,prob=0.65) mean(rockies_wins) ## [1] 2.6036 var(rockies_wins) ## [1] 0.9121583 rockies_wins_df &lt;- data.frame(Wins=rockies_wins) rockies_wins_df %&gt;% ggplot(aes(Wins)) + geom_histogram(binwidth = 1,color = &quot;black&quot;, fill = &quot;purple&quot;) 2.6.1.1 Binomial Coefficient Symmetry Playoff series for a certain sports league are played as a best-of-seven series, with one team hosting four games and the opposing team hosing three. An executive for the league wishes to know the number of ways the home and away games can be assigned. (One such combination is A-A-B-B-A-B-A, the format used by the NBA and NHL for their best-of-seven series.) What is the total number of combinations? However, instead of thinking about the number of ways to assign the games to the team that gets four home games, what if we thought about the number of ways to assign games to the team that gets three home games? That would be \\(\\binom{7}{3}\\). We can use the choose command in R to find this quantity. choose(7,3) ## [1] 35 It turns out that this binomial coefficient is also equal to 35. Theorem: \\(\\binom{n}{k} = \\binom{n}{n-k}\\) \\(\\binom{n}{k} = \\frac{n!}{k!\\ \\cdot\\ (n-k)!}\\) \\(\\binom{n}{n-k} = \\frac{n!}{(n-k)!\\ \\cdot\\ (n-(n-k))!} = \\frac{n!}{(n-k)!\\ \\cdot\\ k!} = \\binom{n}{k}\\) 2.6.2 Geometric RVs Definition 2.21 A Geometric(p) random variable is a discrete random variable that counts the numbers of trials until a “success” occurs, where the probability of success, \\(p\\), is constant across all trials. \\(P(X=k) = p(1-p)^{k-1}\\), where \\(k \\geq 1, 0 \\leq p \\leq 1\\) If \\(X \\sim Geometric(p)\\), then \\(E[X]=\\frac{1}{p}\\) and \\(Var(X)=\\frac{p}{1-p}\\) Example 2.26 Suppose the number of shots needed by a hockey team in order to score their first goal, X, is modeled by a Geometric(\\(\\frac{1}{10}\\)) random variable. Use this information to answer the following questions. What is the probability that it takes exactly 3 shots to score the first goal? What is the probability that it takes less than 3 shots to score the first goal? What is the probability that it takes more than 3 shots to score the first goal? Caution: Some references parameterize the Geometric distribution based on the number of failures before the first success, rather than the trial on which the first success occurs. This changes the PMF, mean, and variance, so be careful. Let’s simulate the number of shot attempts required to score the first goal (Geometric(\\(p=1/10\\))) from the previous example. set.seed(2020) geometric &lt;- rgeom(10000, 1/10) head(geometric, 20) ## [1] 2 2 7 55 6 11 2 11 2 5 0 50 17 2 7 0 7 19 17 1 Some of the values were 0, which could not happen if R was considering the number of the trial on which the first success occurred. You can add 1 to the values given by R to arrive at the first success distribution. first_success &lt;- geometric + 1 head(first_success, 20) ## [1] 3 3 8 56 7 12 3 12 3 6 1 51 18 3 8 1 8 20 18 2 (mean_success &lt;- mean(first_success)) ## [1] 10.0669 The mean of this sample of variables is 10.0669, which is close to the expected mean of \\(\\frac{1}{p} = 10\\). Let’s plot the sample distribution of shots required to score a goal from the simulation as well. first_success_df = data.frame(Shots = first_success) first_success_df %&gt;% ggplot(aes(x=Shots)) + geom_histogram(binwidth = 1) 2.6.3 Poisson RVs Definition 2.22 A Poisson(\\(\\lambda\\)) random variable is a discrete random variable that counts the numbers of “successes” for a given rate parameter, \\(\\lambda\\), for a given interval. \\(P(X=k) = \\frac{e^{-\\lambda}\\lambda^k}{k!}\\), where \\(k \\geq 0,\\) If \\(X \\sim Poisson(\\lambda)\\), then \\(E[X]=\\lambda\\) and \\(Var(X)=\\lambda\\) Example 2.27 During the 2021 Major League Soccer season, the Colorado Rapids scored 51 goals in 34 games on their way to a first-place finish in the Western Conference regular season standings. The team scored \\(\\frac{51}{34} = 1.5\\) goals per game. Let’s model the distribution of Rapids goals using a Poisson(1.5) random variable that we’ll call Y. Which is more likely: Y taking on the value 0 or Y taking on the value 2? We can calculate these probabilities in R using the dpois command. dpois(x=0, lambda=1.5) ## [1] 0.2231302 dpois(x=2, lambda=1.5) ## [1] 0.2510214 We can also plot the PMF of Y to check visually. x &lt;- 0:8 y &lt;- dpois(x, lambda = 1.5) poisson.pmf &lt;- data.frame(x,y) ggplot(transform(poisson.pmf), aes(x, y)) + geom_bar(stat=&quot;identity&quot;) + ggtitle(&quot;Probability mass function of Poisson(1.5) random variable&quot;) + xlab(&quot;Value&quot;) + ylab(&quot;Probability&quot;) Let’s check whether using a Poisson distribution was appropriate by comparing it to the actual 2021 Colorado Rapids match results. # Data: https://www.espn.com/soccer/team/results/_/id/184/season/2021 library(&quot;kableExtra&quot;) rapids21 &lt;- c(0,1,1,3,3,1,3,2,1,1,2,1,2,0,1,0,3,2,2,1,1,1,2,1,0,3,0,3,1,1,2,0,1,5) goals &lt;- c(0:4, &quot;5+&quot;) actual_frequency &lt;- c(6, 14, 7, 6, 0, 1) actual_proportion &lt;- actual_frequency / sum(actual_frequency) expected_proportion &lt;- c(dpois(0:4, lambda=1.5), ppois(4, lambda=1.5, lower.tail=FALSE)) expected_frequency &lt;- round(expected_proportion * 34, 1) rapids.data &lt;- data.frame(goals, actual_frequency, actual_proportion, expected_frequency, expected_proportion) names(rapids.data) = c(&quot;Goals&quot;,&quot;Actual Frequency&quot;,&quot;Actual Proportion&quot;,&quot;Expected Frequency&quot;,&quot;Expected Proportion&quot;) rapids.data %&gt;% kt() Goals Actual Frequency Actual Proportion Expected Frequency Expected Proportion 0 6 0.176 7.6 0.223 1 14 0.412 11.4 0.335 2 7 0.206 8.5 0.251 3 6 0.176 4.3 0.126 4 0 0.000 1.6 0.047 5+ 1 0.029 0.6 0.019 What differences do you notice between the actual results and the expected values based on the Poisson random variable? Even if the true population distribution of 2021 Rapids goals was truly a Poisson(1.5) random variable, why might the actual distribution of their goals differ from the probability mass function? Use a QQ plot to compare the probability distribution of the 2021 Rapids goals to a Poisson distribution. rapids21 %&gt;% as.data.frame %&gt;% ggplot(aes(sample = rapids21)) + stat_qq(distribution = qpois, dparams = 1.5,position=position_jitter(width = 0.1,height = 0.1)) + stat_qq_line(distribution = qpois, dparams = 1.5) + ggtitle(&quot;QQ-plot for Rapids 2021 Goals vs. Poisson Distribution&quot;) + xlab(&quot;Theoretical Quantiles&quot;) + ylab(&quot;Empirical Quantiles&quot;) What are the advantages of using the Poisson distribution to model Major League soccer goals? What are the disadvantages? Example 2.28 In 1997-1998 with the Los Angeles Lakers, Shaquille O’Neal attempted an average of 11.35 free throws per game with a standard deviation of 4.04. Is it appropriate to model Shaq’s per game free throw attempts as a Poisson(11.35) random variable? Plot the data. shaq9798 &lt;- read_csv(&quot;data/shaq9798.csv&quot;) shaq9798 %&gt;% ggplot(aes(x=FTA)) + geom_bar(color = &quot;yellow&quot;, fill = &quot;purple&quot;) + ggtitle(&quot;Per Game FT Attempt Totals by Shaq in 1997-1998&quot;) + xlim(0,25) Plot the PMF of a Poisson(11.35) random variable. x &lt;- 0:25 y &lt;- dpois(x, lambda = 11.35) poisson.pmf &lt;- data.frame(x,y) ggplot(poisson.pmf, aes(x, y)) + geom_bar(stat=&quot;identity&quot;) + ggtitle(&quot;Probability mass function of Poisson(11.35) random variable&quot;) + xlab(&quot;Value&quot;) + ylab(&quot;Probability&quot;) What similarities and what differences do you notice? Calculate the variance of the two distributions and compare them. var(shaq9798$FTA) ## [1] 16.33305 # Var(Poisson(11.35)) = 11.35 Calculate the probability that Shaq had 20 or more free throws and compare it to \\(P(Poisson(11.35) \\geq 20)\\) shaqFTA &lt;- shaq9798$FTA shaq20 &lt;- sum(shaqFTA &gt;= 20)/length(shaqFTA); shaq20 ## [1] 0.06666667 poisson20 &lt;- ppois(20, lambda=11.35, lower.tail=FALSE); poisson20 ## [1] 0.006536079 Create a QQ-plot of Shaq’s per game free throw attempts and a Poisson distribution. shaq9798 %&gt;% ggplot(aes(sample = FTA)) + stat_qq(distribution = qpois,dparams = 11.35,position=position_jitter(width=0.2,height=0.2)) + stat_qq_line(distribution = qpois, dparams = 11.35) + ggtitle(&quot;QQ-plot for Shaq&#39;s Free Throw Attempts vs. Poisson Distribution&quot;) + xlab(&quot;Theoretical Quantiles&quot;) + ylab(&quot;Empirical Quantiles&quot;) Is the Poisson distribution appropriate to model Shaq’s FTA per game? Explain. 2.6.4 Negative Binomial RVs Definition 2.23 A Negative Binomial(\\(r\\),\\(p\\)) random variable is a discrete random variable that counts the numbers of “successes” for given parameters, \\(r\\) and \\(p\\). \\(P(X=k) = {k+r-1 \\choose k}(1-p)^rp^k\\), where \\(k = 0, 1, 2, ...\\) If \\(X \\sim NB(r,p)\\), then \\(E[X]=\\frac{rp}{1-p}\\) and \\(Var(X)=\\frac{rp}{(1-p)^2}\\) The Negative Binomial distribution is often used to model count data that is “overdispersed”. A property of the Poisson distribution is that the mean and variance are equal. If you are analyzing count data such that the variance is much greater than the mean (i.e., overdispersed), then the Negative Binomial distribution may be an appropriate substitute. Given sample count data, we can estimate appropriate parameters for a Negative Binomial in many ways. One such way is to use the “method of moments” estimator. These estimators are given by: \\(\\hat{p} = \\frac{s^2-\\bar{x}}{s^2}\\) and \\(\\hat{r} = \\frac{\\bar{x}^2}{s^2-\\bar{x}}\\) Example 2.29 Using Shaq’s 1997-1998 data, model his per game free throw attempts as a Negative Binomial random variable. Find an appropriate choice of parameters, \\(r\\) and \\(p\\). shaq.mean &lt;- mean(shaqFTA) shaq.var &lt;- var(shaqFTA) rhat &lt;- shaq.mean^2/(shaq.var-shaq.mean) phat &lt;- (shaq.var-shaq.mean)/shaq.var c(rhat,phat) ## [1] 25.85213 0.30509 Plot the Negative Binomial distribution. Note that R uses an alternative parameterization for \\(p\\). Use \\(prob = 1-p\\). x &lt;- 0:25 y &lt;- dnbinom(x,size=rhat,prob=1-phat) geom.pmf &lt;- data.frame(x,y) ggplot(geom.pmf, aes(x, y)) + geom_bar(stat=&quot;identity&quot;) + labs(x=&quot;Value&quot;, y=&quot;Frequency&quot;, title=&quot;Probability mass function of NB(r=25.852,p=0.305) random variable&quot;) Calculate the mean and variance of the Negative Binomial and Shaq’s dataset. shaq.mean &lt;- mean(shaqFTA) shaq.var &lt;- var(shaqFTA) NB.mean &lt;- (rhat*phat)/(1-phat) NB.var &lt;- (rhat*phat)/(1-phat)^2 c(shaq.mean,shaq.var) ## [1] 11.35000 16.33305 c(NB.mean,NB.var) ## [1] 11.35000 16.33305 Calculate the probability that Shaq had 20 or more free throws and compare it to \\(P(NB(r=25.852,p=0.305) \\geq 20)\\) shaq20 &lt;- sum(shaqFTA &gt;= 20)/length(shaqFTA); shaq20 ## [1] 0.06666667 nb20 &lt;- pnbinom(20,size=rhat,prob=1-phat,lower.tail=FALSE); nb20 ## [1] 0.0208711 Create a QQ-plot of Shaq’s per game free throw attempts and a Negative Binomial distribution. shaq9798 %&gt;% ggplot(aes(sample = FTA)) + stat_qq(distribution = qnbinom,dparams = list(size=25.852,mu=11.35),position=position_jitter(width=0.2,height=0.2)) + stat_qq_line(distribution = qnbinom, dparams = list(size=25.852,mu=11.35)) + ggtitle(&quot;QQ-plot for Shaq&#39;s Free Throw Attempts vs. Negative Binomial Distribution&quot;) + xlab(&quot;Theoretical Quantiles&quot;) + ylab(&quot;Empirical Quantiles&quot;) Is the Negative Binomial distribution appropriate to model Shaq’s FTA per game? How does it compare to using the Poisson distribution? Explain. 2.6.5 Normal RVs Definition 2.24 A Normal(\\(\\mu\\),\\(\\sigma^2\\)) random variable is a continuous random variable that is bell-shaped with mean \\(\\mu\\) and variance \\(\\sigma^2\\). To calculate probabilities under the normal curve, you need either to integrate, use a table, or a computer. Note that a normal random variable can be standardized by using: \\(z = \\frac{x-\\mu}{\\sigma}\\) Theorem 2.8 For a normal(\\(\\mu\\),\\(\\sigma^2\\)) random variable, we have the following approximations: - About 68% of the data falls within one standard deviation of the mean (i.e., \\(\\mu \\pm \\sigma\\)) - About 95% of the data falls within two standard deviations of the mean (i.e., \\(\\mu \\pm 2\\sigma\\)) - About 99.7% of the data falls within three standard deviations of the mean (i.e., \\(\\mu \\pm 3\\sigma\\)) Example 2.30 The skills (or tools) of a baseball player are often rated on a scale of 20-80, where 50 is an average grade, 20 is the lowest grade, and 80 is the highest grade. The distribution of tool grades is approximately normally distributed (\\(\\mu=50, \\sigma =10\\)). See https://blogs.fangraphs.com/scouting-explained-the-20-80-scouting-scale/ for more details. Calculate the following probabilities. Former Rockie Nolan Arenado has been graded to have game power of 70. Game power estimates a player’s ability to hit home runs. Approximately what percentage of baseball players have equal or greater game power than Arenado? Mike Trout has been graded to have raw power of 55. Raw power estimates a player’s ability to hit baseballs hard (i.e., hard hit rate). Approximately what percentage of baseball players have equal or less raw power than Trout? Suppose a Rockies prospect is said to be in the top 10% of all baseball players in terms of their speed. What approximate speed grade would correspond to the player? Suppose a Rockies prospect is said to be in the bottom 20% of all baseball players in terms of their hit ability. What approximate hit grade would correspond to the player? Between what two grades do approximately 95% of all players lie for a given tool? Let’s check our answers: a &lt;- 1-pnorm(q=70,mean=50,sd=10); a ## [1] 0.02275013 b &lt;- pnorm(q=55,mean=50,sd=10); b ## [1] 0.6914625 c &lt;- qnorm(0.1,mean=50,sd=10,lower.tail = F); c ## [1] 62.81552 d &lt;- qnorm(0.2,mean=50,sd=10,lower.tail = T); d ## [1] 41.58379 e &lt;- pnorm(q=70,mean=50,sd=10) - pnorm(q=30,mean=50,sd=10); e ## [1] 0.9544997 Example 2.31 Player X has a projected mean WAR of 3 with standard deviation of 2 and player Y has a projected mean WAR of 1.5 with a standard deviation of 3. Assume projected WAR is normally distributed. What is the probability that Player X outperforms Player Y? Link to WAR explanation: https://www.mlb.com/glossary/advanced-stats/wins-above-replacement We want \\(P(X&gt;Y)\\) or \\(P(X-Y&gt;0)\\) # Calculate probability Z&lt;=0 p &lt;- pnorm(0,1.5,sqrt(5),lower.tail = F); p ## [1] 0.7488325 2.7 Win Probability Models The probability an NFL team will win can be modeled as a normal random variable using the Vegas line. This method is outlined by Wayne Winston in Mathletics building on previous research by Hal Stern. 2.7.1 Estimating Pregame Win Probability Winston estimates that the final margin of victory is approximately a normal random variable with a mean of the Vegas line and a standard deviation between 13-14. Winston and Stern estimated the standard deviation to be 13.86 based on data from the 1981, 1983, and 1984 NFL seasons. This estimated standard deviation has since been updated to be 13.45 based on data from 1978 – 2012 NFL seasons. Reference: https://www.pro-football-reference.com/about/win_prob.htm Example 2.32 Sketch the distribution of the final margin of victory for an NFL team that is favored by 7 points. Shade the area for a win in regulation (for the favorite) and a tie in regulation. library(ggplot2) library(gridExtra) final_margin_full &lt;- ggplot(data.frame(x = c(-21, 42)), aes(x = x)) + stat_function(fun = dnorm, args = list(mean = 7, sd = 13.45)) + xlab(&quot;Final Margin (for favorite)&quot;) + ggtitle(&quot;Full Distribution&quot;) final_margin_zoom &lt;- ggplot(data.frame(x = c(-3, 10)), aes(x = x)) + stat_function(fun = dnorm, args = list(mean = 7, sd = 13.45)) + xlab(&quot;Final Margin (for favorite)&quot;) + ggtitle(&quot;Zoomed Distribution&quot;) + scale_x_continuous(breaks=seq(-2, 10, 1)) grid.arrange(final_margin_full, final_margin_zoom, ncol=2) Example 2.33 In Super Bowl 50, the Denver Broncos were 5.5 point underdogs (+5.5) against the Carolina Panthers. Estimate the pregame win probability for the Denver Broncos. fav_line &lt;- 5.5 full_sd &lt;- 13.45 win_prob &lt;- pnorm(q = 0.5, mean = fav_line, sd = full_sd, lower.tail = FALSE) tie_prob &lt;- pnorm(q = 0.5, mean = fav_line, sd = full_sd, lower.tail = TRUE) - pnorm(q = -0.5, mean = fav_line, sd = full_sd, lower.tail = TRUE) # win probability for favorite (panthers) win_prob &lt;- win_prob + 1/2 * tie_prob # win probability for underdog (broncos) (broncos_win_prob &lt;- 1 - win_prob) ## [1] 0.3414021 2.7.2 Estimating In-Game Win Probability Winston proposed an updated method to calculate in-game win probabilities based on the time remaining in the game, current score margin, and Vegas line. In this proposed method, the pregame mean (Vegas line) and pregame variance (13.45) are scaled down linearly as a function of time remaining in the game. For instance, since there are four 15-minute quarters (total regulation game time is 60 minutes), then the in-game mean and standard deviation are calculated as follows. \\(\\mu_{updated} = Line \\cdot \\frac{\\text{time remaining}}{60}\\) \\(\\sigma_{updated} = \\frac{13.45}{\\sqrt{60/\\text{time remaining}}}\\) Note: This model assumes perfectly neutral possession, down, distance, and field-position conditions. Reference: https://www.pro-football-reference.com/about/win_prob.htm Example 2.34 In Super Bowl 50, the Denver Broncos led the Carolina Panthers 10-0 after the first quarter. The Broncos were 5.5 point underdogs at the start of the game. Use Winston’s method to estimate the probability of a Broncos win after one quarter. fav_margin &lt;- -10 fav_line &lt;- 5.5 full_sd &lt;- 13.45 full_min &lt;- 60 new_min &lt;- 45 new_mean &lt;- fav_line * new_min/full_min new_sd &lt;- full_sd / sqrt(full_min/new_min) win_prob &lt;- pnorm(q = 0.5 - fav_margin, mean = new_mean, sd = new_sd, lower.tail = FALSE) tie_prob &lt;- pnorm(q = 0.5 - fav_margin, mean = new_mean, sd = new_sd, lower.tail = TRUE) - pnorm(q = -0.5 - fav_margin, mean = new_mean, sd = new_sd, lower.tail = TRUE) # win probability for favorite (panthers) win_prob &lt;- win_prob + 1/2 * tie_prob # win probability for underdog (broncos) (broncos_win_prob &lt;- 1 - win_prob) ## [1] 0.6928385 The win probability models outlined above use only the Vegas line, the current score, and the time remaining in the game. More accurate estimation models will also consider possession, down, distance, and field-position conditions. Pro Football Reference offers an in-game win probability model with these additional factors. Reference: https://www.pro-football-reference.com/boxscores/win_prob.cgi Example 2.35 The Broncos led the Panthers 10-0 at the end of the first quarter. The Panthers had 2nd and 11 at their own 46 at the beginning of the second quarter. Calculate the Broncos win probability. Reference: https://www.pro-football-reference.com/boxscores/201602070den.htm Pro Football Reference Win Probability Calculator Inputs Pro Football Reference Win Probability Calculator Output Class Reading: Chapters 6–7 in the Hidden Game of Football by Carroll, Palmer, Thorn "],["odds-and-bets.html", "Chapter 3 Odds and Bets 3.1 Odds 3.2 Gambling Odds 3.3 Types of Bets", " Chapter 3 Odds and Bets Sports Betting in USA In 2018, the United States Supreme Court overturned a 1992 federal law that banned commercial sports betting in most states. For more about this ruling, see this New York Times article: https://www.nytimes.com/2018/05/14/us/politics/supreme-court-sports-betting-new-jersey.html In Colorado, you must be at least 21 years old to gamble including betting on sports games. Gambling Addiction Gambling addiction, compulsive gambling, or gambling disorder is a serious impulse-control disorder. Here is a link to the Mayo Clinic’s discussion of compulsive gambling: https://www.mayoclinic.org/diseases-conditions/compulsive-gambling/symptoms-causes/syc-20355178 Gambling is not encouraged and can lead to numerous problems. If you choose to gamble on sports, don’t bet beyond your means and seek help if you worry that you may be suffering from gambling addiction. 3.1 Odds In the previous chapter, we quantified uncertainty using probabilities (numbers between 0 and 1) and percentages (numbers between 0 and 100). We can also quantify uncertainty using odds. Definition 3.1 The odds (in favor) of an outcome \\(A\\) is the probability of \\(A\\) divided by the probability of \\(A^C\\). \\[Odds = \\frac{p}{1-p}\\] Note: We may also be given the odds against a particular outcome. In this case, we have \\(Odds Against = \\frac{1-p}{p}\\). Some Common Odds: Odds p q Odds p q 0:1 0.000 1.000 1:0 1.000 0.000 1:1 0.500 0.500 1:1 0.500 0.500 2:1 0.667 0.333 1:2 0.333 0.667 3:1 0.750 0.250 1:3 0.250 0.750 4:1 0.800 0.200 1:4 0.200 0.800 5:1 0.833 0.167 1:5 0.167 0.833 10:1 0.909 0.091 1:10 0.091 0.909 100:1 0.990 0.010 1:100 0.010 0.990 In the following table, the odds of an outcome along with the probability of the outcome, p, and the probability of the outcome’s complement, q=1-p are given. Example 3.1 For the following examples, convert between probability and odds. Suppose that the probability that the Cubs win the 2025 World Series is 0.03. What are the odds in favor? Suppose that the odds that the Rockies win the World Series in 2025 is 100:1. What is the probability in favor? Suppose there is a 1% chance that CSU wins a national championship in any sport in the next decade. What are the probability and the odds against CSU winning a national championship in the next decade? Example 3.2 Suppose that there are three finalists in an Olympic competition. It is estimated that Athlete A has a 50% chance of winning, Athlete B has a 40% chance of winning, and Player C has a 10% chance of winning. Calculate the odds against each of the athletes winning the competition. 3.2 Gambling Odds Here’s a helpful resource on calculating gambling odds: https://www.actionnetwork.com/education/decimal-odds Gambling odds are a bit different that odds in a probability context. Gambling odds tell the amount that the bookmaker will pay out for a winning bet. For example, if a bookmaker is offering “10:1” that the Rockies win the next World Series, the bookmaker will pay out 10x the original wager plus the original wager if the Rockies win the World Series and the bookmaker will keep the original bet if the Rockies fail to win the World Series. Definition 3.2 The implied probability, \\(\\tilde{p}\\), of a wager is the probability that corresponds to the odds of the wager. \\[\\tilde{p} = \\frac{Odds}{Odds+1}\\] Definition 3.3 Fractional odds are common in horse racing and quote the net total that will be paid out to the bettor, should he or she win, relative to the stake. The numerator and denominator of fractional odds are always positive integers. For example, a $100 wager on a “5:1” bet would result in a payout of \\(5 \\cdot \\$100 + \\$100 = \\$600\\) if the wager is correct and a payout of $0 if the wager is incorrect. Definition 3.4 Decimal Odds represent the multiplier of a winning bet and is calculated by taking the inverse of the implied probability. For instance, if you bet $100 with decimal odds of 1.8, your payout is $180 ($100 wager + $80 winnings). \\[Decimal \\, Odds = [\\tilde{p}]^{-1}\\] 3.3 Types of Bets Definition 3.5 A moneyline bet are common bets in American sports. When the moneyline is positive, the figure tells what the winning payout would be on a $100 bet. When the moneyline is negative, the figure tells what wager is required for a winning payout of $100. Example 3.3 For the following scenarios, assume a wager of $100. Calculate the payout for a winning bet. Fractional odds of 4/1 Moneyline +400 Moneyline -300 Decimal Odds of 1.5 Definition 3.6 A moneyline bet refers to the odds of a straight-up outcome on a game without consideration of a point spread. Typically, favorites will have negative moneyline odds and underdogs will have a positive moneyline odds. If ML is negative: \\[\\tilde{p} = \\frac{-ML_{NEG}}{-ML_{NEG}+100}\\] If ML is positive: \\[\\tilde{p} = \\frac{100}{ML_{POS}+100}\\] Example 3.4 Calculate the implied probabilities for the following examples. Fractional odds of 4/1 Moneyline -125 Moneyline +125 Decimal Odds of 1.5 Example 3.5 Suppose that for an upcoming NFL game, a moneyline wager on the Broncos is -105 and a moneyline wager on the Raiders is -120. Calculate the implied probabilities of the two possible outcomes. (Note that sometime ties are an optional wager. Other times, ties will result in a push, that is, no winner.) What is the sum of the implied probabilities? Does the result from (b) violate the axioms of probability? If so, why? Note: The goal of bookmaking is to make money, so there will be almost certainly be a house advantage. This means that the sum of the implied probabilities will be greater than 1. Definition 3.7 The house advantage (or hold percentage) is the percentage of money that sportsbooks keep for every dollar earned. \\[House \\, Advantage = 100 \\cdot \\sum_{i=1}^n \\tilde{p}_i - 100\\] Example 3.6 Suppose that a bookmaker is offering a moneyline wager on the Broncos at -105 and a moneyline wager on the Raiders at -120. Calculate the bookmakers expected winnings based on the following amounts of total bets. $500 wagered on the Broncos, $500 wagered on the Raiders $250 wagered on the Broncos, $750 wagered on the Raiders $750 wagered on the Broncos, $250 wagered on the Raiders $0 wagered on the Broncos, $1000 wagered on the Raiders $1000 wagered on the Broncos, $0 wagered on the Raiders What is the house advantage? Example 3.7 A point spread bet is a bet based on the projected margin of victory that can result in a win, loss, or push. For example, if a sportsbook offers Rockies -1.5 against the Cubs and you bet on the Rockies, if the Rockies win by 2 or more runs, you win and if the Rockies win by 1 run or lose, then you lose. Example 3.8 Suppose a sportsbook offers Broncos +14 against the Raiders at -110 (they also offer Raiders -14 at -110) and you have $20 to wager. Calculate the payout for the following scenarios. You bet $20 on the Broncos and the final score is Broncos 21 Raiders 20. What is your payout? You bet $20 on the Raiders and the final score is Broncos 21 Raiders 20. What is your payout? You bet $10 on the Broncos and $10 on the Raiders and the final score is Broncos 21 Raiders 20. What is your payout? Example 3.9 A parlay bet is a combination of multiple bets where the winnings from a winning bet are placed on other bets. All bets must be win for the parlay bet to pay out. Example 3.10 Suppose that CSU is a three point favorite (-3) against CU in a women’s basketball game and the over/under on total number of points is 97. Assume that the price of bets is -110. Suppose you place two bets, CSU -3 and Over 97, and the outcome of the game is CSU 60 CU 40. What is your payout? Suppose you place a parlay bet on CSU -3 and Over 97 and the outcome of the game is CSU 60 CU 40. What is your payout? Suppose you place two bets, CSU -3 and Over 97, and the outcome of the game is CSU 44 CU 40. What is your payout? Suppose you place a parlay bet on CSU -3 and Over 97 and the outcome of the game is CSU 44 CU 40. What is your payout? Reference: https://www.wikihow.com/Calculate-Odds Class Reading: Chapters 44 in the Mathletics by Wayne Winston "],["monte-carlo-simulation.html", "Chapter 4 Monte Carlo Simulation 4.1 Basics 4.2 Estimating Probabilities 4.3 Simulating Streaks 4.4 Gambling Simulations 4.5 Simulating Censored Data", " Chapter 4 Monte Carlo Simulation 4.1 Basics Monte Carlo Simulation is a collection of computer-driven, computational algorithms that use repeated random sampling to calculate estimates. The basic steps for such a simulation are as follows: Set seed for replicability Initialize all variables/vectors Loop through “n” simulations and save simulated values Analyze the simulated values from the “n” simulations One function that will be particularly useful for simulation is set.seed(). set.seed() allows us to replicate any simulation by giving the initial seed for the simulation. The actual number that is “seeded” is not particularly important though if you want to replicate the same simulations, you will want to re-use this number. Example 4.1 Simulate 10 overtime coin tosses with and without using set.seed() and compare the results # Sample 1 sample(c(&quot;H&quot;,&quot;T&quot;),size=10,prob=c(0.5,0.5),replace=T) ## [1] &quot;H&quot; &quot;T&quot; &quot;H&quot; &quot;H&quot; &quot;H&quot; &quot;T&quot; &quot;T&quot; &quot;T&quot; &quot;H&quot; &quot;T&quot; # Sample 2 sample(c(&quot;H&quot;,&quot;T&quot;),size=10,prob=c(0.5,0.5),replace=T) ## [1] &quot;T&quot; &quot;T&quot; &quot;T&quot; &quot;H&quot; &quot;H&quot; &quot;T&quot; &quot;T&quot; &quot;T&quot; &quot;H&quot; &quot;H&quot; # Sample 3 set.seed(2020) sample(c(&quot;H&quot;,&quot;T&quot;),size=10,prob=c(0.5,0.5),replace=T) ## [1] &quot;H&quot; &quot;T&quot; &quot;H&quot; &quot;T&quot; &quot;T&quot; &quot;T&quot; &quot;T&quot; &quot;T&quot; &quot;T&quot; &quot;H&quot; # Sample 4 set.seed(2020) sample(c(&quot;H&quot;,&quot;T&quot;),size=10,prob=c(0.5,0.5),replace=T) ## [1] &quot;H&quot; &quot;T&quot; &quot;H&quot; &quot;T&quot; &quot;T&quot; &quot;T&quot; &quot;T&quot; &quot;T&quot; &quot;T&quot; &quot;H&quot; Simulation can be very helpful when you want to estimate quantities that are not easily solved using analytical methods like formulas. Example 4.2 Shaquille O’Neal has a career free throw percentage of 52.7%. Suppose that Shaq takes 10 free throw shots. What is the probability that he makes all 10 shots? In this case, we can calculate the exact probability of interest using binomial random variable. dbinom(x=10,size=10,prob=0.527) ## [1] 0.001652366 In more complicated simulations, there may not be an easy formula to use to calculate the value of interest. In these situations, simulation can be very helpful in estimating quantities. set.seed(2020) # Number of Simulations n.sims &lt;- 10000 # Initialize FT variable with 10000 zeros FT &lt;- rep(0,n.sims) for(i in 1:n.sims){ # Simulate 10 free throws temp &lt;- sample(x=c(0,1), size = 10, replace = T, prob = c(0.473,0.527) ) # Count the number of free throws made and store them in FT FT[i] &lt;- sum(temp) } prob10 &lt;- sum(FT == 10)/n.sims; prob10 ## [1] 0.0023 prob10 &lt;- mean(FT == 10); prob10 ## [1] 0.0023 The estimated probability that Shaq goes 10-for-10 in free throw attempts based on his career average is 0.0023. FT %&gt;% as.data.frame() %&gt;% ggplot(aes(x=FT)) + geom_bar() + ggtitle(&quot;Number of free throws made out of 10&quot;) + scale_x_continuous(breaks = seq(0, 10, by = 2)) If we run the simulation again with a different seed, we will get another estimate (0.0019). set.seed(1) # Number of Simulations n.sims &lt;- 10000 # Initialize FT variable with 10000 zeros FT &lt;- rep(0,n.sims) for(i in 1:n.sims){ # Simulate 10 free throws temp &lt;- sample(x=c(0,1), size = 10, replace = T, prob = c(0.473,0.527) ) # Count the number of free throws made and store them in FT FT[i] &lt;- sum(temp) } (prob10 &lt;- mean(FT == 10)) ## [1] 0.0019 As we increase the number of simulations, the estimate will become more accurate. set.seed(1) # Number of Simulations n.sims &lt;- 100000 # Initialize FT variable with 10000 zeros FT &lt;- rep(0,n.sims) for(i in 1:n.sims){ # Simulate 10 free throws temp &lt;- sample(x=c(0,1), size = 10, replace = T, prob = c(0.473,0.527) ) # Count the number of free throws made and store them in FT FT[i] &lt;- sum(temp) } (prob10 &lt;- mean(FT==10)) ## [1] 0.00174 One way to simulate data is to make assumptions about the distributions of the underlying data. The random variables given in the last chapter are possible candidates. 4.2 Estimating Probabilities We can use simulation to estimate probabilities of different events occurring. One way to do this is for each simulation to record a “1” if the event of interest occurs and a “0” if the event of interest does not occur. Definition 4.1 The indicator function, \\(I(A)\\), is defined such that \\(I(A)\\) is equal to 1 if \\(A\\) occurs and is equal to 0 if \\(A\\) does not occur. For instance, suppose we roll a die and a “6” is on top. Then we have the following: \\(I(6)=1, I(5)=0, I(even)=1, I(odd)=0\\). One way to calculate probabilities is to use the following rule: \\(P(A) = E[I(A)]\\). The probability that \\(A\\) occurs is equal to the expected value of the indicator function of \\(A\\). Example 4.3 During the 2021 WNBA season, Kahleah Copper of the Chicago Sky had a free throw percentage of 81.8%. She played a total of 32 games and the probability mass function for number of free throw attempts per game are given in the table below. Estimate the probability that Copper did not make a free throw in a game. Note: Copper did not make a free throw in 6 out of the 32 games for a probability of 0.1875. FTA nFTA p(FTA) 0 5 0.156 1 2 0.062 2 8 0.250 3 0 0.000 4 7 0.219 5 2 0.062 6 4 0.125 7 2 0.062 8 2 0.062 set.seed(2020) n.sims &lt;- 10000 games &lt;- 32 FTprob &lt;- 0.818 FTA &lt;- 0:8 nFTA &lt;- c(5,2,8,0,7,2,4,2,2) pFTA &lt;- nFTA/32 FT &lt;- rep(0, n.sims) FT0.ind &lt;- rep(0,n.sims) # Simulate the number of FTA per game FTA.sim &lt;- sample(x = FTA,size = n.sims,replace = T,prob = pFTA) # Simulate 10,000 games and record number of FT made for(i in 1:n.sims){ FT[i] &lt;- rbinom(n=1,size = FTA.sim[i],prob = FTprob) } # Look at the header of the simulated data head(FT) ## [1] 6 3 0 0 1 1 # Create indicator function for 0 FT made FT0.ind = FT == 0 head(FT0.ind) ## [1] FALSE FALSE TRUE TRUE FALSE FALSE # Calculate the probability via mean of the indicator function mean(FT0.ind) ## [1] 0.1711 Example 4.4 The number of regulation goals scored in a game by Hockey Team A, \\(X\\), is a Poisson(4) random variable, and the same for Hockey Team B, \\(Y\\), is a Poisson(3.2) random variable. A statistician is interested in the probability that Team A defeats Team B in regulation. This is \\(P(X&gt;Y)\\) which is difficult to calculate manually. However, using simulation, we can straightforwardly obtain an accurate estimation of this quantity. There are many built-in functions in R that allow users to generate realizations from common probability distributions (rnorm, rbinom, rexp, etc.) Let’s use the rpois function to simulate the appropriate variables, remembering to set a seed so that our results are easily replicable. set.seed(2022) n.sims &lt;- 10000 team_A_goals &lt;- rpois(n = n.sims, lambda = 4) team_B_goals &lt;- rpois(n = n.sims, lambda = 3.2) Now, to find \\(P(X &gt; Y)\\), we can use the following line of code: mean(team_A_goals &gt; team_B_goals) ## [1] 0.5415 Why does this work? First, operations to vectors are executed elementwise, meaning that R compares team_A_goals[1] to team_B_goals[1], then team_A_goals[2] to team_B_goals[2], and so on. Second, logical operators are stored as zeroes (when the condition is false) and ones (when the condition is true). The mean of a vector of zeroes and ones is the proportion of ones, which is the frequency of the logical statement being true. In our simulation, it was 0.5415. The true value is 0.5427, meaning that the simulation was quite accurate. Example 4.5 In baseball, hitting for the cycle requires a hitter to get a single, double, triple, and home run in the same game. This is a rare occurrence in professional baseball having happened only 339 times at present count. On August 10, 2009, Colorado Rockie Troy Tulowitzki hit for the cycle against the Cubs at Coors Field in Denver going 5-for-5 with two singles, one double, one triple, and one home run. Here’s a video recap: https://www.youtube.com/watch?v=sTU6ice3ga0 Simulate 100,000 games (5 at-bats per game) for Tulowitzki based on his career numbers and use them to estimate the probability that Tulowitzki hits for the cycle. Tulowitzki’s career totals are: 4804 at-bats, 878 singles, 264 doubles, 24 triples, and 225 home runs. set.seed(2022) n.sims &lt;- 100000 n.ab &lt;- 5 cycle.ind &lt;- rep(0,n.sims) # Possible outcomes: 0 = out/walk, 1 = single, 2 = double, 3 = triple, 4 = HR x &lt;- 0:4 px &lt;- c(3413,878,264,24,225)/4804 tulo &lt;- data.frame(x,px) for( i in 1:n.sims){ game &lt;- sample(x = tulo$x, prob = tulo$px, size = n.ab, replace = T) cycle &lt;- (1 %in% game) &amp; (2 %in% game) &amp; (3 %in% game) &amp; (4 %in% game) if( cycle ){ cycle.ind[i] &lt;- 1 } } mean(cycle.ind) ## [1] 0.00024 4.3 Simulating Streaks Streaks are often of interest to casual sports fans. Some especially famous streaks include Joe DiMaggio’s 56-game hitting streak in 1941, Wayne Gretzky’s 51 consecutive games with a point in 1983-1984, and the Chicago Cubs 108 year World Series drought. Simulation can be helpful in quantifying the likelihood of different kinds of streaks like winning streaks or hitting streaks. 4.3.1 Winning Streak Simulation Example 4.6 Suppose an NBA team is in the middle of a rebuild and has a 25% probability of winning each of its games in the following 82-game season. What is the probability that the team will go on at least one winning streak of four or more games over the course of the 82-game season? Use simulation to answer this question. We can simulate a season for the team, find the longest winning streak in that season, and store it in a vector. After repeating that process 10,000 times, we can then find the proportion of the values in that vector that are greater than or equal to 4. set.seed(2022) n.sims &lt;- 10000 n.games &lt;- 82 win.prob &lt;- 0.25 longest_streak &lt;- rep(NA, n.sims) for (i in 1:n.sims) { game_results &lt;- rbinom(size = 1, n = n.games, prob = win.prob) # 1=win, 0=loss streaks &lt;- rle(game_results) longest_streak[i] &lt;- max(streaks$lengths[streaks$values==1]) } table(longest_streak) ## longest_streak ## 1 2 3 4 5 6 7 8 9 ## 116 3626 4233 1480 410 105 21 7 2 mean(longest_streak &gt;= 4) ## [1] 0.2025 The team had a 4+ game winning streak in about 20% of the simulations. 4.3.2 Hitting Streak Simulation In 1941, New York Yankee Joe DiMaggio had a 56-game hitting streak which is an all-time record in MLB. How unlikely was such an outcome? Background videos on DiMaggio’s 56 game hitting streak: https://www.youtube.com/watch?v=Y5K49dtOKmo https://www.youtube.com/embed/BErlc16YS8A Example 4.7 Let’s build a simulation to estimate the probability of a hitting streak of at least 56 games using DiMaggio’s statistics. DiMaggio’s 1941 game log is contained in dimaggio41.csv. dimaggio &lt;- read_csv(&quot;data/dimaggio41.csv&quot;, col_names = TRUE) names(dimaggio) ## [1] &quot;Rk&quot; &quot;Gtm&quot; &quot;Date&quot; &quot;Opp&quot; &quot;Rslt&quot; &quot;PA&quot; &quot;AB&quot; &quot;R&quot; &quot;H&quot; &quot;2B&quot; ## [11] &quot;3B&quot; &quot;HR&quot; &quot;RBI&quot; &quot;BB&quot; &quot;IBB&quot; &quot;SO&quot; &quot;HBP&quot; &quot;SH&quot; &quot;SF&quot; &quot;ROE&quot; ## [21] &quot;GDP&quot; &quot;SB&quot; &quot;CS&quot; &quot;BA&quot; &quot;OBP&quot; &quot;SLG&quot; &quot;OPS&quot; &quot;BOP&quot; &quot;aLI&quot; &quot;WPA&quot; ## [31] &quot;acLI&quot; &quot;cWPA&quot; &quot;RE24&quot; &quot;Pos&quot; nrow(dimaggio) ## [1] 140 dimaggio %&gt;% select(1:13) %&gt;% slice(1:10,139:140) %&gt;% kt() Rk Gtm Date Opp Rslt PA AB R H 2B 3B HR RBI 1 1 Apr 14 WSH W3-0 4 4 0 2 0 1 0 1 2 2 Apr 15 PHA L1-3 4 4 1 2 1 0 0 0 3 3 Apr 16 PHA L7-10 5 5 1 4 2 0 1 2 4 4 Apr 17 PHA W9-4 5 4 2 2 0 0 0 0 5 5 Apr 18 WSH L4-7 4 4 1 1 0 0 0 1 6 6 Apr 19 WSH W5-2 5 5 1 1 0 0 1 2 7 7 Apr 20 PHA W19-5 6 5 4 3 0 0 1 6 8 8 Apr 21 PHA W14-4 6 5 3 4 1 0 1 2 9 9 Apr 22 PHA L5-6 4 3 1 0 0 0 0 0 10 10 Apr 23 BOS W4-2 5 4 0 0 0 0 0 1 139 156 Sep 28 WSH L0-5 4 4 0 1 1 0 0 0 NA NA NA NA 90-47 622 541 122 193 43 11 30 125 DiMaggio played in 139 games, had 622 plate appearances, 541 at-bats, and 193 hits. # remove last row (totals) dimaggio &lt;- dimaggio %&gt;% slice(1:139) # Create indicator variable for a hit hit.game &lt;- ifelse(dimaggio$H &gt; 0,1,0) # Use rle to calculate the streak lengths streaks &lt;- rle(hit.game) table(streaks) %&gt;% kt() 0 1 1 5 2 2 4 3 3 4 2 4 0 2 5 0 1 7 0 1 8 0 1 16 0 1 56 0 1 As seen above, DiMaggio had a 56-game hitting streak. An impossible feat to match? Create a histogram for DiMaggio’s per game plate appearances and at bats. (Hint: for discrete values, geom_bar() is often a good option.) library(gridExtra) p1 &lt;- dimaggio %&gt;% ggplot(aes(x=PA)) + geom_bar() + scale_x_continuous(breaks=0:10) + ggtitle(&quot;DiMaggio Plate Appearances Per Game, 1941&quot;) + xlab(&quot;Plate Appearances&quot;) p2 &lt;- dimaggio %&gt;% ggplot(aes(x=AB)) + geom_bar() + scale_x_continuous(breaks=0:10) + ggtitle(&quot;DiMaggio At-Bats Per Game, 1941&quot;) + xlab(&quot;At-Bats&quot;) grid.arrange(p1, p2, ncol = 1) Create a frequency and percentage frequency table for plate appearances and at-bats. library(janitor) table.pa = tabyl(dimaggio,PA) %&gt;% adorn_totals(&quot;row&quot;) %&gt;% adorn_pct_formatting(digits = 1) names(table.pa) = c(&quot;Plate Appearances&quot;, &quot;Frequency&quot;, &quot;Percent&quot;) table.pa %&gt;% kt() Plate Appearances Frequency Percent 2 2 1.4% 3 4 2.9% 4 70 50.4% 5 56 40.3% 6 5 3.6% 7 1 0.7% 9 1 0.7% Total 139 100.0% table.ab = tabyl(dimaggio,AB) %&gt;% adorn_totals(&quot;row&quot;) %&gt;% adorn_pct_formatting(digits = 1) names(table.ab) = c(&quot;At-Bats&quot;, &quot;Frequency&quot;, &quot;Percent&quot;) table.ab %&gt;% kt() At-Bats Frequency Percent 2 7 5.0% 3 37 26.6% 4 63 45.3% 5 30 21.6% 6 1 0.7% 8 1 0.7% Total 139 100.0% DiMaggio had 193 hits in 622 plate appearances over 139 games. We will simulate DiMaggio’s season of 139 games 100,000 times to estimate the probability of a 56-game hitting streak. There are many ways to do this. Let’s use the empirical probability mass function of his per game plate appearances to simulate the number of plate appearances that he gets in his 139 games. pa &lt;- tabyl(dimaggio,PA) %&gt;% select(1,2) pa &lt;- pa %&gt;% as.data.frame() %&gt;% mutate(Prob=n/139) pa %&gt;% kt() PA n Prob 2 2 0.014 3 4 0.029 4 70 0.504 5 56 0.403 6 5 0.036 7 1 0.007 9 1 0.007 # One simulated season of per game plate appearances sim.pa &lt;- sample(x=pa$PA,prob = pa$Prob,size=139,replace=T) sim.pa ## [1] 4 4 4 9 4 4 4 5 2 5 5 5 4 5 4 4 4 4 4 4 5 5 4 5 9 7 4 4 5 5 5 5 5 5 6 4 5 ## [38] 4 5 4 5 5 4 4 5 4 5 7 2 5 4 5 4 4 4 4 4 5 4 4 4 5 6 4 4 5 4 4 5 4 5 6 4 5 ## [75] 4 4 4 4 5 4 5 4 5 4 5 3 5 5 3 5 4 2 4 5 4 4 4 4 5 5 4 5 5 4 5 5 4 5 5 5 4 ## [112] 5 4 4 4 5 4 5 4 4 4 4 5 5 4 4 5 5 4 5 4 4 4 4 5 4 4 5 4 # DiMaggio Simulation set.seed(2022) n.sims &lt;- 10000 n.games &lt;- 139 prob.hit &lt;- 0.310 longest.streak &lt;- rep(0, n.sims) sim.games &lt;- rep(0,n.games) for( i in 1: n.sims){ sim.pa &lt;- sample(x=pa$PA,prob = pa$Prob,size=n.games,replace=T) for( j in 1:n.games){ sim.games[j] &lt;- rbinom(n = 1,size = sim.pa[j],prob = prob.hit) } sim.hits &lt;- ifelse(sim.games &gt; 0,1,0) streaks &lt;- rle(sim.hits) longest.streak[i] &lt;- max(streaks$lengths[streaks$values==1]) } # table of longest streaks during simulated seasons table(longest.streak) ## longest.streak ## 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ## 3 11 38 127 306 510 756 811 908 920 807 790 685 595 474 421 333 272 258 186 ## 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 ## 142 139 100 81 68 45 51 28 22 16 13 23 14 11 7 1 5 3 4 5 ## 46 47 48 49 50 56 58 59 ## 2 2 2 1 1 1 1 1 longest.streak %&gt;% as.data.frame() %&gt;% ggplot(aes(x=longest.streak)) + geom_histogram(binwidth=2) + ggtitle(&quot;Longest Hitting Streak for 10,000 Simulated DiMaggio 1941 Seasons&quot;) + xlab(&quot;Max Hitting Streak in a Simulation Season&quot;) # statistics for 10,000 simulations (mean(longest.streak)) ## [1] 17.2849 (mean(longest.streak&gt;=56)) ## [1] 3e-04 Running the simulation above with set.seed(2022) and n.sims=10000, we get \\(P(Streak \\geq 66) = 3 \\cdot 10^{-4}\\). There were three simulated hitting streaks of at least 56 games. If we run the simulation again with set.seed(2022) but increase n.sims=100000, we get \\(P(Streak \\geq 66) = \\frac{10}{100000} = 10^{-4}\\). In other words, we estimate the probability that DiMaggio gets a hitting streak of at least 56 games in 100000 simulated seasons is about 1-in-10000. # statistics for 100,000 simulations (mean(longest.streak)) ## [1] 17.1655 (mean(longest.streak&gt;=56)) ## [1] 1e-04 We would prefer to not use nested for loops, as they are slow. Can you find a faster simulation method? Let’s try simulating by permuting DiMaggio’s games. In other words, let’s randomly order DiMaggio’s 1941 games and analyze the hitting streaks. # Create indicator variable for a hit hit.game &lt;- ifelse(dimaggio$H &gt; 0,1,0) set.seed(2022) n.sims &lt;- 100000 longest.streak &lt;- rep(0, n.sims) for( i in 1: n.sims){ sim.hits &lt;- sample(x=hit.game,replace=F) streaks &lt;- rle(sim.hits) longest.streak[i] &lt;- max(streaks$lengths[streaks$values==1]) } longest.streak %&gt;% as.data.frame() %&gt;% ggplot(aes(x=longest.streak)) + geom_histogram(binwidth=2) + ggtitle(&quot;Longest Hitting Streak for 100,000 Simulated DiMaggio 1941 Seasons&quot;) + xlab(&quot;Max Hitting Streak in a Simulation Season&quot;) # statistics for 100,000 simulations (mean(longest.streak)) ## [1] 18.25769 (mean(longest.streak&gt;=56)) ## [1] 7e-05 Using this simulation method with reordering, there is an estimated probability of \\(7 \\cdot 10^{-5}\\) or about 1-in-14000 chance of DiMaggio hitting a 56-game hit streak. Other authors have used different simulation and mathematical methods for estimating the rarity of Dimaggio’s 56 game hitting streak. Billie et al (2010) used an at-bat rather than plate appearance simulation and estimated the likelihood as 1-in-5000. Rothman et al (2010) estimated the likelihood as 1-in-10000. Example 4.8 Let’s consider a more general simulation for hitting streaks. Suppose a hitter with a 0.300 batting average plays 140 games and has an equal likelihood of 3, 4, or 5 at-bats in a game. Simulate 10,000 seasons for this hitter, calculate the average max hitting streak, and the overall max hitting streak. After this, repeat the process for a hitter with a 0.400 batting average. # 0.300 Hitter Hitting Streak Simulation set.seed(2022) n.sims &lt;- 10000 n.games &lt;- 140 prob.hit &lt;- 0.300 longest.streak &lt;- rep(0, n.sims) sim.games &lt;- rep(0,n.games) for( i in 1: n.sims){ sim.pa &lt;- sample(x=3:5,size=n.games,replace=T) for( j in 1:n.games){ sim.games[j] &lt;- rbinom(n = 1,size = sim.pa[j],prob = prob.hit) } sim.hits &lt;- ifelse(sim.games &gt; 0,1,0) streaks &lt;- rle(sim.hits) longest.streak[i] &lt;- max(streaks$lengths[streaks$values==1]) } longest.streak %&gt;% as.data.frame() %&gt;% ggplot(aes(x=longest.streak)) + geom_histogram(binwidth=2) + ggtitle(&quot;Longest Hitting Streak for 10,000 Simulated Seasons (0.300 AVG hitter)&quot;) + xlab(&quot;Max Hitting Streak in a Simulation Season&quot;) # statistics for 10,000 simulations (0.300 batting average) (mean(longest.streak)) ## [1] 13.9355 (max(longest.streak)) ## [1] 42 # statistics for 10,000 simulations (0.400 batting average) (mean(longest.streak)) ## [1] 23.1349 (max(longest.streak)) ## [1] 85 4.4 Gambling Simulations Simulation can be very helpful and useful in evaluating betting systems in (sports) gambling. 4.4.1 Martingale System One such famous betting system is called a martingale system. Under this system, the bettor makes an initial wager. If they lose, they make the same wager. If they lose again, they follow a double or nothing procedure. This means that the bettor will continue betting the amount they have lost until they eventually win and get back even. What is wrong with this system? Example 4.9 Suppose you are betting on sports matches on the spread where there is no house advantage, so all bets are 1:1 and each team is equally likely to win. You begin by wagering $1 and you lose the initial bet (call it Bet Zero). You decide to employee the martingale system. Calculate the expected number of bets that you would have to make to break even. Also, create a histogram for the the biggest deficits in the simulations. set.seed(2022) n.sims &lt;- 10000 sim.bets &lt;- rep(NA,n.sims) max.deficit &lt;- rep(NA,n.sims) for( i in 1:n.sims ){ bets &lt;- 1 while( 1 ){ if( runif(1) &lt; 0.5 ){ bets &lt;- bets + 1 } else { break; } } sim.bets[i] &lt;- bets } mean(sim.bets) ## [1] 2.0003 max(sim.bets) ## [1] 13 sim.bets %&gt;% as.data.frame() %&gt;% ggplot(aes(x=sim.bets)) + geom_histogram(breaks=0:15) + ggtitle(&quot;Simulated Number of Money Bets to Break Even&quot;) + xlab(&quot;Number of Bets&quot;) On average, two bets were needed to be placed after Bet Zero to break even. In two simulations (out of 10,000 total simulations), 12 bets were needed to be made to break even after the initial failed bet, Bet Zero. The first bet after Bet Zero was for $1. The second failed bet was from $2. The twelfth bet was for \\(\\$2^{11} = \\$2048\\). If your total bankroll was $1000, you wouldn’t have been even able to make the twelfth bet to break even. The weakness of the martingale system is that you are only guaranteed (with probability 1) to break even if you have an infinite bankroll. The distribution in this example should look familiar. It is the geometric distribution. Let’s plot the probability mass function for a Geometric(0.5) random variable and calculate the probability that 12 or more bets are required to break even. ggplot(transform(data.frame(x=c(0:15)), y=dgeom(x, prob = 0.5)), aes(x, y)) + geom_bar(stat=&quot;identity&quot;) + ggtitle(&quot;Probability mass function of Geometric(0.5) random variable&quot;) + labs(x=&quot;Value&quot;, y=&quot;Frequency&quot;, ) # recall that R counts the number of failures before a success, # so we will be looking for at least 11 failures pgeom(q=11,prob=0.5,lower.tail=F) ## [1] 0.0002441406 There is a 0.02% chance that we will need to make 12 or more wagers. In other words, if your bankroll is $1000, there is a 0.02% you lose the full bankroll before you can break even. 4.4.2 Gambler’s Ruin The previous example is an ideal case where there is no house advantage. Sportsbooks will always have a house advantage, so it is more practical to consider an example where there is house advantage. For example, a point spread bet at -110 for two evenly matched teams will offer the sportsbook a house advantage. Example 4.10 Suppose you have a bankroll of $1000 and place $20 bets on point spread bets at -110. You will stop if you ever have less than $20. Assume that both teams are equally likely to beat the spread. How long will your bankroll last? Calculate your expected bankroll after 10 bets, 100 bets, and 1000 bets. We’ll use the following code and run simulations with total.bets = 10, 100, 1000, 10000. set.seed(2022) n.sims &lt;- 10000 bankroll.end &lt;- rep(0,n.sims) # betting info bankroll.start &lt;- 1000 wager &lt;- 20 ml &lt;- -110 total.bets &lt;- 10 implied.prob &lt;- (-ml)/(-ml+100) dec.odds &lt;- 1/implied.prob profit &lt;- wager * (dec.odds - 1) for(i in 1:n.sims){ bets &lt;- 0 bankroll &lt;- bankroll.start while(bankroll &gt;= 20 &amp;&amp; bets &lt; total.bets){ bets &lt;- bets + 1 if( runif(1) &lt; 0.5 ){ bankroll &lt;- bankroll + profit } else bankroll &lt;- bankroll - 20 } bankroll.end[i] &lt;- bankroll } mean.ending.bankroll &lt;- mean(bankroll.end) max.ending.bankroll &lt;- max(bankroll.end) data.frame(mean.ending.bankroll,max.ending.bankroll) %&gt;% kt() bankroll.end %&gt;% as.data.frame() %&gt;% ggplot(aes(x=bankroll.end)) + geom_histogram(binwidth=100) + ggtitle(&quot;Simulated Bankroll (starting at $1000) after 10 bets&quot;) + xlab(&quot;Bankroll after 10 bets&quot;) Number of Bets Mean Ending Bankroll Max Ending Payroll 10 990.111 1181.818 100 908.583 1596.364 1000 278.584 2496.364 All bettors eventually go broke under this scenario due to the house advantage. This is called the concept of Gambler’s Ruin. A gambler playing a game with negative expected value will eventually go broke, regardless of their betting system. See Wikipedia for further details: https://en.wikipedia.org/wiki/Gambler's_ruin 4.4.3 Simulating a Winning System Example 4.11 Suppose your betting system allows you pick winners on the spread 55% of the time. If you are betting at -110, then your probability exceeds the implied probability of 52.4% and this system is not guaranteed to be an eventual loser. Repeat the simulation above with the new probability of winning a wager and 1,000 total bets. set.seed(2022) n.sims &lt;- 10000 bankroll.end &lt;- rep(0,n.sims) # betting info bankroll.start &lt;- 1000 wager &lt;- 20 ml &lt;- -110 total.bets &lt;- 1000 implied.prob &lt;- (-ml)/(-ml+100) dec.odds &lt;- 1/implied.prob profit &lt;- wager * (dec.odds - 1) for(i in 1:n.sims){ bets &lt;- 0 bankroll &lt;- bankroll.start while(bankroll &gt;= 20 &amp;&amp; bets &lt; total.bets){ bets &lt;- bets + 1 if( runif(1) &lt; 0.55 ){ bankroll &lt;- bankroll + profit } else bankroll &lt;- bankroll - 20 } bankroll.end[i] &lt;- bankroll } mean.bankroll &lt;- mean(bankroll.end) max.bankroll &lt;- max(bankroll.end) median.bankroll &lt;- median(bankroll.end) prob.zero &lt;- mean(bankroll.end &lt;= 20) data.frame(prob.zero,mean.bankroll,median.bankroll,max.bankroll) %&gt;% kt() prob.zero mean.bankroll median.bankroll max.bankroll 0.002 2001.857 2000 4290.909 bankroll.end %&gt;% as.data.frame() %&gt;% ggplot(aes(x=bankroll.end)) + geom_histogram(binwidth=100) + ggtitle(&quot;Simulated Bankroll (starting at $1000) after 1000 bets&quot;) + xlab(&quot;Bankroll after 1000 bets&quot;) 4.4.4 Using the Kelly Growth Criterion Example 4.12 Suppose your betting system allows you pick winners on the spread 55% of the time. If you are betting at -110, then your probability exceeds the implied probability of 52.4% and this system is not guaranteed to be an eventual loser. The Kelly Growth Criterion is a formula for an optimal size of a bet when the expected returns are known. The formula is as follows: \\[f = \\frac{p}{LoseMult} - \\frac{q}{WinMult}\\] Calculate \\(f\\) and use this value in the previous simulation. How does the results of this simulation differ from the previous fixed bet simulation? set.seed(2022) n.sims &lt;- 10000 bankroll.end &lt;- rep(0,n.sims) # betting info bankroll.start &lt;- 1000 ml &lt;- -110 total.bets &lt;- 1000 implied.prob &lt;- (-ml)/(-ml+100) dec.odds &lt;- 1/implied.prob profit &lt;- wager * (dec.odds - 1) f = 0.055 for(i in 1:n.sims){ bets &lt;- 0 bankroll &lt;- bankroll.start while(bankroll &gt; 0 &amp;&amp; bets &lt; total.bets){ wager &lt;- bankroll * f bets &lt;- bets + 1 if( runif(1) &lt; 0.55 ){ bankroll &lt;- bankroll + wager*10/11 } else bankroll &lt;- bankroll - wager } bankroll.end[i] &lt;- bankroll } mean.bankroll &lt;- mean(bankroll.end) max.bankroll &lt;- max(bankroll.end) median.bankroll &lt;- median(bankroll.end) prob.zero &lt;- mean(bankroll.end &lt;= 20) data.frame(f,prob.zero,mean.bankroll,median.bankroll,max.bankroll) %&gt;% kt() f prob.zero mean.bankroll median.bankroll max.bankroll 0.055 0.001 16017.59 3966.691 4153581 bankroll.end %&gt;% as.data.frame() %&gt;% ggplot(aes(x=log10(bankroll.end))) + geom_histogram(bins=30) + ggtitle(&quot;Simulated Bankroll (starting at $1000) after 1000 bets&quot;) + xlab(&quot;Log10 Bankroll after 1000 bets&quot;) Example 4.13 Repeat the previous simulation for \\(f=0.01, f=0.1, f=0.3\\) f prob.zero mean.bankroll median.bankroll max.bankroll 0.01 0 1650.297 1575.793 5558.73 f prob.zero mean.bankroll median.bankroll max.bankroll 0.055 0.001 16017.59 3966.691 4153581 f prob.zero mean.bankroll median.bankroll max.bankroll 0.1 0.075 196920.1 1558.97 509186795 f prob.zero mean.bankroll median.bankroll max.bankroll 0.3 0.995 11988.19 0 108298711 4.5 Simulating Censored Data In 1994, major league baseball players went on strike and the season ended prematurely. Most teams played about 115 games out of the scheduled 162 game season. What might have happened in the remainder of the season? There are two individual statistics are particularly of interest. Tony Gwynn of the San Diego Padres was batting 0.394 when the strike occurred. The last time that a player hit 0.400 in a season was 1941 for MLB (Ted Williams, 0.406) and 1948 for the Negro League (Artie Wilson, 0.435). Matt Williams of the San Francisco Giants had 43 home runs when the strike occurred. At the time, the single season home run record was 61 by Roger Maris of the New York Yankees in 1961. We will use simulation to estimate the probability that these players would match these records. 4.5.1 Tony Gwynn 1994 Batting Average Simulation The San Diego Padres had played 117 games when the strike ended the season in 1994. Tony Gwynn had a batting average of 0.394, 475 plate appearances, 419 at-bats, and 165 hits over 110 games at that point. Assume that Gwynn would play in all remaining games for the season. Video: https://www.youtube.com/watch?v=irr-JblLOZM How many at-bats was Gwynn expected to have in the remainder of the season? n.season = 162 n.partial = 117 n.hits = 165 (n.remain = n.season - n.partial) ## [1] 45 ab = 419 ab.remain = ab/n.partial*n.remain ab.remain = round(ab.remain); ab.remain ## [1] 161 Gwynn was expected to have about 161 more at-bats in the remainder of the 45 cancelled games. Assuming that Gwynn’s hitting ability stayed constant for the remainder of the season, estimate the probability that his average would exceed 0.400. avg = 0.394 n.sims = 10000 sim.hits = rbinom(n=n.sims,size=ab.remain,prob=avg) sim.hits.total = n.hits + sim.hits sim.avg = sim.hits.total/(ab+ab.remain) mean(sim.avg &gt;= 0.400) ## [1] 0.3118 For more discussion on this issue, see: https://www.complex.com/sports/2016/07/tony-gwynn-would-have-hit-400-1994 4.5.2 Matt Williams 1994 Home Run Simulation The San Francisco Giants had played 115 games when the strike ended the season in 1994. Matt Williams had hit 43 homeruns in 483 plate appearances in 112 games at that point. Assume that Williams would play in all remaining games for the season. Video: https://www.youtube.com/watch?v=wVkBu---RKw How many plate appearances was Williams expected to have in the remainder of the season? n.season = 162 n.partial = 115 n.hr = 43 (n.remain = n.season - n.partial) ## [1] 47 ab = 483 ab.remain = ab/n.partial*n.remain ab.remain = round(ab.remain); ab.remain ## [1] 197 Williams was expected to have about 197 more plate appearances in the remainder of the 47 cancelled games. He would need to hit 18 home runs to match Maris and 19 or more to beat Maris. Estimate the probability that Matt Williams would have beaten Maris’ single season home run record. hr.avg = n.hr/ab n.sims = 10000 sim.hr = rbinom(n=n.sims,size=ab.remain,prob=hr.avg) sim.hr.total = n.hr + sim.hr mean(sim.hr.total &gt;= 62) ## [1] 0.4 For more discussion on this issue, see: https://www.mlb.com/news/matt-williams-1994-home-run-chase "],["inferential-statistics.html", "Chapter 5 Inferential Statistics 5.1 Defining a Population 5.2 Statistical Inference 5.3 Inference for Population Mean 5.4 Inference for Population Proportion 5.5 Bootstrap 5.6 Margin of Error Calcuations 5.7 One Sample and Two Sample t-tests and confidence intervals 5.8 Permutation Tests 5.9 Bootstrap", " Chapter 5 Inferential Statistics 5.1 Defining a Population For team and individual statistics in sports, we often split data up by the seasons. For statistical inference, we need to define what the population is and what the sample is. It is acceptable to define a season as the population and a subset of the season as a sample, but this is usually not exactly what we want to do. Instead, we often think of a season as a random sample from a theoretical population of all possible seasons. In the same manner, we can think of individual games are a random sample from a theoretical population of all possible games. 5.2 Statistical Inference Definition 5.1 Statistical Inference is the process of inferring properties of a population by use of sample data. For statistical inference, we need a point estimator and a measure of uncertainty. We will focus on statistical inference for population means and population proportions. We will examine two methods of Statistical Inference: Confidence Intervals Hypothesis Tests For sports data, we often want to infer properties of a player’s (or team’s) underlying ability on a game or season level. 5.2.1 Confidence Intervals Definition 5.2 A confidence interval gives a range of plausible values for a population parameter. Confidence intervals can be one-sided or two-sided. Different Types of Confidence Intervals There are three different types of hypothesis tests. Left-tailed confidence interval   Right-tailed confidence interval   Two-tailed confidence interval   How to Interpret a confidence interval 5.2.2 Hypothesis Tests The goal of a hypothesis test is to test competing claims about a population parameter. In other words, we want to determine if the sample data are consistent with the null hypothesis which is our initial assumption regarding the population parameter of interest. Definition 5.3 The null hypothesis, denoted \\(H_0\\), is the claim that is initially assumed to be true. Definition 5.4 The alternative hypothesis, denoted \\(H_a\\), is the assertion contradictory to \\(H_0\\) (“the opposite of \\(H_0\\)”). The null hypothesis will be rejected in favor of the alternative hypothesis if the sample evidence suggests that \\(H_0\\) is false. The two possible conclusions of a hypothesis test are Reject \\(H_0\\) or Fail to Reject \\(H_0\\). Rules for formulating hypotheses \\(H_0\\) contains “=” \\(H_a\\) contains \\(\\neq\\), \\(&gt;\\), \\(&lt;\\) Usually, the claim we are attempting to show is more plausible is \\(H_a\\) Different Types of Hypothesis Tests There are three different types of hypothesis tests. Left-tailed test   Right-tailed test   Two-tailed test   Errors in Hypothesis Testing After collecting a sample, we will decide which hypothesis is supported by the data. Since we don’t know the true parameter value, there is a chance we will make an error. Two Types of Errors in Hypothesis Testing Type I error (\\(\\alpha\\)): Reject \\(H_0\\) when \\(H_0\\) is true. Type II error (\\(\\beta\\)): Fail to reject \\(H_0\\) when \\(H_0\\) is false. Note: \\(\\alpha\\) is also called the level of significance for a test. Six Steps for Hypothesis Testing Different textbooks will give a different number of steps or outline on how to complete a hypothesis test. For our class, stick to the following method. Step 1: State the hypotheses. Step 2: Determine the level of significance. Step 3: Compute a test statistic. Step 4: Calculate a p-value. Step 5: Make a statistical decision. Step 6: Interpret the statistical decision (in the context of the problem). 5.3 Inference for Population Mean Theorem 5.1 A random sample from an infinite population with mean \\(\\mu\\) and variance \\(\\sigma^2\\) has the following properties: \\(E[\\bar{X}] = \\mu\\) \\(Var(\\bar{X}) = \\frac{\\sigma^2}{n}\\) \\(\\hat{SE}(\\bar{X}) = \\frac{s}{\\sqrt{n}}\\) 5.3.1 Confidence Interval for Population Mean Definition 5.5 The confidence interval for a population mean \\(\\mu\\) with sample mean \\(\\bar{x}\\) and sample variance \\(s^2\\) is given by: \\(\\bar{x} \\pm t_{c.v.}\\frac{s}{\\sqrt{n}}, \\, df=n-1\\), where \\(t_{c.v.}\\) denotes the critical value for a t-distribution with \\(df=n-1\\) degrees of freedom for the required confidence level. Example 5.1 In Michael Jordan’s third season, 1986–1987, he had a career best with an average of 37.1 points per game (standard deviation: 9.92) while playing an average of 40.0 minutes per game over 82 games. Data for Jordan’s 1986–1987 season are given in jordan86-87.csv. Video highlights from Michael Jordan’s 1986–1987 season: https://www.youtube.com/watch?v=cWSrUhhR3DA Let \\(\\mu\\) be the true point scoring ability of Michael Jordan during his 1986–1987 season. Create a 95% two-sided confidence interval for \\(\\mu\\). jordan86_87 &lt;- read_csv(&quot;data/jordan86-87.csv&quot;) jordan86_87 %&gt;% summarize( Games = n(), `Points Mean`= mean(PTS), `Points SD` = sd(PTS), `Minutes Mean` = mean(MP), `Minutes SD` = sd(MP)) %&gt;% kable(booktabs=T,digits = 2) Games Points Mean Points SD Minutes Mean Minutes SD 82 37.09 9.92 40.01 4.44 library(infer) jordan86_87 %&gt;% t_test(response=PTS,conf_int = 0.95) %&gt;% kable(booktabs=T,digits = 2) statistic t_df p_value alternative estimate lower_ci upper_ci 33.84 81 0 two.sided 37.09 34.9 39.27 5.3.2 Hypothesis Test for Population Mean Definition 5.6 The test statistic for a population mean \\(\\mu\\) with sample mean \\(\\bar{x}\\) and sample variance \\(s^2\\) is given by: \\(t_{test} = \\frac{\\bar{x}-\\mu}{s/\\sqrt{n}} \\sim t_{n-1}\\) Example 5.2 Wilt Chamberlain is considered one of the greatest of all-time in basketball and he had a career year in the 1961–1962 season. Data for Chamberlain’s 1961–1962 season are given in wilt61-62.csv. On March 2, 1962, Wilt Chamberlain scored 100 points in a single game. He also averaged 50.4 points per game (standard deviation: 12.0 points) while playing an average of 48.5 minutes per game over 80 games. Background videos on Wilt Chamberlain: https://www.youtube.com/watch?v=LxMeEzhvNRs https://www.youtube.com/watch?v=1WsCtyLGg1w Let \\(\\mu\\) be Wilt’s true point scoring ability in 1961–1962. Test the claim that \\(\\mu &gt; 50\\) PPG at \\(\\alpha=0.10\\). wilt61_62 &lt;- read_csv(&quot;data/wilt61-62.csv&quot;) wilt61_62 %&gt;% summarize( Games = n(), `Points Mean`= mean(PTS), `Points SD` = sd(PTS), `Minutes Mean` = mean(MP), `Minutes SD` = sd(MP)) %&gt;% kable(booktabs=T,digits = 2) Games Points Mean Points SD Minutes Mean Minutes SD 80 50.36 11.99 48.52 2.5 wilt61_62 %&gt;% t_test(response=PTS,mu=50,alternative = &quot;greater&quot;) %&gt;% kable(booktabs=T,digits = 2) statistic t_df p_value alternative estimate lower_ci upper_ci 0.27 79 0.39 greater 50.36 48.13 Inf 5.3.3 Test for Difference in Means Theorem 5.2 The test statistic for a difference in population means \\(\\mu_1 - \\mu_2\\) is given by: \\(t_{test} = \\frac{\\bar{x}_1 -\\bar{x}_2 - D_0}{\\sqrt{\\frac{s_1^2}{n_1}+\\frac{s_2^2}{n_2}}} \\sim t_{\\nu}\\) where \\(\\nu = \\frac{\\big(s_1^2/n_1 + s_2^2/n_2\\big)^2}{(s_1^2/n_1)^2/(n_1-1) + (s_2^2/n_2)^2/(n_2-1)}\\) 5.3.4 Confidence Interval for Difference in Means Theorem 5.3 The confidence interval for a difference in population means \\(\\mu_1 - \\mu_2\\) is given by: \\((\\bar{x}_1 - \\bar{x}_2) \\pm t_{c.v.} \\sqrt{\\frac{s_1^2}{n_1}+\\frac{s_2^2}{n_2}}\\) where \\(t_{c.v.}\\) denotes the critical value for a t-distribution with \\(df=\\nu\\) degrees of freedom for the required confidence level and \\(\\nu = \\frac{\\big(s_1^2/n_1 + s_2^2/n_2\\big)^2}{(s_1^2/n_1)^2/(n_1-1) + (s_2^2/n_2)^2/(n_2-1)}\\) Example 5.3 NBA statistics are often given as a rate statistic per 36 minutes to account for differences in playing time. Compare points per game (PPG) and points per 36 minutes (PP36) on a season level for Jordan’s 1986–1987 season and Chamberlain’s 1961–1962 season. wilt_pp36 &lt;- sum(wilt61_62$PTS)/sum(wilt61_62$MP)*36 jordan_pp36 &lt;- sum(jordan86_87$PTS)/sum(jordan86_87$MP)*36 data.frame(`Wilt PPG` = mean(wilt61_62$PTS), `Jordan PPG` = mean(jordan86_87$PTS), `Wilt PP36` = wilt_pp36, `Jordan PP36` = jordan_pp36) %&gt;% kable(booktabs=T,digits = 2) Wilt.PPG Jordan.PPG Wilt.PP36 Jordan.PP36 50.36 37.09 37.36 33.37 Example 5.4 Calculate PP36 on a game-by-game basis for Jordan and Chamberlain. Create a 99% confidence interval for the difference in PP36 and make a statistical decision as to if there is a difference. jordan86_87$PP36 &lt;- jordan86_87$PTS/jordan86_87$MP*36 wilt61_62$PP36 &lt;- wilt61_62$PTS/wilt61_62$MP*36 jordan_wilt &lt;- data.frame(PP36=c(jordan86_87$PP36,wilt61_62$PP36), Player=c(rep(&quot;MJ&quot;,82),rep(&quot;WC&quot;,80))) jordan_wilt %&gt;% t_test(formula=PP36~Player, order=c(&quot;WC&quot;,&quot;MJ&quot;),conf_level = 0.99) %&gt;% kable(booktabs=T,digits = 2) statistic t_df p_value alternative estimate lower_ci upper_ci 2.84 159.96 0.01 two.sided 3.87 0.32 7.42 5.4 Inference for Population Proportion Theorem 5.4 A random sample of size \\(n\\) from an infinite population with mean \\(\\pi\\) has the following properties: \\(E[\\hat{p}] = \\pi\\) \\(Var(\\hat{p}) = \\frac{\\pi(1-\\pi)}{n}\\) \\(\\hat{SE}(\\hat{p}) = \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\) 5.4.1 Confidence Interval for Population Proportion Theorem 5.5 The confidence interval for a population proportion \\(\\pi\\) with sample proportion \\(\\hat{p}\\) and sample size \\(n\\) is given by: \\(\\hat{p} \\pm z_{c.v.}\\sqrt{\\frac{p(1-p)}{n}}\\) where \\(z_{c.v.}\\) denotes the critical value for a z-distribution for the required confidence level. 5.4.2 Test for Population Proportion Theorem 5.6 The test statistic for a population proportion \\(\\pi\\) is given by: \\(z_{test} = \\frac{\\hat{p}-\\pi}{\\sqrt{\\frac{\\pi(1-\\pi)}{n}}} \\sim \\mathcal{N}(0,1)\\) Example 5.5 From Mathletics (Section 4.8): Since interleague play began in 1997, there was a suspicion that American League teams had a slight advantage since they had a full-time designate hitter on their roster. The designated hitter was approved for National League play in 2022. From 1997 until 2013, American League teams played the National League teams in 4,264 interleague games. American League teams won 2,235 of the games (52.4% winning percentage). We want to test if the true winning percentage of American League teams exceeded 50% at a significance level of 0.01. n &lt;- 4264 al &lt;- 2235 nl &lt;- n - al phat &lt;- al/n # Calculate the CI manually se &lt;- sqrt(phat*(1-phat)/n) z &lt;- qnorm(0.99) moe &lt;- z*se bound &lt;- phat-moe; bound ## [1] 0.5063636 # Calculate test statistic and p-value manually z_test &lt;- (phat-0.5)/sqrt(0.5*0.5/n) p_value &lt;- pnorm(z_test,lower.tail = F) data.frame(`Test Stat` = z_test, `P-value` = p_value) %&gt;% kable(booktabs=T,digits = 4) Test.Stat P.value 3.1547 8e-04 # Use binomial test binom.test(x=al,n=n,p=0.5,alternative = &quot;greater&quot;,conf.level = 0.99) ## ## Exact binomial test ## ## data: al and n ## number of successes = 2235, number of trials = 4264, p-value = ## 0.0008449 ## alternative hypothesis: true probability of success is greater than 0.5 ## 99 percent confidence interval: ## 0.5062306 1.0000000 ## sample estimates: ## probability of success ## 0.5241557 data &lt;- data.frame(Winner = c(rep(1,al),rep(0,nl))) data %&gt;% t_test(response=Winner,mu=0.5,conf_level = 0.99,alternative = &quot;greater&quot;) ## # A tibble: 1 × 7 ## statistic t_df p_value alternative estimate lower_ci upper_ci ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 3.16 4263 0.000800 greater 0.524 0.506 Inf 5.4.3 Confidence Interval for Difference in Proportions Theorem 5.7 The confidence interval for a difference in population proportions \\(\\pi_1 - \\pi_2\\) is given by: \\((\\hat{p}_1 - \\hat{p}_2) \\pm z_{c.v.}\\sqrt{\\frac{\\hat{p}_1(1-\\hat{p}_1)}{n_1}+\\frac{\\hat{p}_2(1-\\hat{p}_2)}{n_2}}\\) where \\(z_{c.v.}\\) denotes the critical value for a z-distribution for the required confidence level. 5.4.4 Test for Difference in Proportions Theorem 5.8 The test statistic for a difference in population proportions \\(\\pi_1 - \\pi_2\\) is given by: \\(z_{test} = \\frac{\\hat{p}_1 - \\hat{p}_2 - D_0}{\\sqrt{\\frac{\\hat{p}_1(1-\\hat{p}_1)}{n_1}+\\frac{\\hat{p}_2(1-\\hat{p}_2)}{n_2}}} \\sim \\mathcal{N}(0,1)\\) Example 5.6 Football coaches often try to “ice the kicker” before a late field goal attempt. Paul Dalen did some analysis for icing the kicker on the collegiate level: https://www.footballstudyhall.com/2018/11/24/18110091/is-icing-the-kicker-really-a-thing From his dataset that includes data from 2017–2018, we have the following: For field goal attempts that were 36–45 yards, iced kickers made 41 out of 66 attempts and non-iced kickers made 195 out of 287 attempts. Is there evidence of a difference in proportions of iced and non-iced kickers? Test the hypothesis at \\(\\alpha=0.05\\) and create a 95% confidence interval for the difference. # Iced Kickers n.ice &lt;- 66 x.ice &lt;- 41 phat.ice &lt;- x.ice/n.ice # Non-iced Kickers n.nice &lt;- 287 x.nice &lt;- 195 phat.nice &lt;- x.nice/n.nice # Calculate the 95% CI manually diff &lt;- phat.ice - phat.nice se &lt;- sqrt(phat.ice*(1-phat.ice)/n.ice + phat.nice*(1-phat.nice)/n.nice) z &lt;- qnorm(0.975) moe &lt;- z*se (bounds &lt;- c(diff-moe,diff+moe)) ## [1] -0.1871143 0.0706535 # Calculate the z-test and p-value manually z_test &lt;- diff/se p_value &lt;- 2*pnorm(z_test) data.frame(`P(Make|Ice)` = phat.ice, `P(Make|No Ice)`= phat.nice, `Test Stat` = z_test, `P-value` = p_value) %&gt;% kable(booktabs=T,digits = 4) P.Make.Ice. P.Make.No.Ice. Test.Stat P.value 0.6212 0.6794 -0.8855 0.3759 5.5 Bootstrap Bootstrapping is a resampling method with replacement that can be used to estimate margins of error, create confidence intervals, or complete statistical testing. It is particularly useful when distributional assumptions may be in doubt for standard inferential methods. A bootstrap sample is created by sampling with replacement from known sample data, calculating the statistic of interest, and then analyzing the results from all of the bootstrap samples. Example 5.7 Example from Analytic Methods in Sports (Section 4.5): In 2012, Baltimore Ravens quarterback Joe Flacco passed for 3,817 yards and had a passer rating of 87.7. We would like to build a confidence interval for Flacco’s passer rating using bootstrapping. # Load data flacco2012 &lt;- read_csv(&quot;data/flacco2012.csv&quot;,show_col_types = F) # Build Kable Table for data flacco2012 %&gt;% kable(booktabs=T,digits = 4) Game Date Opp Cmp Att Yds TD Int Rate 1 9/10/12 CIN 21 29 299 2 0 128.4 2 9/16/12 PHI 22 42 232 1 1 66.8 3 9/23/12 NWE 28 39 382 3 1 117.7 4 9/27/12 CLE 28 46 356 1 1 83.2 5 10/7/12 KAN 13 27 187 0 1 55.6 6 10/14/12 DAL 17 26 234 1 0 106.9 7 10/21/12 HOU 21 43 147 1 2 45.4 8 11/4/12 CLE 15 24 153 1 0 94.6 9 11/11/12 OAK 21 33 341 3 1 115.8 10 11/18/12 PIT 20 32 164 0 0 75.5 11 11/25/12 SDG 30 51 355 1 0 86.6 12 12/2/12 PIT 16 34 188 1 1 61.9 13 12/9/12 WAS 16 21 182 3 1 121.4 14 12/16/12 DEN 20 40 254 2 1 76.5 15 12/23/12 NYG 25 36 309 2 0 114.2 16 12/30/12 CIN 4 8 34 0 0 61.5 ALL 16 Games NA 317 531 3817 22 10 87.7 # Function to calculate passer rating rating &lt;- function(QB,ind){ dat &lt;- QB[ind,] att &lt;- sum(dat$Att) ypa &lt;- sum(dat$Yds)/att ipa &lt;- sum(dat$Int)/att cpa &lt;- sum(dat$Cmp)/att tdpa &lt;- sum(dat$TD)/att Y &lt;- 0.25 * (ypa - 3) T &lt;- 20 * tdpa I &lt;- 2.375 - 25*ipa C &lt;- 5 * (cpa-0.3) 100*(C+Y+T+I)/6 } # Remove season total row flacco2012 &lt;- flacco2012 %&gt;% slice(1:16) rating(flacco2012,1:16) ## [1] 87.74718 # Manually find bootstrap distribution and statistics n.sims &lt;- 10000 ratings &lt;- rep(NA,10000) for(i in 1:n.sims){ temp.ind &lt;- sample(1:16,16,replace=T) ratings[i] &lt;- rating(flacco2012,temp.ind) } ratings %&gt;% data.frame() %&gt;% ggplot(aes(x=.)) + geom_histogram(bins=30) + labs(x=&quot;Passer Rating&quot;,y=&quot;Count&quot;, title=&quot;Bootstrap Distribution for Flacco&#39;s QB Rating&quot;) # Bootstrap statistics (mean.pr &lt;- mean(ratings)) ## [1] 87.89389 (se.pr &lt;- sd(ratings)) ## [1] 6.482204 # Approximate CI for Passer Rating using MOE moe.pr &lt;- qnorm(0.975) * se.pr (bounds.pr &lt;- c(mean.pr-moe.pr,mean.pr+moe.pr)) ## [1] 75.1890 100.5988 # Approximate CI using middle 95% quantile(ratings,c(0.025,0.975)) ## 2.5% 97.5% ## 75.38335 100.68129 # Bootstrap using &quot;boot&quot; package library(boot) (boot.pr &lt;- boot(data=flacco2012,statistic=rating,R=10000)) ## ## ORDINARY NONPARAMETRIC BOOTSTRAP ## ## ## Call: ## boot(data = flacco2012, statistic = rating, R = 10000) ## ## ## Bootstrap Statistics : ## original bias std. error ## t1* 87.74718 0.1468445 6.364337 boot.ci(boot.out = boot.pr,type=&quot;perc&quot;) ## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS ## Based on 10000 bootstrap replicates ## ## CALL : ## boot.ci(boot.out = boot.pr, type = &quot;perc&quot;) ## ## Intervals : ## Level Percentile ## 95% ( 75.43, 100.58 ) ## Calculations and Intervals on Original Scale 5.6 Margin of Error Calcuations 5.6.1 MOE for Probabilities (Shooting percentages, batting averages, save percentage) 5.6.2 MOE for Averages (PPG, Digs per game, Passer Rating–using bootstrap) 5.6.3 MOE estimation using simulation (Durant scoring, AM, page 98) 5.7 One Sample and Two Sample t-tests and confidence intervals 5.7.1 Hockey Faceoffs (Mathletics, chapter 40 page 383) 5.7.2 Hockey Penalty Scoring (Mathletics, chapter 40, page 13) 5.7.3 NFL Overtime Winners (Scorecasting, page 192) (Mathletics, chapter 25, page 211) 5.7.4 Icing the Kicker (Scorecasting, page 211) 5.7.5 Example: Football One vs. Two Point Conversion (Mathletics, chapter 23, page 194) – discussion of “the chart” 5.7.6 Two Sample Tests (NBA Players, AM, page 103) (Comparing NL and AL, page 106) 5.8 Permutation Tests 5.9 Bootstrap library(infer) observed_statistic &lt;- wilt61_62 %&gt;% specify(response = PTS) %&gt;% calculate(stat = &quot;mean&quot;) null_dist_1_sample &lt;- wilt61_62 %&gt;% specify(response = PTS) %&gt;% hypothesize(null = &quot;point&quot;, mu = 50) %&gt;% generate(reps = 1000, type = &quot;bootstrap&quot;) %&gt;% calculate(stat = &quot;mean&quot;) "],["measures-of-association.html", "Chapter 6 Measures of Association 6.1 Pearson Correlation Coefficient 6.2 Association of Categorical Variables 6.3 Rank Correlation 6.4 Serial Correlation 6.5 Pythagorean Record", " Chapter 6 Measures of Association This chapter will examine various measures of association betweeen two or more variables. A popular measure of association is Pearson’s Correlation Coefficient for two continuous, quantitative variables. Other measures of association are more appropriate for other types of data like qualitative data. 6.1 Pearson Correlation Coefficient Definition 6.1 The Pearson correlation coefficient (also known as Pearson’s R or correlation coefficient) is a measure of linear relationship between two quantitative variables. For two random variables, \\(X\\) and \\(Y\\), the Pearson correlation coefficient, \\(\\rho\\), is: \\(\\rho = \\frac{Cov(X,Y)}{\\sigma_X \\sigma_Y}\\) For two sets of sample data, \\(\\{x_1,x_2,\\ldots,x_n\\}\\) and \\(\\{y_1,y_2,\\ldots,y_n\\}\\), the Pearson correlation coefficient is: \\(r_{xy} = \\frac{\\sum_{i=1}^n (x_i-\\bar{x})(y_i-\\bar{y})}{\\sqrt{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^n(y_i-\\bar{y})^2}}\\) Example 6.1 Download pitching data for individual pitchers in the 2022 MLB season. Investigate the correlation between common pitching statistics. library(tidyverse) library(knitr) library(baseballr) mlb22_all &lt;- bref_daily_pitcher(&quot;2022-01-01&quot;, &quot;2022-12-31&quot;) %&gt;% fip_plus() mlb22_pitch &lt;- mlb22_all %&gt;% dplyr::select(Name, IP, SO, uBB, HR, ERA, FIP) %&gt;% dplyr::arrange(dplyr::desc(IP)) mlb22_pitch %&gt;% head(n=10) %&gt;% kable(booktabs=T) Name IP SO uBB HR ERA FIP Sandy Alcantara 228.2 207 49 16 2.28 2.97 Aaron Nola 205.0 235 28 19 3.25 2.57 Miles Mikolas 202.1 153 39 25 3.29 3.87 Corbin Burnes 202.0 243 51 23 2.94 3.14 Framber Valdez 201.1 194 67 11 2.82 3.06 Gerrit Cole 200.2 257 50 33 3.50 3.47 Merrill Kelly 200.1 177 59 21 3.37 3.62 Shane Bieber 200.0 198 36 18 2.88 2.87 Alek Manoah 196.2 180 51 16 2.24 3.35 MartÃ­n PÃ©rez 196.1 169 69 11 2.89 3.26 library(GGally) mlb22_pitch %&gt;% select(-Name) %&gt;% ggpairs() library(ellipse) library(RColorBrewer) # Use of the mtcars data proposed by R data &lt;- mlb22_pitch %&gt;% select(-Name) %&gt;% cor() # Build a Pannel of 100 colors with Rcolor Brewer my_colors &lt;- brewer.pal(5, &quot;Spectral&quot;) my_colors &lt;- colorRampPalette(my_colors)(100) # Order the correlation matrix ord &lt;- order(data[1, ]) data_ord &lt;- data[ord, ord] plotcorr(data_ord, col=my_colors[data_ord*50+50], mar=c(1,1,1,1)) # Example adapted from: # https://r-graph-gallery.com/273-custom-your-scatterplot-ggplot2.html library(ggpubr) mlb22_pitch %&gt;% ggplot(aes(x=IP,y=SO)) + geom_point( color=&quot;black&quot;, fill=&quot;#69b3a2&quot;, shape=22, alpha=0.5, size=2 ) + geom_smooth(method=lm,se=F,color=&quot;black&quot;) + labs(title = &quot;Innings Pitched vs. Strikeouts&quot;, subtitle = &quot;2022 MLB Season | Individual Pitchers&quot;, caption = &quot;Data: Baseball Reference via baseballr&quot;, x = &quot;Innings Pitched (IP)&quot;, y = &quot;Strikeouts (SO)&quot;) + stat_cor(method = &quot;pearson&quot;, label.x = 155, label.y = 70) library(ggExtra) p &lt;- mlb22_pitch %&gt;% ggplot(aes(x=SO,y=ERA)) + geom_point() ggMarginal(p, type=&quot;histogram&quot;) library(RColorBrewer) color_pal &lt;- brewer.pal(n = 8, name = &quot;Dark2&quot;) p &lt;- mlb22_pitch %&gt;% filter(ERA &lt;= 10.00) %&gt;% ggplot(aes(x=SO,y=ERA)) + geom_point(alpha=0.5,color=color_pal[1]) + geom_smooth(method=&quot;lm&quot;,color=color_pal[2]) + stat_cor(method = &quot;pearson&quot;, label.x = 185, label.y = 5.8) + labs(title = &quot;Strikeouts (SO) vs. Earned Run Average (ERA)&quot;, subtitle = &quot;2022 MLB Season | Individual Pitchers&quot;, caption = &quot;Data: Baseball Reference via baseballr&quot;, x = &quot;Innings Pitched (IP)&quot;, y = &quot;Earned Run Average (ERA)&quot;) ggMarginal(p, type=&quot;histogram&quot;) ## `geom_smooth()` using formula = &#39;y ~ x&#39; ## `geom_smooth()` using formula = &#39;y ~ x&#39; ## `geom_smooth()` using formula = &#39;y ~ x&#39; mlb22_pitch %&gt;% ggplot(aes(x=ERA,y=FIP)) + geom_point(alpha=0.5,color=color_pal[1]) + scale_x_continuous(limits=c(0,5)) + scale_y_continuous(limits=c(0,5)) + labs( title = &quot;Earned Run Average (ERA) vs. Fielding Independent Pitching (FIP)&quot;, subtitle = &quot;2022 MLB Season | Individual Pitchers&quot;, caption = &quot;Data: Baseball Reference via baseballr&quot;, x = &quot;Earned Run Average (ERA)&quot;, y = &quot;Fielding Independent Pitching (FIP)&quot;) rox22_pitch &lt;- mlb22_all %&gt;% select(Name,Team,IP,H,uBB,ERA,FIP) %&gt;% filter(Team==&quot;Colorado&quot;) rox22_pitch %&gt;% arrange(desc(IP)) %&gt;% kable(booktabs=T) Name Team IP H uBB ERA FIP GermÃ¡n MÃ¡rquez Colorado 181.2 185 63 4.95 4.72 Kyle Freeland Colorado 174.2 193 53 4.53 4.21 Chad Kuhl Colorado 137.0 155 57 5.72 5.24 Austin Gomber Colorado 124.2 137 33 5.56 4.52 Ryan Feltner Colorado 97.1 102 35 5.83 4.76 Antonio Senzatela Colorado 92.1 133 23 5.07 4.06 Daniel Bard Colorado 60.1 35 24 1.79 2.81 Carlos EstÃ©vez Colorado 57.0 44 22 3.47 4.02 Jake Bird Colorado 47.2 45 20 4.91 4.79 Jhoulys ChacÃ­n Colorado 47.1 55 21 7.61 4.94 Alex ColomÃ© Colorado 47.0 57 20 5.74 4.41 Ty Blach Colorado 44.1 51 9 5.89 3.72 Lucas Gilbreath Colorado 43.0 37 26 4.19 3.53 Justin Lawrence Colorado 42.2 44 22 5.70 3.40 Tyler Kinley Colorado 24.0 21 6 0.75 1.74 Ashton Goudeau Colorado 20.1 25 10 7.08 4.95 Chad Smith Colorado 18.0 16 15 7.50 4.83 Gavin Hollowell Colorado 7.0 7 4 7.71 4.40 Jordan Sheffield Colorado 2.0 2 2 0.00 5.11 Noah Davis Colorado 1.0 3 1 18.00 15.11 Brian Serven Colorado 1.0 0 1 0.00 6.11 Randal Grichuk Colorado 1.0 0 0 0.00 3.11 rox22_pitch %&gt;% ggplot(aes(x=H,y=uBB,size=IP)) + geom_point(alpha=0.5,color=color_pal[1]) + labs(title = &quot;Colorado Rockies Pitchers: Hits Allowed vs. Unintentional Walks&quot;, subtitle = &quot;2022 MLB Season | Individual Pitchers&quot;, caption = &quot;Data: Baseball Reference via baseballr&quot;, x = &quot;Hits Allowed (H)&quot;, y = &quot;Unintentional Walks (uBB)&quot;) 6.1.1 Partial Correlation and Confounding Variables As seen in the previous example, counting statistics are often highly correlated. In particular, we may want to speculate that pitchers with poor control (high walks) tend to give up lots of hits due to poor control. This is only due to the presence of a lurking variable (innings pitched). To account for a lurking variable, one can calculate partial correlation coefficient in such situations. Example 6.2 Let \\(X,Y,Z\\) be random variables and let \\(r_{XY}\\) be the (standard) correlation coefficient between \\(X\\) and \\(Y\\). The partial correlation coefficient of \\(X\\) and \\(Y\\), controlling for \\(Z\\) is: \\(r_{XY \\bullet Z} = \\frac{r_{XY}-r_{XZ}r_{YZ}}{\\sqrt{1-r_{XZ}^2}\\sqrt{1-r_{YZ}^2}}\\) Example 6.3 Calculate the correlation between strikeouts and (unintentional) walks for pitchers with at least 20 IP during the 2022 season, with and without controlling for innings pitched. ( cor_matrix &lt;- mlb22_all %&gt;% select(H,uBB,IP) %&gt;% cor() ) ## H uBB IP ## H 1.0000000 0.8766316 0.9698289 ## uBB 0.8766316 1.0000000 0.8927844 ## IP 0.9698289 0.8927844 1.0000000 ( cor_without &lt;- cor_matrix[1,2] ) ## [1] 0.8766316 ( cor_with &lt;- (cor_matrix[1,2] - cor_matrix[1,3]*cor_matrix[2,3]) / (sqrt(1-cor_matrix[1,3]^2)*sqrt(1-cor_matrix[2,3]^2)) ) ## [1] 0.09819068 6.1.2 Properties of the Linear Correlation Coefficient Pearson’s correlation coefficient is unaffected by changes in location (adding a constant) or scale (multiplying by a constant) of data. To illustrate this concept, let’s consider the correlation between the number of points scored by the winning team of the Super Bowl and 1) the number of the Super Bowl {1, 2, 3, … , 56} and 2) the year of the Super Bowl {1967, 1968, 1969, … , 2022}. cor(Super_Bowl_Number, Winning_Team_Points) ## [1] 0.1063479 cor(Super_Bowl_Year, Winning_Team_Points) ## [1] 0.1063479 The only difference between the two plots is that the x-axis is shifted. Since the change is essentially a linear (location) transformation, the correlations are identical. Note: The correlations were equal only because there has been a one-to-one relationship between Super Bowl number and year since 1967. Major League Baseball has had years in which no World Series was held (1904 - boycott, 1994 - players’ strike); thus, the same example applied to the MLB would produce slightly different correlation coefficients. 6.2 Association of Categorical Variables While Pearson’s correlations can be used to find associations between categorical variables, there are better measures to be used. Example 6.4 (From Analytic Methods in Sports) Suppose we are given the following partial contingency table that tabulates the number of “complete games” for a starting pitcher by league. Yes No Total NL 2592 AL 2268 Total 128 4732 4860 Choose values to give the largest and smallest correlations. Example 1: Small correlation League &lt;- c(rep(0,2592),rep(1,2268)) Complete &lt;- rep(0,4860) Complete[1:68] = 1 Complete[2593:(2593+59)]=1 small_corr &lt;- data.frame(League,Complete) small_corr_table &lt;- table(small_corr) rownames(small_corr_table) = c(&quot;NL&quot;,&quot;AL&quot;) colnames(small_corr_table) = c(&quot;No&quot;,&quot;Yes&quot;) small_corr_table &lt;- small_corr_table[,c(2,1)] small_corr_table %&gt;% kable(booktabs=T,digits = 3) Yes No NL 68 2524 AL 60 2208 cor(small_corr) %&gt;% kable(booktabs=T,digits = 3) League Complete League 1.000 0.001 Complete 0.001 1.000 Example 2: Large correlation (1) Complete &lt;- rep(0,4860) Complete[1:128] = 1 large_corr1 &lt;- data.frame(League,Complete) large_corr1_table &lt;- table(large_corr1) rownames(large_corr1_table) = c(&quot;NL&quot;,&quot;AL&quot;) colnames(large_corr1_table) = c(&quot;No&quot;,&quot;Yes&quot;) large_corr1_table &lt;- large_corr1_table[,c(2,1)] large_corr1_table %&gt;% kable(booktabs=T,digits = 3) Yes No NL 128 2464 AL 0 2268 cor(large_corr1) %&gt;% kable(booktabs=T,digits = 3) League Complete League 1.000 -0.154 Complete -0.154 1.000 Example 3: Large correlation (2) Complete &lt;- rep(0,4860) Complete[2593:(2593+127)] = 1 large_corr2 &lt;- data.frame(League,Complete) large_corr2 &lt;- data.frame(League,Complete) large_corr2_table &lt;- table(large_corr2) rownames(large_corr2_table) = c(&quot;NL&quot;,&quot;AL&quot;) colnames(large_corr2_table) = c(&quot;No&quot;,&quot;Yes&quot;) large_corr2_table &lt;- large_corr2_table[,c(2,1)] large_corr2_table %&gt;% kable(booktabs=T,digits = 3) Yes No NL 0 2592 AL 128 2140 cor(large_corr2) %&gt;% kable(booktabs=T,digits = 3) League Complete League 1.000 0.176 Complete 0.176 1.000 6.2.1 Odds Ratios Let \\(X\\) and \\(Y\\) be two binary, categorical variables with the following contingency table. Yes No Total Yes a b a+b No c d c+d Total a+c b+d a+b+c+d One possible way to measure the association between two binary variables is to look at the odds ratio. Definition 6.2 The odds ratio (OR) is a measure of association between two categorical variables of \\(X\\) and \\(Y\\) and is: \\(OR = \\frac{ad}{bc}\\) \\(OR &gt; 1\\) means that \\(Y=1\\) is more likely when \\(X=1\\) than when \\(X=0\\). \\(OR &lt; 1\\) means that \\(Y=1\\) is less likely when \\(X=1\\) than when \\(X=0\\). \\(OR = 1\\) means that \\(Y=1\\) is equally likely when \\(X=1\\) than when \\(X=0\\). \\(OR\\) ranges from 0 to \\(\\infty\\) The odds ratio allows one to compare the relative likelihoods of \\(Y=1\\) given \\(X=1\\) vs. \\(X=0\\). \\(\\text{Ratio of OR} = \\frac{P(Y=1|X=1)/P(Y=0|X=1)}{P(Y=1|X=0)/P(Y=0|X=0)}\\) Example 6.5 The following contingency table summarizes complete games by league during the 2012 MLB season. Yes No NL 59 2533 AL 69 2199 Calculate the following: (a) \\(P(CG|AL)\\) (b) \\(P(CG|NL)\\) (c) \\(OR(CG)\\) 6.2.2 Yule’s Q Definition 6.3 Yule’s Q is a measure of association between two categorical variables and is defined by: \\(Q = \\frac{OR-1}{OR+1} = \\frac{ad-bc}{ad+bc}\\) \\(Q\\) ranges from -1 to 1, where \\(Q=0\\) implies no relationship between the variables. Some general guidelines: \\(Q=0\\): No association \\(|Q| &lt; 0.3\\): Weak association \\(0.3 \\leq |Q| &lt; 0.5\\): Moderate association \\(0.5 \\leq |Q| &lt; 1\\): Strong assocation \\(|Q|=1\\): Perfect association Example 6.6 Calculate Yule’s Q for the four examples (Examples 1-3 and Actual) and determine if there appears to be an association between and complete games for each of these examples Example 6.7 (From Analytic Methods in Sports) Rafael Nadal is often considered to be the best clay-court tennis player of all-time. Assess this belief by calculating Yule’s Q for the Nadal’s performances between 2008–2012. mat &lt;- data.frame(matrix(c(1660,3658,5318,863,2715,3578,2523,6373,8896),ncol=3)) rownames(mat) &lt;- c(&quot;Clay&quot;,&quot;Nonclay&quot;,&quot;Total&quot;) colnames(mat) &lt;- c(&quot;Win&quot;,&quot;Loss&quot;,&quot;Total&quot;) mat %&gt;% kable(booktabs=T) Win Loss Total Clay 1660 863 2523 Nonclay 3658 2715 6373 Total 5318 3578 8896 Example 6.8 (From Analytic Methods in Sports) Does the pass rush have an effect on Tom Brady’s performance? We can turn numerical variables into categories and calculate Yule’s Q to help us answer this question. Use the following table to calculate Yule’s Q and assess the belief that the pass rush affects Brady’s performance. Data is given for the 2009–2012 seasons mat &lt;- data.frame(matrix(c(29,18,47,22,2,24,51,20,71),ncol=3)) rownames(mat) &lt;- c(&quot;0-2 sacks&quot;,&quot;3+ sacks&quot;,&quot;Total&quot;) colnames(mat) &lt;- c(&quot;0-2 TDs&quot;,&quot;3+ TDs&quot;,&quot;Total&quot;) mat %&gt;% kable(booktabs=T) 0-2 TDs 3+ TDs Total 0-2 sacks 29 22 51 3+ sacks 18 2 20 Total 47 24 71 6.2.3 Chi-Squared Test of Independence We can formally test whether two categorical variables are related to each other by use of the Chi-Squared Test of Independence. Theorem 6.1 A Chi-Squared Test of Independence (\\(\\chi^2-test\\)) between two categorical variables has the test statistic \\(X^2\\) which follows a \\(\\chi^2(df=(r-1)(c-1))\\), where: \\(X^2 = \\sum_{i=1}^r\\sum_{j=1}^c\\frac{(E_{ij}-O_{ij})^2}{E_{ij}}\\) \\(O_{ij}\\) is the \\(i^{th}\\) row and \\(j^{th}\\) column observation count and \\(E_{ij} = \\frac{R_i \\cdot C_j}{N}\\) Note: Sometimes, a Yate’s chi-squared test (or Yate’s correction of continuity) used for 2x2 contingency tables with cell counts under 5. Under this test, the test statistic is: \\(X^2_{Yates} = \\sum_{i=1}^r\\sum_{j=1}^c\\frac{(|E_{ij}-O_{ij}|-0.5)^2}{E_{ij}}\\) Example 6.9 Complete a Chi-Squared Test of Independence for the Tom Brady TDs/Sacks example. Is there evidence of dependence between Touchdowns and Sacks? Explain. a1 &lt;- data.frame(TDs=rep(&quot;0-2&quot;,29),Sacks=rep(&quot;0-2&quot;,29)) a2 &lt;- data.frame(TDs=rep(&quot;0-2&quot;,18),Sacks=rep(&quot;3+&quot;,18)) a3 &lt;- data.frame(TDs=rep(&quot;3+&quot;,22),Sacks=rep(&quot;0-2&quot;,22)) a4 &lt;- data.frame(TDs=rep(&quot;3+&quot;,2),Sacks=rep(&quot;3+&quot;,2)) brady_data = rbind(a1,a2,a3,a4) chisq.test(table(brady_data$TDs,brady_data$Sacks)) ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: table(brady_data$TDs, brady_data$Sacks) ## X-squared = 5.6468, df = 1, p-value = 0.01749 chisq.test(table(brady_data$TDs,brady_data$Sacks),correct = F) ## ## Pearson&#39;s Chi-squared test ## ## data: table(brady_data$TDs, brady_data$Sacks) ## X-squared = 7.0499, df = 1, p-value = 0.007927 Example 6.10 Complete a Chi-Squared Test of Independence for the AL/NL complete game example. Is there evidence of dependence between League and Complete Games? Explain. a1 &lt;- data.frame(Complete=rep(&quot;No&quot;,2533),League=rep(&quot;NL&quot;,2533)) a2 &lt;- data.frame(Complete=rep(&quot;No&quot;,2199),League=rep(&quot;AL&quot;,2199)) a3 &lt;- data.frame(Complete=rep(&quot;Yes&quot;,59),League=rep(&quot;NL&quot;,59)) a4 &lt;- data.frame(Complete=rep(&quot;Yes&quot;,69),League=rep(&quot;AL&quot;,69)) mlb_data = rbind(a1,a2,a3,a4) chisq.test(table(mlb_data$Complete,mlb_data$League)) ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: table(mlb_data$Complete, mlb_data$League) ## X-squared = 2.4777, df = 1, p-value = 0.1155 chisq.test(table(mlb_data$Complete,mlb_data$League),correct=F) ## ## Pearson&#39;s Chi-squared test ## ## data: table(mlb_data$Complete, mlb_data$League) ## X-squared = 2.7684, df = 1, p-value = 0.09614 summary(table(mlb_data$Complete,mlb_data$League)) ## Number of cases in table: 4860 ## Number of factors: 2 ## Test for independence of all factors: ## Chisq = 2.7684, df = 1, p-value = 0.09614 6.3 Rank Correlation Rank correlation is a nonparametric method to measure the ordinal association between two different variables. Rank correlation can investigate non-linear relationships between variables and thus measure monotonicity. Definition 6.4 Spearman’s rank correlation coefficient or Spearman’s \\(\\rho\\) is a nonparametric measure of rank correlation and is calculated by: \\(r_s = \\frac{Cov(R(X),R(Y))}{\\sigma_{R(X)}\\sigma_{R(Y)}}\\) That is, the Spearman’s rank correlation coefficient is Pearson’s correlation between the rank values of the two variables. Example 6.11 nfl22.csv contains NFL team offense statistics for the 2022 season. Investigate the relationship between PF (points scored for) and RPCT (percentage of offensive plays that were rushes). Calculate the ranks for PF and RPCT and use these values to calculate the Spearman correlation coefficient. nfl22 &lt;- read_csv(&quot;data/nfl22.csv&quot;,show_col_types = F) nfl22 &lt;- nfl22 %&gt;% slice(1:32) nfl22 %&gt;% slice_head(n=10) %&gt;% kable(booktabs=T) Rk Tm G PF Yds Plays Pass_Att Pass_Yds Rush_Att Rush_Yds 1 Kansas City Chiefs 17 496 7032 1094 651 5062 417 1970 2 Philadelphia Eagles 17 477 6614 1124 536 4105 544 2509 3 Dallas Cowboys 17 467 6034 1114 556 3736 531 2298 4 Buffalo Bills 16 455 6361 1037 574 4129 430 2232 5 Detroit Lions 17 453 6460 1092 588 4281 480 2179 6 San Francisco 49ers 17 450 6216 1047 512 3856 504 2360 7 Minnesota Vikings 17 424 6145 1123 672 4484 404 1661 8 Cincinnati Bengals 16 418 5768 1053 610 4240 399 1528 9 Seattle Seahawks 17 407 5976 1044 573 3934 425 2042 10 Jacksonville Jaguars 17 404 6075 1072 596 3959 448 2116 nfl22 &lt;- nfl22 %&gt;% mutate(`RPCT`=100*Rush_Att/Plays) nfl22 &lt;- nfl22 %&gt;% mutate(PF_Rank = rank(PF), RPCT_Rank = rank(RPCT)) nfl22 %&gt;% select(Tm,PF,PF_Rank,RPCT,RPCT_Rank) %&gt;% slice(1:10) %&gt;% kable(booktabs=T,digits=1) Tm PF PF_Rank RPCT RPCT_Rank Kansas City Chiefs 496 32 38.1 7 Philadelphia Eagles 477 31 48.4 27 Dallas Cowboys 467 30 47.7 23 Buffalo Bills 455 29 41.5 15 Detroit Lions 453 28 44.0 19 San Francisco 49ers 450 27 48.1 26 Minnesota Vikings 424 26 36.0 3 Cincinnati Bengals 418 25 37.9 5 Seattle Seahawks 407 24 40.7 11 Jacksonville Jaguars 404 23 41.8 16 nfl22 %&gt;% select(PF,PF_Rank,RPCT,RPCT_Rank) %&gt;% cor(method = &quot;pearson&quot;) ## PF PF_Rank RPCT RPCT_Rank ## PF 1.0000000000 0.988409408 -0.02501179 0.0008416183 ## PF_Rank 0.9884094078 1.000000000 -0.01187428 0.0097158572 ## RPCT -0.0250117927 -0.011874280 1.00000000 0.9759711461 ## RPCT_Rank 0.0008416183 0.009715857 0.97597115 1.0000000000 nfl22 %&gt;% select(PF,PF_Rank,RPCT,RPCT_Rank) %&gt;% cor(method = &quot;spearman&quot;) ## PF PF_Rank RPCT RPCT_Rank ## PF 1.000000000 1.000000000 0.009715857 0.009715857 ## PF_Rank 1.000000000 1.000000000 0.009715857 0.009715857 ## RPCT 0.009715857 0.009715857 1.000000000 1.000000000 ## RPCT_Rank 0.009715857 0.009715857 1.000000000 1.000000000 Example 6.12 Investigate the relationship between PPG (points per game), RYPG (rushing yards per game), and PYPG (passing yards per game) using Spearman’s rank correlation coefficient. nfl22 &lt;- nfl22 %&gt;% mutate(PPG=PF/G,RYPG=Rush_Yds/G,PYPG=Pass_Yds/G) nfl22 %&gt;% select(PPG,RYPG,PYPG) %&gt;% cor(method = &quot;spearman&quot;) ## PPG RYPG PYPG ## PPG 1.0000000 0.2640264 0.6237052 ## RYPG 0.2640264 1.0000000 -0.4310203 ## PYPG 0.6237052 -0.4310203 1.0000000 library(GGally) nfl22 %&gt;% select(PPG,RYPG,PYPG) %&gt;% ggpairs() 6.4 Serial Correlation Another type of correlation that we can utilize to look for patterns in sports data is serial correlation. 6.4.1 Autocorrelation Definition 6.5 The autocorrelation (or serial correlation) of a sequence of outcomes is the Pearson correlation coefficient between successive outcomes or the correlation between outcomes and lag delayed outcomes. Example 6.13 Simulate three sets of Bernoulli trials (zeros and ones) of length 10000. One dataset should exhibit no serial correlation, one should exhibit positive serial correlation, and one should exhibit negative serial correlation. set.seed(2023) len &lt;- 10000 # Easy to simulate independent Bernoulli trials corr_none &lt;- sample(c(0,1),size=len,prob=c(0.5,0.5),replace=T) # initialize vectors for other two examples corr_pos &lt;- rep(0,len) corr_neg &lt;- rep(0,len) # Positive serial correlation # Notice that the probability of switching is less than 0.5 for(i in 1:10000){ if(i == 1){ corr_pos[i] &lt;- sample(c(0,1),size=1,prob=c(0.5,0.5),replace=T) } else { if(runif(1)&lt;0.8){ corr_pos[i] &lt;- corr_pos[i-1] } else { corr_pos[i] &lt;- 1-corr_pos[i-1] } } } # Negative serial correlation # Notice that the probability of switching is greater than 0.5 for(i in 1:10000){ if(i == 1){ corr_neg[i] &lt;- sample(c(0,1),size=1,prob=c(0.5,0.5),replace=T) } else { if(runif(1)&lt;0.2){ corr_neg[i] &lt;- corr_neg[i-1] } else { corr_neg[i] &lt;- 1-corr_neg[i-1] } } } # Look at first 20 values of each sequence corr_none[1:30] ## [1] 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 0 1 0 0 1 1 0 0 0 0 1 1 1 corr_pos[1:30] ## [1] 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 1 1 1 corr_neg[1:30] ## [1] 0 1 0 1 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 0 0 1 0 # Calculate mean of each sequence c(mean(corr_none),mean(corr_pos),mean(corr_neg)) ## [1] 0.5068 0.5001 0.5006 Note that all three sequences have approximately equal probability of 1 and 0, however, the serial correlation differs between them. corr_none %&gt;% acf(lag.max = 30,main=&quot;Autocorrelation of Sequence 1 (No Corr.)&quot;) library(ggplot2) library(gridExtra) library(forecast) ## Registered S3 method overwritten by &#39;quantmod&#39;: ## method from ## as.zoo.data.frame zoo ## ## Attaching package: &#39;forecast&#39; ## The following object is masked from &#39;package:ggpubr&#39;: ## ## gghistogram corr_none %&gt;% ggAcf(lag.max = 10,main=&#39;Autocorrelation of Sequence 1 (No Corr.)&#39;) acf(corr_none,lag.max=10,plot=F) ## ## Autocorrelations of series &#39;corr_none&#39;, by lag ## ## 0 1 2 3 4 5 6 7 8 9 10 ## 1.000 0.007 0.011 0.008 0.009 0.010 0.012 0.011 -0.015 0.000 0.009 corr_pos %&gt;% ggAcf(lag.max = 10,main=&#39;Autocorrelation of Sequence 2 (Positive Corr.)&#39;) acf(corr_pos,lag.max=10,plot=F) ## ## Autocorrelations of series &#39;corr_pos&#39;, by lag ## ## 0 1 2 3 4 5 6 7 8 9 10 ## 1.000 0.608 0.375 0.237 0.156 0.104 0.062 0.037 0.023 0.012 -0.008 corr_neg %&gt;% ggAcf(lag.max = 10,main=&#39;Autocorrelation of Sequence 3 (Negative Corr.)&#39;) acf(corr_neg,lag.max=10,plot=F) ## ## Autocorrelations of series &#39;corr_neg&#39;, by lag ## ## 0 1 2 3 4 5 6 7 8 9 10 ## 1.000 -0.598 0.348 -0.209 0.134 -0.084 0.060 -0.045 0.027 -0.012 0.002 6.4.2 Run Lengths Another way to investigate serial correlation is to look at the lengths of “streaks” using the rle function. t(table(rle(corr_none))) ## lengths ## values 1 2 3 4 5 6 7 8 9 10 11 12 ## 0 1276 604 289 157 66 45 27 9 9 0 1 0 ## 1 1219 622 308 150 101 46 20 9 5 2 1 1 Example 6.14 Which of the three examples has the most “streaks”? How about fewest streaks? # Use rle to calculate run lengths t(table(rle(corr_none))) ## lengths ## values 1 2 3 4 5 6 7 8 9 10 11 12 ## 0 1276 604 289 157 66 45 27 9 9 0 1 0 ## 1 1219 622 308 150 101 46 20 9 5 2 1 1 t(table(rle(corr_pos))) ## lengths ## values 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ## 0 201 153 119 91 77 69 54 51 27 32 15 19 14 9 9 5 3 6 ## 1 193 174 123 99 77 51 50 35 29 33 26 24 9 2 3 7 10 7 ## lengths ## values 19 20 21 22 23 24 25 26 27 29 30 36 ## 0 7 2 4 5 1 2 1 1 0 1 1 0 ## 1 6 5 3 1 5 2 0 1 1 0 2 1 t(table(rle(corr_neg))) ## lengths ## values 1 2 3 4 5 6 7 ## 0 3189 643 137 18 6 1 0 ## 1 3169 665 138 19 2 0 1 Example 6.15 Examine the autocorrelation function for Joe DiMaggio’s 1941 and 1942 seasons. Also, calculate the length of his streaks that season. dimaggio41 &lt;- read_csv(&quot;data/dimaggio41.csv&quot;, show_col_types = FALSE) dimaggio41 &lt;- dimaggio41 %&gt;% slice(1:139) # Create indicator variable for a hit hit.game41 &lt;- ifelse(dimaggio41$H &gt; 0,1,0) hit.game41 %&gt;% ggAcf(lag.max = 10,main=&#39;Autocorrelation of DiMaggio 1941 season&#39;) acf(hit.game41,lag.max=10,plot=F) ## ## Autocorrelations of series &#39;hit.game41&#39;, by lag ## ## 0 1 2 3 4 5 6 7 8 9 10 ## 1.000 0.364 0.070 -0.020 0.125 0.172 0.268 0.120 0.167 0.134 0.190 t(table(rle(hit.game))) ## lengths ## values 1 2 3 4 5 7 8 16 56 ## 0 5 4 4 0 0 0 0 0 0 ## 1 2 3 2 2 1 1 1 1 1 dimaggio42 &lt;- read_csv(&quot;data/dimaggio42.csv&quot;) # Create indicator variable for a hit hit.game42 &lt;- ifelse(dimaggio42$H &gt; 0,1,0) hit.game42 %&gt;% ggAcf(lag.max = 10,main=&#39;Autocorrelation of DiMaggio 1942 season&#39;) acf(hit.game42,lag.max=10,plot=F) ## ## Autocorrelations of series &#39;hit.game42&#39;, by lag ## ## 0 1 2 3 4 5 6 7 8 9 10 ## 1.000 0.055 -0.009 -0.098 0.013 -0.007 -0.035 -0.003 0.030 -0.077 0.000 t(table(rle(hit.game))) ## lengths ## values 1 2 3 4 5 7 8 16 56 ## 0 5 4 4 0 0 0 0 0 0 ## 1 2 3 2 2 1 1 1 1 1 6.4.3 Wald-Wolfowitz Runs Test Theorem 6.2 The Wald-Wolfowitz runs test is a nonparametric statistical method for testing the hypothesis of an independent sequence of binary data. \\(H_0:\\) Elements of sequence are mutually independent \\(H_a:\\) Elements of the sequence are mutually dependent Let \\(N_+\\) be the number of runs of the indicator/positive values and let \\(N_-\\) be the number of runs of the negative values. The number of runs, \\(N = N_+ + N_-\\), is approximately normally distributed with: Mean: \\(\\mu=\\frac{2N_+N_-}{N}+1\\) Variance: \\(\\sigma^2 = \\frac{2N_+N_-(2N_+N_- - N)}{N^2(N-1)}\\) Example 6.16 Complete a WW runs test for the three simulated sequences. State the conclusion of the WW hypothesis test. library(DescTools) RunsTest(corr_none) ## ## Runs Test for Randomness ## ## data: corr_none ## z = -0.65166, runs = 4967, m = 4932, n = 5068, p-value = 0.5146 ## alternative hypothesis: true number of runs is not equal the expected number RunsTest(corr_pos) ## ## Runs Test for Randomness ## ## data: corr_pos ## z = -60.853, runs = 1958, m = 4999, n = 5001, p-value &lt; 2.2e-16 ## alternative hypothesis: true number of runs is not equal the expected number RunsTest(corr_neg) ## ## Runs Test for Randomness ## ## data: corr_neg ## z = 59.733, runs = 7988, m = 4994, n = 5006, p-value &lt; 2.2e-16 ## alternative hypothesis: true number of runs is not equal the expected number Example 6.17 Complete a WW runs test for DiMaggio’s 1941 and 1942 seasons. State the conclusion of the WW hypothesis test. RunsTest(hit.game41) ## ## Runs Test for Randomness ## ## data: hit.game41 ## z = -4.2075, runs = 27, m = 25, n = 114, p-value = 2.582e-05 ## alternative hypothesis: true number of runs is not equal the expected number RunsTest(hit.game42) ## ## Runs Test for Randomness ## ## data: hit.game42 ## z = -0.59874, runs = 55, m = 38, n = 116, p-value = 0.5493 ## alternative hypothesis: true number of runs is not equal the expected number 6.4.4 Hot Hand (Scorecasting, page 215) 6.4.5 Streakiness in Sports (Mathletics, chapter 11, page 105) 6.5 Pythagorean Record Baseball statistican (sabermetrican) Bill James proposed Pythagorean expectation to estimate the percentage (or number) of games that a team is expected to win based on the number of runs they score and the number of runs they allow. Definition 6.6 The (basic) Pythagorean expectation for a team’s win percentage and win total are given by the following: \\[\\text{Pythagorean Win Pct} = PythWin\\% = 100 * \\frac{RS^2}{RS^2 + RA^2}\\] \\[\\text{Pythagorean Win Total} = PythWin = N \\cdot \\frac{RS^2}{RS^2 + RA^2}\\] where for a given team, \\(N\\) is the number of games, \\(RS\\) is the number of runs scored, and \\(RA\\) is the number of runs allowed. Note that \\(RS\\) and \\(RA\\) can be based on season totals or per game averages. Example 6.18 In 2022, the Colorado Rockies baseball team scored an average of 4.3 runs per game and allowed an average of 5.4 runs per game. The Rockies’ record in 2022 was 69-94 (0.420 win pct). Calculate the Pythagorean win percentage and win total. Did the Rockies underperform or overperform based on these results? \\(PythWin\\% = 100 * \\frac{RS^2}{RS^2+RA^2} = \\frac{4.3^2}{4.3^2+5.4^2} = 38.8\\%\\) \\(PythWin\\% = N \\cdot \\frac{RS^2}{RS^2+RA^2} = 162 * \\frac{4.3^2}{4.3^2+5.4^2} = 63\\) ( pythwinpct = 100*(4.3^2)/(4.3^2+5.4^2) ) ## [1] 38.80378 ( pythwins = 162*(4.3^2)/(4.3^2+5.4^2) ) ## [1] 62.86212 It turns out that we can find a more optimal estimate of Pythagorean wins by using an exponent different from 2. For example, Baseball Reference (https://www.sports-reference.com/blog/baseball-reference-faqs/) uses an exponent of 1.83. Definition 6.7 The (general) Pythagorean expectation for a team’s win percentage and win total are given by the following: \\[\\text{Pythagorean Win Pct} = PythWin\\% = 100 * \\frac{RS^n}{RS^2 + RA^n}\\] \\[\\text{Pythagorean Win Total} = PythWin = N \\cdot \\frac{RS^n}{RS^n + RA^n}\\] where for a given team, \\(N\\) is the number of games, \\(RS\\) is the number of runs scored, and \\(RA\\) is the number of runs allowed. \\(n\\) is optimized for predictive accuracy over a large dataset. It will be helpful to have a function to find the optimal Pythagorean exponent. Such a function called pyth_opt is given below that minimizes mean squared error. Use plot_flag=1 to generate a plot. pyth_opt = function(RS,RA,WinPct,digits,plot_flag){ exps = seq(0,15,by=10^(-digits)) n_exps = length(exps) MSE = rep(NA,n_exps) for(i in 1:n_exps){ temp_exp = exps[i] PyWinPct = RS^temp_exp/(RS^temp_exp + RA^temp_exp) MSE[i] = mean((PyWinPct-WinPct)^2) } min_idx = which(MSE==min(MSE)) pyth_opt = exps[min_idx] if(plot_flag){ df = data.frame(Exponent=exps,MSE=MSE) df %&gt;% ggplot(aes(x=Exponent,y=MSE)) + geom_line() + geom_point(data=df[min_idx,],color=&quot;blue&quot;) + geom_label(data = df[min_idx,], aes(x = Exponent, y = MSE, label = Exponent),vjust=-0.5) } else { return(pyth_opt) } } Example 6.19 Final season MLB standings and related statistics are given in mlb_2022.csv. Find the optimal value of \\(n\\) that minimizes mean squared error between actual wins and Pythagorean wins. mlb_2022 = read_csv(&quot;data/mlb_2022.csv&quot;) mlb_2022 %&gt;% slice(1:10) %&gt;% kable(booktabs=T,digits = 4) Team W L W-L% R RA Rdiff pythWL Los Angeles Dodgers 111 51 0.685 5.2 3.2 2.1 116-46 Houston Astros 106 56 0.654 4.5 3.2 1.4 106-56 Atlanta Braves 101 61 0.623 4.9 3.8 1.1 100-62 New York Mets 101 61 0.623 4.8 3.7 1.0 99-63 New York Yankees 99 63 0.611 5.0 3.5 1.5 106-56 St. Louis Cardinals 93 69 0.574 4.8 3.9 0.8 95-67 Cleveland Guardians 92 70 0.568 4.3 3.9 0.4 88-74 Toronto Blue Jays 92 70 0.568 4.8 4.2 0.6 91-71 Seattle Mariners 90 72 0.556 4.3 3.8 0.4 89-73 San Diego Padres 89 73 0.549 4.4 4.1 0.3 86-76 pyth_opt(mlb_2022$R,mlb_2022$RA,mlb_2022$`W-L%`,2,1) Example 6.20 For a more accurate estimate of the optimal Pythagorean exponent, use all MLB final standings data from 2000–2017. This is contained in mlb_standings_long.csv. mlb_long = read_csv(&quot;data/mlb_standings_long.csv&quot;) mlb_long %&gt;% slice_head(n = 3) %&gt;% kable(booktabs=T,digits = 4) yearID lgID teamID G W L R RA RD Wpct 2000 AL ANA 162 82 80 864 869 -5 0.5062 2000 NL ARI 162 85 77 792 754 38 0.5247 2000 NL ATL 162 95 67 810 714 96 0.5864 mlb_long %&gt;% slice_tail(n = 3) %&gt;% kable(booktabs=T,digits = 4) yearID lgID teamID G W L R RA RD Wpct 2017 AL TEX 162 78 84 799 816 -17 0.4815 2017 AL TOR 162 76 86 693 784 -91 0.4691 2017 NL WAS 162 97 65 819 672 147 0.5988 pyth_opt(mlb_long$R,mlb_long$RA,mlb_long$Wpct,2,1) As previously mentioned, sabermetricans tend to use PyExp = 1.83 for MLB. Example 6.21 Create a scatterplot to compare Team Wins and Team Pythagorean Wins in 2022 and calculate the correlation. mlb_2022 = mlb_2022 %&gt;% mutate(PyWins=162*R^1.83/(R^1.83+RA^1.83)) mlb_2022 %&gt;% ggplot(aes(x=W,y=PyWins)) + geom_point() + labs(x=&quot;Wins&quot;) + geom_abline(intercept=0, slope=1, color=&quot;blue&quot;, linetype=&quot;dashed&quot;) cor(mlb_2022$W,mlb_2022$PyWins) ## [1] 0.9764977 Example 6.22 The Rockies scored 4.31 runs per game and allowed 5.4 runs per game in 2022. Did the Rockies underperform or overperform based on their Pythagorean record? mlb_2022 %&gt;% filter(Team==&quot;Colorado Rockies&quot;) %&gt;% mutate(PyWins = 162*4.31^1.83/(4.31^1.83+5.39^1.83)) %&gt;% kable(booktabs=T,digits = 4) Team W L W-L% R RA Rdiff pythWL PyWins Colorado Rockies 68 94 0.42 4.3 5.4 -1.1 65-97 64.6548 The Rockies won 68 games and were expected to win 65 games based on their Pythagorean record. The Rockies outperformed their Pythagorean record. Example 6.23 Calculate the Pythagorean exponent for NFL using 2022 season totals. This data is contained in nfl_2022.csv. nfl_2022 = read_csv(&quot;data/nfl_2022.csv&quot;) nfl_2022 %&gt;% slice_head(n=5) %&gt;% kable(booktabs=T,digits = 4) Team W L T W-L% PF PA Buffalo Bills* 13 3 0 0.813 455 286 Miami Dolphins+ 9 8 0 0.529 397 399 New England Patriots 8 9 0 0.471 364 347 New York Jets 7 10 0 0.412 296 316 Cincinnati Bengals* 12 4 0 0.750 418 322 pyth_opt(nfl_2022$PF,nfl_2022$PA,nfl_2022$`W-L%`,2,1) For 2022, there is an optimal Pythagorean exponent of 3.38. Using a larger dataset of more seasons will give a better estimate. Football Outsiders (https://www.footballoutsiders.com/stat-analysis/2017/presenting-adjusted-pythagorean-theorem) uses PyExp = 2.37 for NFL. Similar analyses can be done for other sports as well. PyExp = 13.91 is often used for NBA and PyExp = 2.15 for NHL. "],["data-acquisition.html", "Chapter 7 Data Acquisition 7.1 Tabular Data From Sports Reference 7.2 Downloading Datasets From Internet 7.3 Importing Data Using R Libraries 7.4 Data Scraping", " Chapter 7 Data Acquisition There are many ways to acquire sports data to analyze in R. These include: Manually typing data into a spreadsheet Downloading pre-formatted tabular data from (https://www.sports-reference.com/) Downloading datasets from various internet sources Importing data using R libraries Scraping data from internet websites This chapter will explore these various methods of acquiring data and will also review data visualization and summaries. We will typically use ggplot for visualization and kable for data tables. The R Graph Gallery (http://r-graph-gallery.com/) is a nice resource for visualizations using ggplot. 7.1 Tabular Data From Sports Reference All tabular data on Sports Reference (https://www.sports-reference.com/) can be easily downloaded though a little bit of data wrangling and cleaning is required to prepare the data. Once you have navigated to the page that you want to download data from, click Share &amp; Export, and select Get table as CSV (for Excel). This will generate comma-separated data that you can copy and paste into your favorite text editor. Get table in CSV format Copy data and save as .csv Example 7.1 Acquire the Scoring Regular Season dataset for the Colorado Avalanche 2021–2022 season. This data is located on this webpage: https://www.hockey-reference.com/teams/COL/2022.html. Once the data has been collected, using data wrangling and cleaning methods to transform the dataset into an easier to use format. Use this dataset to explore the relationship between goals, assists, OPS (offensive point shares), and DPS (defensive point shares). # Load data after collection avs21 &lt;- read_csv(&quot;data/avs21.csv&quot;) # Take a look at the first five rows and first five columns avs21 %&gt;% slice_head(n=5) %&gt;% select(1:5) %&gt;% kable(booktabs=T) …1 …2 …3 …4 …5 Rk Player Age Pos GP 1 Mikko Rantanen 25 RW 75 2 Nathan MacKinnon 26 C 65 3 Nazem Kadri 31 C 71 4 Cale Makar 23 D 77 # Remove unnecessary first row during loading avs21 &lt;- read_csv(&quot;data/avs21.csv&quot;,skip = 1) # Select columns of interest avs21 &lt;- avs21 %&gt;% select(Player,G,A,OPS) # Take a look at the first five rows avs21 %&gt;% slice_head(n=5) %&gt;% kable(booktabs=T) Player G A OPS Mikko Rantanen 36 56 7.9 Nathan MacKinnon 32 56 7.7 Nazem Kadri 28 59 7.2 Cale Makar 28 58 8.5 Andre Burakovsky 22 39 4.3 # Make sure to eliminate any extra rows like &quot;Team Totals&quot; avs21 &lt;- avs21 %&gt;% slice(1:n()-1) # Let&#39;s also remove all players that did not have a goal and an assist avs21 &lt;- avs21 %&gt;% filter(G&gt;0 &amp; A &gt;0) Histogram avs21 %&gt;% ggplot(aes(x=G)) + geom_histogram(binwidth = 2,color=&quot;white&quot;,fill=&quot;steelblue&quot;) + labs(x=&quot;Goals&quot;,y=&quot;Count&quot;,title=&quot;Colorado Avalanche Player Goal Counts, 2021-2022 season&quot;) Density plot avs21 %&gt;% ggplot(aes(x=OPS)) + geom_density(fill=&quot;#6F263D&quot;) + labs(x=&quot;Offensive Point Shares (OPS)&quot;,y=&quot;Density&quot;,title=&quot;Colorado Avalanche Player OPS Density, 2021-2022 season&quot;) Scatterplot with Linear Fit avs21 %&gt;% ggplot(aes(x=G,y=OPS)) + geom_point() + geom_smooth(method=lm , fill=&quot;steelblue&quot;, color=&quot;#6F263D&quot;, se=TRUE) + labs(x=&quot;Goals&quot;,y=&quot;Offensive Point Shares (OPS)&quot;,title=&quot;Colorado Avalanche Player Goals and OPS, 2021-2022 season&quot;) Scatterplot with LOESS Smoother avs21 %&gt;% ggplot(aes(x=A,y=OPS)) + geom_point(alpha=0.8,color=&quot;steelblue&quot;) + geom_smooth(method=loess, color=&quot;#6F263D&quot;, se=FALSE) + labs(x=&quot;Assists&quot;,y=&quot;Offensive Point Shares (DPS)&quot;,title=&quot;Colorado Avalanche Player OPS and DPS, 2021-2022 season&quot;) Correlation Matrix Plot library(GGally) avs21 %&gt;% select(-Player) %&gt;% ggpairs() 7.2 Downloading Datasets From Internet We can directly download datasets from the internet if we have a valid url to the datset. Example 7.2 Game-by-game data for the CSU volleyball team is available at: https://aaron-nielsen.github.io/csu_volleyball.csv Download this data and create some visualizations. # Load data from URL url &lt;- &quot;https://aaron-nielsen.github.io/csu_volleyball.csv&quot; csu_vb = read_csv(url,show_col_types = F) # Look at first ten rows and columns csu_vb %&gt;% select(1:10) %&gt;% slice(1:10) %&gt;% kable(booktabs=T) Date Opponent W/L SP K E TA PCT AST SA 8/25/17 Duke L 5 66 28 179 0.212 64 5 8/26/17 Central Florida W 4 56 18 126 0.302 52 7 8/29/17 Northern Colorado W 3 39 8 77 0.403 38 5 9/1/17 vs TCU W 5 62 20 149 0.282 59 6 9/1/17 vs UNC Asheville W 3 41 7 80 0.425 39 8 9/2/17 at Florida State W 3 48 12 95 0.379 45 6 9/8/17 Ball State W 4 59 24 145 0.241 56 6 9/8/17 Michigan W 3 48 8 101 0.396 46 3 9/10/17 Idaho State W 3 46 11 92 0.380 46 4 9/15/17 UAlbany W 3 41 7 73 0.466 36 5 Correlogram # Example adapted from: http://r-graph-gallery.com/97-correlation-ellipses.html # Libraries library(ellipse) library(RColorBrewer) # Use of the mtcars data proposed by R data &lt;- csu_vb %&gt;% select(-(1:3)) %&gt;% cor() # Build a Pannel of 100 colors with Rcolor Brewer my_colors &lt;- brewer.pal(5, &quot;Spectral&quot;) my_colors &lt;- colorRampPalette(my_colors)(100) # Order the correlation matrix ord &lt;- order(data[1, ]) data_ord &lt;- data[ord, ord] plotcorr(data_ord, col=my_colors[data_ord*50+50], mar=c(1,1,1,1)) Correlation Matrix Plot csu_vb %&gt;% select(-(1:3)) %&gt;% ggcorr(method = c(&quot;everything&quot;, &quot;pearson&quot;)) Boxplot csu_vb %&gt;% ggplot(aes(x=`W/L`, y=PCT, fill=`W/L`)) + geom_boxplot(alpha=0.3) + theme(legend.position=&quot;none&quot;) + labs(x=&quot;Match Result&quot;,y=&quot;Hitting Percentage&quot;) + scale_x_discrete(limits = c(&quot;W&quot;, &quot;L&quot;),labels=c(&quot;Wins&quot;,&quot;Losses&quot;)) Violin Plot csu_vb %&gt;% ggplot(aes(x=`W/L`, y=PCT, fill=`W/L`)) + geom_violin() + labs(x=&quot;Match Result&quot;,y=&quot;Hitting Percentage&quot;) + scale_x_discrete(limits = c(&quot;W&quot;, &quot;L&quot;),labels=c(&quot;Wins&quot;,&quot;Losses&quot;)) + theme(legend.position=&quot;none&quot;) 7.3 Importing Data Using R Libraries 7.3.1 BaseballR package The baseballr package allows for scraping data from Baseball Reference, Fangraphs, and Baseball Savant. For more information, visit: https://billpetti.github.io/baseballr/ Example 7.3 Use the baseballr package to obtain game results for the Colorado Rockies in 2022. Create a Kable Table of the first 20 games. library(baseballr) # Scrape data from Baseball Reference rox22 &lt;- bref_team_results(&quot;COL&quot;, 2022) # Select relevant columns and display first 20 games rox22 %&gt;% select(Date,H_A,Opp,Result,R,RA,Time,Attendance) %&gt;% slice(1:20) %&gt;% kable(booktabs=T) Date H_A Opp Result R RA Time Attendance Friday, Apr 8 H LAD L 3 5 3:09 48627 Saturday, Apr 9 H LAD W 3 2 2:48 48087 Sunday, Apr 10 H LAD W 9 4 3:13 40825 Monday, Apr 11 A TEX W 6 4 4:01 35052 Tuesday, Apr 12 A TEX W 4 1 3:09 15862 Thursday, Apr 14 H CHC L 2 5 3:02 24444 Friday, Apr 15 H CHC W 6 5 3:26 35450 Saturday, Apr 16 H CHC W 9 6 2:58 37476 Sunday, Apr 17 H CHC L 4 6 3:19 36391 Monday, Apr 18 H PHI W 4 1 2:53 20403 Tuesday, Apr 19 H PHI W 6 5 3:02 23800 Wednesday, Apr 20 H PHI L 6 9 3:09 21490 Saturday, Apr 23 (1) A DET L 0 13 3:02 37566 Saturday, Apr 23 (2) A DET W 3 2 2:47 28635 Sunday, Apr 24 A DET W 6 2 2:55 20088 Monday, Apr 25 A PHI L 2 8 3:09 20130 Tuesday, Apr 26 A PHI L 3 10 3:19 22300 Wednesday, Apr 27 A PHI L 3 7 3:20 20127 Thursday, Apr 28 A PHI L 1 7 3:08 20098 Friday, Apr 29 H CIN W 10 4 3:25 30206 Example 7.4 Use the baseballr packges to obtain the batting leaderboards for MLB in 2022. Create a table with the top ten players in terms of WAR. # Scrape data from Fangraphs bat22 &lt;- fg_batter_leaders(x = 2022, y = 2022) # Select relevant columns bat22 = bat22 %&gt;% select(Name,Team,OPS,WPA,wRC,WAR) # Arrange by leaders in WAR and print to a Kable table bat22 %&gt;% arrange(desc(WAR)) %&gt;% slice(1:10) %&gt;% kable(booktabs=T) Name Team OPS WPA wRC WAR Aaron Judge NYY 1.111 7.74 162 11.4 Manny Machado SDP 0.898 4.65 110 7.4 Nolan Arenado STL 0.891 2.54 106 7.3 Paul Goldschmidt STL 0.981 4.91 131 7.1 Freddie Freeman LAD 0.918 2.82 128 7.1 Francisco Lindor NYM 0.788 3.76 99 6.8 Yordan Alvarez HOU 1.019 5.22 116 6.6 Jose Altuve HOU 0.921 2.85 111 6.6 Mookie Betts LAD 0.873 4.44 105 6.6 J.T. Realmuto PHI 0.820 0.38 84 6.5 Example 7.5 Using the baseballr package, obtain the top ten leaders for max hit speed along with these players average hit speed, number of barrels, and barrel percent. Present this information in a Kable table. # Scrape Statcast data from Baseball Savant sc_leader &lt;- statcast_leaderboards(leaderboard = &quot;exit_velocity_barrels&quot;,year = 2022) # Select relevant columns sc_leader %&gt;% mutate(Name = paste(first_name, last_name), `Max Hit Speed` = max_hit_speed, `Avg Hit Speed` = avg_hit_speed, `Barrels` = barrels, `Barrel Percent` = brl_percent) %&gt;% select(Name,`Max Hit Speed`,`Avg Hit Speed`,`Barrels`,`Barrel Percent`) %&gt;% arrange(desc(`Max Hit Speed`)) %&gt;% slice(1:10) %&gt;% kable(booktabs=T) Name Max Hit Speed Avg Hit Speed Barrels Barrel Percent Oneil Cruz 122.4 91.9 32 15.5 Giancarlo Stanton 119.8 95.0 51 19.3 Shohei Ohtani 119.1 92.9 72 16.8 Vladimir Guerrero Jr.  118.4 92.8 59 11.2 Aaron Judge 118.4 95.9 106 26.5 Luis Robert Jr.  117.8 89.3 27 8.9 Yordan Alvarez 117.4 95.2 78 21.0 Christian Yelich 117.2 91.5 34 8.2 Julio Rodríguez 117.2 92.0 48 13.1 Rowdy Tellez 116.9 91.1 53 12.9 This is a useful website for obtaining and visualizing StatCast pitch data: https://billpetti.github.io/baseballr/articles/using_statcast_pitch_data.html Example 7.6 Obtain Shohei Ohtani’s pitch data for the 2022 season. Plot the horizontal and vertical break of the pitches. Also, investigate his fastball velocity by inning. More about Ohtani’s pitching repertoire: https://youtu.be/7nZBlYIqEww More about types of pitches: https://youtu.be/1FTFWzcgjHE library(RColorBrewer) # This follows the example at: # https://billpetti.github.io/baseballr/articles/using_statcast_pitch_data.html # ohtani_id &lt;- baseballr::playerid_lookup(last_name = &quot;Ohtani&quot;, first_name = &quot;Shohei&quot;) %&gt;% # pull(mlbam_id) # can get player id for mlbam at: https://razzball.com/mlbamids/ ohtani_id &lt;- &quot;660271&quot; ohtani_data &lt;- baseballr::statcast_search_pitchers(start_date = &quot;2022-03-01&quot;, end_date = &quot;2022-12-01&quot;, pitcherid = &quot;660271&quot;) ohtani_cleaned_data &lt;- ohtani_data %&gt;% # Only keep rows with pitch movement readings # and during the regular season filter(!is.na(pfx_x), !is.na(pfx_z), game_type == &quot;R&quot;) %&gt;% mutate(pfx_x_in_pv = -12*pfx_x, pfx_z_in = 12*pfx_z) colors &lt;- brewer.pal(n = 6, name = &quot;Dark2&quot;) pitch_colors &lt;- c(&quot;4-Seam Fastball&quot; = colors[1], &quot;Sinker&quot; = colors[2], &quot;Cutter&quot; = colors[3], &quot;Curveball&quot; = colors[4], &quot;Slider&quot; = colors[5], &quot;Split-Finger&quot; = colors[6]) ( ohtani_pitch_types &lt;- unique(ohtani_cleaned_data$pitch_name) ) ## [1] &quot;Slider&quot; &quot;Curveball&quot; &quot;Sinker&quot; &quot;Cutter&quot; ## [5] &quot;4-Seam Fastball&quot; &quot;Split-Finger&quot; ohtani_cleaned_data %&gt;% ggplot(aes(x = pfx_x_in_pv, y = pfx_z_in, color = pitch_name)) + geom_vline(xintercept = 0) + geom_hline(yintercept = 0) + geom_point(size = 1.5, alpha = 0.5) + scale_color_manual(values = pitch_colors, limits = ohtani_pitch_types) + scale_x_continuous(limits = c(-25,25), breaks = seq(-20,20, 5), labels = scales::number_format(suffix = &quot;\\&quot;&quot;)) + scale_y_continuous(limits = c(-25,25), breaks = seq(-20,20, 5), labels = scales::number_format(suffix = &quot;\\&quot;&quot;)) + coord_equal() + labs(title = &quot;Shohei Ohtani Pitch Movement&quot;, subtitle = &quot;2022 MLB Season | Pitcher&#39;s POV&quot;, caption = &quot;Data: Baseball Savant via baseballr&quot;, x = &quot;Horizontal Break&quot;, y = &quot;Induced Vertical Break&quot;, color = &quot;Pitch Name&quot;) # Group pitches by inning ohtani_velo_by_inning &lt;- ohtani_cleaned_data %&gt;% filter(pitch_name == &quot;4-Seam Fastball&quot;) %&gt;% group_by(inning, pitch_name) %&gt;% summarize(average_velo = mean(release_speed, na.rm = TRUE)) # Plot average fastball speed by inning ohtani_velo_by_inning %&gt;% ggplot(aes(x = inning, y = average_velo, color = pitch_name)) + geom_line(linewidth = 1.5, alpha = 0.5, show.legend = FALSE) + geom_point(size = 3, show.legend = FALSE) + scale_color_manual(values = pitch_colors) + scale_x_continuous(breaks = 1:9) + scale_y_continuous(limits = c(90, 100)) + labs(title = &quot;Shohei Ohtani 4-Seam Fastball Velo By Inning&quot;, subtitle = &quot;2022 MLB Season&quot;, caption = &quot;Data: Baseball Savant via baseballr&quot;, x = &quot;Inning&quot;, y = &quot;Average Velo&quot;) 7.3.2 nflfastR package The nflfastR package is a helpful package for obtaining play-by-play and roster data for NFL games. For more details, see: https://www.nflfastr.com/articles/nflfastR.html For a quick explanation of expected points added, see: https://youtu.be/qo7-zeJEVzs Example 7.7 Use the nflfastR package to obtain the play-by-play data for the Denver Broncos home game against the San Francisco 49ers during the 2022 season. library(nflfastR) library(gsisdecoder) # First find the game ID by searching Broncos home games in 2022 fast_scraper_schedules(2022) %&gt;% filter(home_team==&quot;DEN&quot;) %&gt;% select(game_id,gameday,away_team,home_team) %&gt;% kable(booktabs=T) game_id gameday away_team home_team 2022_02_HOU_DEN 2022-09-18 HOU DEN 2022_03_SF_DEN 2022-09-25 SF DEN 2022_05_IND_DEN 2022-10-06 IND DEN 2022_07_NYJ_DEN 2022-10-23 NYJ DEN 2022_11_LV_DEN 2022-11-20 LV DEN 2022_14_KC_DEN 2022-12-11 KC DEN 2022_15_ARI_DEN 2022-12-18 ARI DEN 2022_18_LAC_DEN 2023-01-08 LAC DEN # Scrape data for the specific game and display play-by-play data fast_scraper(&quot;2022_03_SF_DEN&quot;) %&gt;% clean_pbp() %&gt;% select(desc, play_type, ep, epa, home_wp) %&gt;% head(10) %&gt;% kable(booktabs=T,digits = 3) %&gt;% column_spec(1, width = &quot;3.5in&quot;) ## [21:58:48] WARNING: src/learner.cc:553: ## If you are loading a serialized model (like pickle in Python, RDS in R) generated by ## older XGBoost, please export the model by calling `Booster.save_model` from that version ## first, then load it back in current version. See: ## ## https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html ## ## for more details about differences between saving model and serializing. ## ## [21:58:48] WARNING: src/learner.cc:553: ## If you are loading a serialized model (like pickle in Python, RDS in R) generated by ## older XGBoost, please export the model by calling `Booster.save_model` from that version ## first, then load it back in current version. See: ## ## https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html ## ## for more details about differences between saving model and serializing. ## ## [21:58:48] WARNING: src/learner.cc:553: ## If you are loading a serialized model (like pickle in Python, RDS in R) generated by ## older XGBoost, please export the model by calling `Booster.save_model` from that version ## first, then load it back in current version. See: ## ## https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html ## ## for more details about differences between saving model and serializing. ## ## [21:58:48] WARNING: src/learner.cc:553: ## If you are loading a serialized model (like pickle in Python, RDS in R) generated by ## older XGBoost, please export the model by calling `Booster.save_model` from that version ## first, then load it back in current version. See: ## ## https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html ## ## for more details about differences between saving model and serializing. desc play_type ep epa home_wp GAME NA 0.770 0.000 0.567 8-B.McManus kicks 63 yards from DEN 35 to SF 2. 3-R.McCloud to SF 10 for 8 yards (40-J.Strnad). kickoff 0.770 -1.071 0.567 (14:54) (Shotgun) 22-J.Wilson right tackle to SF 12 for 2 yards (99-D.Williams). run -0.301 -0.415 0.589 (14:19) 10-J.Garoppolo pass short left to 19-D.Samuel to SF 25 for 13 yards (21-K.Williams, 22-K.Jackson). pass -0.716 1.559 0.599 (13:42) (Shotgun) 19-D.Samuel left tackle to SF 26 for 1 yard (98-M.Purcell). run 0.843 -0.530 0.567 (13:07) (Shotgun) 10-J.Garoppolo pass incomplete short left to 11-B.Aiyuk (2-P.Surtain). pass 0.313 -0.752 0.585 (13:01) (Shotgun) 10-J.Garoppolo pass incomplete short middle to 85-G.Kittle (97-Dj.Jones). pass -0.438 -1.445 0.610 (12:57) 18-M.Wishnowsky punts 45 yards to DEN 29, Center-46-T.Pepper, out of bounds. punt -1.884 0.035 0.647 (12:50) (Shotgun) 3-R.Wilson pass short right to 33-J.Williams to DEN 31 for 2 yards (57-D.Greenlaw). pass 1.849 -0.587 0.619 (12:24) (No Huddle, Shotgun) 33-J.Williams left guard to DEN 31 for no gain (57-D.Greenlaw; 90-K.Givens). run 1.262 -0.790 0.607 library(nflplotR) # Example from: https://www.nflfastr.com/articles/nflfastR.html pbp &lt;- nflfastR::load_pbp(2022) %&gt;% filter(season_type == &quot;REG&quot;) %&gt;% filter(!is.na(posteam) &amp; (rush == 1 | pass == 1)) offense &lt;- pbp %&gt;% group_by(team = posteam) %&gt;% summarise(off_epa = mean(epa, na.rm = TRUE)) defense &lt;- pbp %&gt;% group_by(team = defteam) %&gt;% summarise(def_epa = mean(epa, na.rm = TRUE)) offense %&gt;% inner_join(defense, by = &quot;team&quot;) %&gt;% ggplot(aes(x = off_epa, y = def_epa)) + geom_abline(slope = -1.5, intercept = c(.4, .3, .2, .1, 0, -.1, -.2, -.3), alpha = .2) + geom_mean_lines(aes(h_var = off_epa, v_var = def_epa)) + geom_nfl_logos(aes(team_abbr = team), width = 0.07, alpha = 0.7) + labs(x = &quot;Offense EPA/play&quot;, y = &quot;Defense EPA/play&quot;, caption = &quot;Data: @nflfastR&quot;, title = &quot;2022 NFL Offensive and Defensive EPA per Play&quot;) + theme_bw() + theme( plot.title = element_text(size = 12, hjust = 0.5, face = &quot;bold&quot;) ) + scale_y_reverse() 7.3.3 hoopR package The hoopR allows for one to access data related to professional and college basketball. Example 7.8 Using the hoopR package, obtain the play-by-play data for the Denver Nuggets vs. Philadelphia 76ers game on January 28, 2023. library(hoopR) # https://www.espn.com/nba/game/_/gameId/401468896 hoopR::espn_nba_pbp(game_id = 401468896) %&gt;% select(`Description`=text,`Play Type`=type_text, Quarter=period_display_value,Points=score_value,Clock=clock_display_value) %&gt;% slice(1:15) %&gt;% kable(booktabs=T) %&gt;% column_spec(1, width = &quot;3in&quot;) %&gt;% column_spec(2, width = &quot;1in&quot;) Description Play Type Quarter Points Clock Nikola Jokic vs. Joel Embiid (Jamal Murray gains possession) Jumpball 1st Quarter 0 12:00 Nikola Jokic misses 11-foot jumper Jump Shot 1st Quarter 0 11:45 James Harden defensive rebound Defensive Rebound 1st Quarter 0 11:41 Joel Embiid makes 6-foot two point shot (James Harden assists) Driving Floating Bank Jump Shot 1st Quarter 2 11:35 Nikola Jokic shooting foul Shooting Foul 1st Quarter 0 11:35 Joel Embiid misses free throw 1 of 1 Free Throw - 1 of 1 1st Quarter 0 11:35 Michael Porter Jr. defensive rebound Defensive Rebound 1st Quarter 0 11:32 Michael Porter Jr. makes 27-foot three point jumper (Kentavious Caldwell-Pope assists) Jump Shot 1st Quarter 3 11:20 Tobias Harris misses 26-foot three point jumper Jump Shot 1st Quarter 0 10:58 Kentavious Caldwell-Pope defensive rebound Defensive Rebound 1st Quarter 0 10:55 Nikola Jokic makes finger roll layup (Jamal Murray assists) Finger Roll Layup 1st Quarter 2 10:48 Joel Embiid makes driving layup (James Harden assists) Driving Layup Shot 1st Quarter 2 10:37 Aaron Gordon makes 16-foot pullup jump shot Pullup Jump Shot 1st Quarter 2 10:25 Joel Embiid makes 14-foot pullup jump shot Pullup Jump Shot 1st Quarter 2 10:12 Joel Embiid shooting foul Shooting Foul 1st Quarter 0 9:59 Example 7.9 Obtain win probability as a function of game time for Colorado State vs. Boise State men’s basketball on January 28, 2023. # Get ID from ESPN game URL: https://www.espn.com/mens-college-basketball/game/_/gameId/401482835 library(hoopR) hoopR::espn_mbb_wp(game_id = 401482835) %&gt;% select(Period=period,`Seconds Remaining`=game_seconds_left,`Home Win Pct`=home_win_percentage,`Play ID`=play_id) %&gt;% slice(1:10) %&gt;% kable(booktabs=T) Period Seconds Remaining Home Win Pct Play ID 1 2375 0.891 401482835101806401 1 2372 0.893 401482835101806701 1 2349 0.913 401482835101809001 1 2322 0.916 401482835101815701 1 2319 0.918 401482835101816001 1 2297 0.934 401482835101818201 1 2273 0.939 401482835101824601 1 2269 0.933 401482835101825001 1 2269 0.924 401482835101825002 1 2238 0.939 401482835101828101 library(ncaahoopR) wp_chart_new(401482835,show_labels = F) ## Scraping Data for Game: 1 of 1 game_flow(game_id = 401482835, home_col = &quot;blue&quot;, away_col = &quot;forestgreen&quot;) ## Scraping Data for Game: 1 of 1 7.3.4 hockeyR package The hockeyR packages allows you to obtain data from NHL.com and Hockey Reference. The sportyR package is useful for plotting spatial data on various playing fields/courts. Example 7.10 Create a shot plot for the Colorado Avalanche vs. St. Louis Blues on January 28, 2023. # Example adapted from: https://hockeyr.netlify.app/ # devtools::install_github(&quot;danmorse314/hockeyR&quot;) library(hockeyR) library(sportyR) pbp &lt;- hockeyR::load_pbp(&#39;2022-2023&#39;) # get single game game &lt;- pbp %&gt;% filter(game_date == &quot;2023-01-28&quot; &amp; home_abbreviation == &quot;COL&quot;) game %&gt;% select(Date=game_date,Period=period,Time=period_time_remaining,Event=event, Description=description) %&gt;% slice(1:15) %&gt;% kable(booktabs=T) Date Period Time Event Description 2023-01-28 1 20:00 Game Scheduled Game Scheduled 2023-01-28 1 20:00 Faceoff J.T. Compher faceoff won against Noel Acciari 2023-01-28 1 19:47 Stoppage Icing 2023-01-28 1 19:47 Faceoff J.T. Compher faceoff won against Noel Acciari 2023-01-28 1 19:35 Takeaway Takeaway by Matt Nieto 2023-01-28 1 19:09 Shot Torey Krug Wrist Shot saved by Alexandar Georgiev 2023-01-28 1 19:09 Stoppage Goalie Stopped 2023-01-28 1 19:09 Faceoff Nathan MacKinnon faceoff won against Brayden Schenn 2023-01-28 1 18:39 Shot Evan Rodrigues Wrist Shot saved by Jordan Binnington 2023-01-28 1 18:07 Hit Andreas Englund hit Logan Brown 2023-01-28 1 17:30 Shot Denis Malgin Wrist Shot saved by Jordan Binnington 2023-01-28 1 17:21 Blocked Shot Samuel Girard shot blocked shot by Niko Mikkola 2023-01-28 1 16:46 Hit Noel Acciari hit Erik Johnson 2023-01-28 1 16:35 Missed Shot Noel Acciari Wide of Net Alexandar Georgiev 2023-01-28 1 16:25 Shot Matt Nieto Wrist Shot saved by Jordan Binnington # grab team logos &amp; colors team_logos &lt;- hockeyR::team_logos_colors %&gt;% filter(team_abbr == unique(game$home_abbreviation) | team_abbr == unique(game$away_abbreviation)) %&gt;% # add in dummy variables to put logos on the ice mutate(x = ifelse(full_team_name == unique(game$home_name), 50, -50), y = 0) # add transparency to logo transparent &lt;- function(img) { magick::image_fx(img, expression = &quot;0.3*a&quot;, channel = &quot;alpha&quot;) } # get only shot events fenwick_events &lt;- c(&quot;MISSED_SHOT&quot;,&quot;SHOT&quot;,&quot;GOAL&quot;) shots &lt;- game %&gt;% filter(event_type %in% fenwick_events) %&gt;% # adding team colors left_join(team_logos, by = c(&quot;event_team_abbr&quot; = &quot;team_abbr&quot;)) # create shot plot geom_hockey(&quot;nhl&quot;) + ggimage::geom_image( data = team_logos, aes(x = x, y = y, image = team_logo_espn), image_fun = transparent, size = 0.22, asp = 2.35 ) + geom_point( data = shots, aes(x_fixed, y_fixed), size = 3, color = shots$team_color1, shape = ifelse(shots$event_type == &quot;GOAL&quot;, 19, 1) ) + labs( title = glue::glue(&quot;{unique(game$away_name)} @ {unique(game$home_name)}&quot;), subtitle = glue::glue( &quot;{unique(game$game_date)}\\n {unique(shots$away_abbreviation)} {unique(shots$away_final)} - {unique(shots$home_final)} {unique(shots$home_abbreviation)}&quot; ), caption = &quot;data from hockeyR | plot made with sportyR&quot; ) + theme( plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5), plot.caption = element_text(hjust = .9)) 7.3.5 worldfootballR The worldfootballR package allows one to access data from FBRef, Understat, and other soccer websites. Example 7.11 Download the match summaries for all US Women’s National Team (USWNT) in the 2019 World Cup. Display this information in a kable table. For more on xG, see: https://youtu.be/zSaeaFcm1SY library(worldfootballR) # USWNT 2019 World Cup results url &lt;- &quot;https://fbref.com/en/squads/1c912aa0/2019/United-States-Women-Stats&quot; uswnt19 &lt;- get_team_match_results(url) uswnt19 %&gt;% filter(Comp == &quot;World Cup&quot;) %&gt;% select(-Day,-Time,-Comp,-Team_Url,-Captain,-Formation, -Referee,-Notes,-Attendance,-Venue,-Team) %&gt;% kable(booktabs=T) Date Round Result GF GA Opponent xG xGA Poss 2019-06-11 Group stage W 13 0 Thailand 7.1 0.1 72 2019-06-16 Group stage W 3 0 Chile 3.7 0.0 71 2019-06-20 Group stage W 2 0 Sweden 2.1 0.4 61 2019-06-24 Round of 16 W 2 1 Spain 2.4 0.2 55 2019-06-28 Quarter-finals W 2 1 France 1.1 1.6 40 2019-07-02 Semi-finals W 2 1 England 0.9 1.7 43 2019-07-07 Final W 2 0 Netherlands 3.0 0.2 53 7.4 Data Scraping Acquiring data from internet websites can be completed by using data scraping methods. In essence, this allows your computer to extract data from websites. There are a handful of techniques that we will use to accomplish some basic scraping tasks. 7.4.1 General Tips Brainstorm: Ask yourself what data you need and were to find it. If you pull from different sources, do you have a unique identifier between the sources? Start small: View your scraping project as a war, winning it with small battles. If you want to scrape sports statistics for the NFL, consider how to scrape these statistics for one team. Hyperlinks are your friend: Lead to websites with more detailed information and/or serve as the unique identifier between different data sources? Data is everywhere: Text color, font, or highlighting may serve as valuable data that you need. If these features exist on the webpage, then they exist within the HTML code which generated the document. Ready your search engine: When you are undoubtably stuck and have a question, it’s likely the answer is already on StackOverflow (https://stackoverflow.com/) Careful how quickly you scrape from a website: If you attempt to scrape from a website too frequently, you may get a temporary (or even permanent) IP ban. You can view a website’s rules for scraping by looking at the robots.txt file on the website of interest. For example, see: https://www.basketball-reference.com/robots.txt 7.4.2 Introduction to HTML All contents that are displayed on a web page are structured through HTML with the help of HTML elements. HTML elements consist of a tag and contents. The tag defines how the web browser should format and display the content. Aptly, the content is what should be displayed. Attributes are optional parameters which provide additional information about the element in which the attribute is included. The type of attribute is the attribute name , whereas the quantity assigned to the attribute is the attribute value. HTML element structure 7.4.3 rvest Package The rvest (pronounced “harvest”) package in R is one of the best options for scraping data directly into R. This is part of the tidyverse ecosystem in R. Allows users to scrape (or harvest) data from webpages. Common use functions from the package include: - read_html(): read HTML from a webpage - html_elements(): returns a subset of elements with specified characteristics - html_text(): returns the content of all elements - html_attr(): returns attribute values for all elements with specified attribute - html_table(): returns a list of all HTML tables A working knowledge of css and/or xpath is helpful. 7.4.4 CSS Gadget Selector All web pages are composed of HTML elements, but some elements are incredibly complex. They often are nested inside of other elements or rely on other elements from another document. A selector gadget allows you to determine what css selector you need to extract the information you desire. These JavaScript bookmark lets determine where the information you desire belongs in the HTML code. You can download the most popular selector gadget here which also has a Google Chrome extension available (shorturl.at/nrFJP). Probably more than half the time, these gadgets prove less than helpful which is why I suggest perusing the HTML file on your own with the Inspect feature in Google Chrome. 7.4.5 Scraping Examples Many R packages exist to scrape data from the Sports Reference websites, however, we can also scrape the data ourselves without too much trouble. Example 7.12 Scrape A’ja Wilson’s per game statistics on Basketball Reference and output the data into a kable table. Use the selector gadget to find the correct Link: https://www.basketball-reference.com/wnba/players/w/wilsoa01w.html We want to get this data into R: HTML element structure We can use the Selector Gadget to identify the html tag for this table. Using the selector gadget library(rvest) library(kableExtra) url &lt;- &quot;https://www.basketball-reference.com/wnba/players/w/wilsoa01w.html&quot; # Be careful to not run this function too quickly or you may be IP banned wilson &lt;- read_html(url) # Grab the node of interest and format the output as a html_table(). # This is now a list wilson %&gt;% html_elements(&quot;#per_game0&quot;) %&gt;% html_table() ## [[1]] ## # A tibble: 6 × 28 ## Year Tm Age G GS MP FG FGA `FG%` `3P` `3PA` `3P%` `2P` ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2018 &quot;LVA&quot; 21 33 33 30.6 7.4 16.1 0.462 0 0 NA 7.4 ## 2 2019 &quot;LVA&quot; 22 26 25 28.5 6.1 12.7 0.479 0 0 0 6.1 ## 3 2020 &quot;LVA&quot; 23 22 22 31.7 7.5 15.7 0.48 0 0 NA 7.5 ## 4 2021 &quot;LVA&quot; 24 32 32 31.9 6.5 14.6 0.444 0 0 1 6.4 ## 5 2022 &quot;LVA&quot; 25 36 36 30 7.2 14.4 0.501 0.9 2.3 0.373 6.4 ## 6 Care… &quot;&quot; NA 149 148 30.5 7 14.7 0.473 0.2 0.6 0.376 6.7 ## # … with 15 more variables: `2PA` &lt;dbl&gt;, `2P%` &lt;dbl&gt;, `eFG%` &lt;dbl&gt;, FT &lt;dbl&gt;, ## # FTA &lt;dbl&gt;, `FT%` &lt;dbl&gt;, ORB &lt;dbl&gt;, DRB &lt;dbl&gt;, TRB &lt;dbl&gt;, AST &lt;dbl&gt;, ## # STL &lt;dbl&gt;, BLK &lt;dbl&gt;, TOV &lt;dbl&gt;, PF &lt;dbl&gt;, PTS &lt;dbl&gt; # We can convert the list to a data frame to allow us to use dplyr functions # like select # Output the first ten columns wilson &lt;- read_html(url) wilson %&gt;% html_elements(&quot;#per_game0&quot;) %&gt;% html_table() %&gt;% data.frame() %&gt;% select(1:10) %&gt;% kable(booktabs=T) Year Tm Age G GS MP FG FGA FG. X3P 2018 LVA 21 33 33 30.6 7.4 16.1 0.462 0.0 2019 LVA 22 26 25 28.5 6.1 12.7 0.479 0.0 2020 LVA 23 22 22 31.7 7.5 15.7 0.480 0.0 2021 LVA 24 32 32 31.9 6.5 14.6 0.444 0.0 2022 LVA 25 36 36 30.0 7.2 14.4 0.501 0.9 Career NA 149 148 30.5 7.0 14.7 0.473 0.2 Example 7.13 Player efficiency rating (PER) is an advanced basketball statistic that attempts to quantify a player’s overall contribution. Scrape the data from the following site and build a kable table with the top 20 players in terms of PER. Link: http://www.espn.com/nba/hollinger/statistics url &lt;- &quot;http://www.espn.com/nba/hollinger/statistics&quot; hollinger &lt;- read_html(url) holl_df &lt;- hollinger %&gt;% html_elements(&quot;div.mod-content&quot;) %&gt;% .[2] %&gt;% html_table() %&gt;% data.frame() colnames(holl_df) = holl_df[2,] holl_df %&gt;% slice(-1,-2,-13,-24,-35,-46) %&gt;% slice(1:20) %&gt;% select(RK,PLAYER,PER) %&gt;% kable(booktabs=T) RK PLAYER PER 1 Nikola Jokic, DEN 31.88 2 Joel Embiid, PHI 30.69 3 Luka Doncic, DAL 30.26 4 Anthony Davis, LAL 28.48 Giannis Antetokounmpo, MIL 28.48 6 Shai Gilgeous-Alexander, OKC 27.32 7 Damian Lillard, POR 26.70 8 Kevin Durant, BKN 26.59 9 Jimmy Butler, MIA 25.49 10 Zion Williamson, NO 25.42 11 LeBron James, LAL 24.94 12 Stephen Curry, GS 24.92 13 Jayson Tatum, BOS 24.07 14 Ja Morant, MEM 23.82 15 Kawhi Leonard, LAC 23.77 16 Domantas Sabonis, SAC 23.03 Donovan Mitchell, CLE 23.03 18 Kristaps Porzingis, WSH 22.74 19 Tyrese Haliburton, IND 22.72 20 Lauri Markkanen, UTAH 22.63 Example 7.14 Obtain the top ten leaders for goals on the US Women’s National Team and output as a kable table. Link: https://www.ussoccer.com/uswnt-stats/2022 url &lt;- &quot;https://www.ussoccer.com/uswnt-stats/2022&quot; uswnt &lt;- read_html(url) uswnt_df &lt;- uswnt %&gt;% html_elements(&quot;#some_table_id&quot;) %&gt;% .[1] %&gt;% html_table() %&gt;% data.frame() colnames(uswnt_df) = uswnt_df[1,] uswnt_df$Goals &lt;- as.integer(uswnt_df$Goals) ## Warning: NAs introduced by coercion uswnt_df %&gt;% slice(-1,-n(),-(n()-1)) %&gt;% arrange(desc(Goals)) %&gt;% slice(1:10) %&gt;% kable(booktabs=T) Name Pos. GP GS Min G A Y R Career Caps Goals Morgan, Alex F 10 9 783 4 1 0 200 119 Rapinoe, Megan F 10 3 364 1 2 2 197 63 Horan, Lindsey M 14 14 979 1 0 1 122 26 Pugh, Mallory F 15 13 1030 7 7 0 82 25 Dunn, Crystal D 3 0 85 0 0 0 126 24 Lavelle, Rose M 16 15 1107 4 6 2 84 22 Williams, Lynn F 2 0 56 0 0 0 47 14 Smith, Sophia F 17 17 1192 11 1 0 27 12 Gautrat, Morgan M 1 1 45 0 0 0 88 8 Macario, Catarina M 5 5 342 5 1 1 17 8 "],["linear-regression.html", "Chapter 8 Linear Regression 8.1 Simple Linear Regression 8.2 Residual Analysis 8.3 Polynomial Regression 8.4 Variable Transformations 8.5 Multiple Regression and Model Selection 8.6 Confounding Variables 8.7 Interaction 8.8 Weighted Least Squares Regression 8.9 Stepwise Regression using Cross-Validation 8.10 Ridge Regression 8.11 Lasso Regression 8.12 Elastic Net 8.13 Mixed Effects Models 8.14 Logistic Regression", " Chapter 8 Linear Regression Linear regression is a statistical method for modeling a quantitative variable as a function of one or more quantitative variables. This method determines a “line of best fit” by minimizing the sum of squared errors. Definition 8.1 A simple linear regression model, \\(\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 x\\), between a dependent variable \\(y\\) and an independent variable \\(x\\) is found by minimizing \\(SSE=\\sum(y_i-\\hat{\\beta}_0-\\hat{\\beta}_1x)^2\\), where: \\(\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x}\\) \\(\\hat{\\beta}_1 = \\frac{\\sum(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum(x_i-\\bar{x})^2}\\) Definition 8.2 A multiple linear regression model, \\(\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_1 + \\ldots \\hat{\\beta}_p x_p\\), between a dependent variable \\(y\\) and an independent variables \\(x_1, x_2, \\ldots, x_p\\) is found by minimizing \\(SSE=\\sum(y_i-\\hat{\\beta}_0-\\hat{\\beta}_1x_1-\\hat{\\beta}_2x_2- \\ldots - -\\hat{\\beta}_px_p)^2\\) We make a few assumptions when we fit these regression models: The response variable can be modeled as a linear combination of the predictor variables (linearity in the parameters). The errors are independent normal random variables. We seek to minimize the sum of squared errors, SSE. 8.1 Simple Linear Regression Example 8.1 Download individual MLB pitching statistics for the 2021 and 2022 seasons. Use these datasets to build simple linear regression models with 2022 season ERA as the dependent variable and 2021 season ERA and FIP as the independent variables. # Download individual pitching data for 2021 and 2022 seasons library(tidyverse) library(baseballr) pit21 &lt;- bref_daily_pitcher(&quot;2021-01-01&quot;, &quot;2021-12-31&quot;) %&gt;% fip_plus() %&gt;% dplyr::select(Name, IP, ERA, FIP) %&gt;% dplyr::arrange(dplyr::desc(IP)) %&gt;% mutate(IP21=IP,ERA21=ERA,FIP21=FIP) pit22 &lt;- bref_daily_pitcher(&quot;2022-01-01&quot;, &quot;2022-12-31&quot;) %&gt;% fip_plus() %&gt;% dplyr::select(Name, IP, ERA, FIP) %&gt;% dplyr::arrange(dplyr::desc(IP)) %&gt;% mutate(IP22=IP,ERA22=ERA,FIP22=FIP) # merge the datasets together, remove redundant columns all_pit &lt;- pit21 %&gt;% left_join(pit22,by = &quot;Name&quot;) %&gt;% select(-c(2:4,8:10)) %&gt;% filter(IP21&gt;5 &amp; IP22 &gt; 5) all_pit %&gt;% slice(1:10) %&gt;% kable(booktabs=T) Name IP21 ERA21 FIP21 IP22 ERA22 FIP22 Zack Wheeler 213.1 2.78 2.57 153.0 2.82 2.87 Walker Buehler 207.2 2.47 3.13 65.0 4.02 3.80 Adam Wainwright 206.1 3.05 3.62 191.2 3.71 3.65 Sandy Alcantara 205.2 3.19 3.39 228.2 2.28 2.97 Robbie Ray 193.1 2.84 3.69 189.0 3.71 4.16 José Berríos 192.0 3.52 3.47 172.0 5.23 4.55 Kevin Gausman 192.0 2.81 2.99 174.2 3.35 2.38 Luis Castillo 187.2 3.98 3.69 150.1 2.99 3.07 Frankie Montas 187.0 3.37 3.36 144.1 4.05 3.72 Julio Urías 185.2 2.96 3.08 175.0 2.16 3.71 # look at correlation between pitching stats in 2021 and 2022 library(GGally) all_pit %&gt;% select(ERA21,ERA22,FIP21,FIP22) %&gt;% ggpairs() # build scatterplots of ERA22 vs ERA21 and ERA22 vs FIP21 library(gridExtra) p1 &lt;- all_pit %&gt;% ggplot(aes(x=ERA21,y=ERA22)) + geom_point() + geom_smooth(method=&quot;lm&quot;) + scale_x_continuous(limits=c(0,10)) + scale_y_continuous(limits=c(0,10)) p2 &lt;- all_pit %&gt;% ggplot(aes(x=FIP21,y=ERA22)) + geom_point() + geom_smooth(method=&quot;lm&quot;) + scale_x_continuous(limits=c(0,10)) + scale_y_continuous(limits=c(0,10)) grid.arrange(p1,p2,nrow=1) # build SLR model 1: ERA22 ~ ERA21 model1 &lt;- lm(ERA22~ERA21,data=all_pit) # sloppy output summary(model1) ## ## Call: ## lm(formula = ERA22 ~ ERA21, data = all_pit) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.4503 -1.1708 -0.3321 0.8072 19.4281 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.72994 0.23077 16.163 &lt; 2e-16 *** ## ERA21 0.12896 0.04878 2.644 0.00845 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.106 on 517 degrees of freedom ## Multiple R-squared: 0.01334, Adjusted R-squared: 0.01143 ## F-statistic: 6.989 on 1 and 517 DF, p-value: 0.008449 library(broom) # format the output nicely in a kable table model1 %&gt;% tidy() %&gt;% mutate( p.value = scales::pvalue(p.value), term = c(&quot;Intercept&quot;, &quot;ERA21&quot;) ) %&gt;% kable(booktabs=T,digits=c(3,3,3,3), caption = &quot;SLR Model Estimating ERA22 Using ERA21&quot;, col.names = c(&quot;Predictor&quot;, &quot;Estimate&quot;, &quot;Std Error&quot;, &quot;t stat&quot;, &quot;p-value&quot;)) %&gt;% kable_styling(latex_options = &quot;hold_position&quot;) Table 8.1: SLR Model Estimating ERA22 Using ERA21 Predictor Estimate Std Error t stat p-value Intercept 3.730 0.231 16.163 &lt;0.001 ERA21 0.129 0.049 2.644 0.008 # build SLR model 2: ERA22 ~ FIP21 model2 &lt;- lm(ERA22~FIP21,data=all_pit) # Nicely output regression information model2 %&gt;% tidy() %&gt;% mutate( p.value = scales::pvalue(p.value), term = c(&quot;Intercept&quot;, &quot;FIP21&quot;) ) %&gt;% kable(booktabs=T,digits=c(3,3,3,3), caption = &quot;SLR Model Estimating ERA22 Using FIP21&quot;, col.names = c(&quot;Predictor&quot;, &quot;Estimate&quot;, &quot;Std Error&quot;, &quot;t stat&quot;, &quot;p-value&quot;)) %&gt;% kable_styling(latex_options = &quot;hold_position&quot;) Table 8.2: SLR Model Estimating ERA22 Using FIP21 Predictor Estimate Std Error t stat p-value Intercept 3.273 0.295 11.097 &lt;0.001 FIP21 0.238 0.066 3.626 &lt;0.001 # build MR model: ERA22 ~ ERA21 + FIP21 model3 &lt;- lm(ERA22~ERA21+FIP21,data=all_pit) # Nicely output regression information model3 %&gt;% tidy() %&gt;% mutate( p.value = scales::pvalue(p.value), term = c(&quot;Intercept&quot;,&quot;ERA21&quot;,&quot;FIP21&quot;) ) %&gt;% kable(booktabs=T,digits=c(3,3,3,3), caption = &quot;SLR Model Estimating ERA22 Using FIP21&quot;, col.names = c(&quot;Predictor&quot;, &quot;Estimate&quot;, &quot;Std Error&quot;, &quot;t stat&quot;, &quot;p-value&quot;)) %&gt;% kable_styling(latex_options = &quot;hold_position&quot;) Table 8.3: SLR Model Estimating ERA22 Using FIP21 Predictor Estimate Std Error t stat p-value Intercept 3.272 0.295 11.080 &lt;0.001 ERA21 0.002 0.071 0.028 0.977 FIP21 0.236 0.096 2.463 0.014 Example 8.2 Our goal is to investigate the relationship between MLB team OPS and runs per game. Download MLB team offensive statistics for the 2022 season using rvest. # scrape the data and output as a kable table library(rvest) url &lt;- &quot;https://www.baseball-reference.com/leagues/majors/2022.shtml&quot; site &lt;- read_html(url) mlb22 &lt;- site %&gt;% html_elements(&quot;#teams_standard_batting&quot;) %&gt;% html_table() mlb22 &lt;- mlb22 %&gt;% data.frame() %&gt;% column_to_rownames(&quot;Tm&quot;) %&gt;% rename(`R/G`=R.G) %&gt;% slice(-(31:33)) mlb22 %&gt;% select(1:8) %&gt;% kable(booktabs=T) X.Bat BatAge R/G G PA AB R H Arizona Diamondbacks 57 26.5 4.33 162 6027 5351 702 1232 Atlanta Braves 53 27.5 4.87 162 6082 5509 789 1394 Baltimore Orioles 58 27.0 4.16 162 6049 5429 674 1281 Boston Red Sox 54 28.8 4.54 162 6144 5539 735 1427 Chicago Cubs 64 27.9 4.06 162 6072 5425 657 1293 Chicago White Sox 44 29.3 4.23 162 6123 5611 686 1435 Cincinnati Reds 66 29.4 4.00 162 5978 5380 648 1264 Cleveland Guardians 50 25.9 4.31 162 6163 5558 698 1410 Colorado Rockies 43 29.1 4.31 162 6105 5540 698 1408 Detroit Tigers 53 27.9 3.44 162 5870 5378 557 1240 Houston Astros 45 29.3 4.55 162 6054 5409 737 1341 Kansas City Royals 55 27.1 3.95 162 6010 5437 640 1327 Los Angeles Angels 66 27.9 3.85 162 5977 5423 623 1265 Los Angeles Dodgers 51 29.6 5.23 162 6247 5526 847 1418 Miami Marlins 56 28.8 3.62 162 5949 5395 586 1241 Milwaukee Brewers 51 29.1 4.48 162 6122 5417 725 1271 Minnesota Twins 61 26.9 4.30 162 6113 5476 696 1356 New York Mets 61 29.7 4.77 162 6176 5489 772 1422 New York Yankees 54 30.2 4.98 162 6172 5422 807 1308 Oakland Athletics 64 28.3 3.51 162 5863 5314 568 1147 Philadelphia Phillies 56 28.1 4.61 162 6077 5496 747 1392 Pittsburgh Pirates 68 26.3 3.65 162 5912 5331 591 1186 San Diego Padres 55 28.2 4.35 162 6175 5468 705 1317 Seattle Mariners 59 27.5 4.26 162 6117 5375 690 1236 San Francisco Giants 66 30.0 4.42 162 6117 5392 716 1261 St. Louis Cardinals 51 28.8 4.77 162 6165 5496 772 1386 Tampa Bay Rays 61 27.0 4.11 162 6008 5412 666 1294 Texas Rangers 55 28.0 4.36 162 6029 5478 707 1308 Toronto Blue Jays 51 27.1 4.78 162 6158 5555 775 1464 Washington Nationals 55 28.7 3.72 162 5998 5434 603 1351 Examine the correlation structure between R/G, BA, OBP, SLG, and OPS. mlb22_off &lt;- mlb22 %&gt;% select(`R/G`,BA,OBP,SLG,OPS) %&gt;% data.frame() %&gt;% mutate_all(as.numeric) mlb22_off %&gt;% ggpairs() Build a SLR model between runs scored and OPS. # build SLR model: R/G ~ OPS model1 &lt;- lm(R.G~OPS,data=mlb22_off) # Nicely output regression information model1 %&gt;% tidy() %&gt;% mutate( p.value = scales::pvalue(p.value), term = c(&quot;Intercept&quot;, &quot;OPS&quot;) ) %&gt;% kable(booktabs=T,digits=c(3,3,3,3), caption = &quot;SLR Model Estimating Runs Per Game Using Team OPS&quot;, col.names = c(&quot;Predictor&quot;, &quot;Estimate&quot;, &quot;Std Error&quot;, &quot;t stat&quot;, &quot;p-value&quot;)) %&gt;% kable_styling(latex_options = &quot;hold_position&quot;) Table 8.4: SLR Model Estimating Runs Per Game Using Team OPS Predictor Estimate Std Error t stat p-value Intercept -3.842 0.485 -7.919 &lt;0.001 OPS 11.509 0.686 16.771 &lt;0.001 Plot a scatterplot of R/G and OPS along with the SLR line of best fit and confidence intervals. mlb22_off %&gt;% ggplot(aes(x=OPS,y=R.G)) + geom_point() + geom_smooth(method=lm , fill=&quot;gray&quot;, color=&quot;steelblue&quot;, se=TRUE) + labs(title = &quot;Runs Per Game vs. OPS&quot;, subtitle = &quot;2022 MLB Season | Teams&quot;, caption = &quot;Data: Baseball Reference&quot;, x = &quot;On-Base Plus Slugging (OPS)&quot;, y = &quot;Runs Per Game (R/G)&quot;) + theme_bw() Use residual analysis to assess the model assumptions in the SLR model. # Create a data frame with the residuals residuals &lt;- data.frame(x = fitted(model1), y = residuals(model1)) # Create a residual plot using ggplot2 ggplot(residuals, aes(x, y)) + geom_point() + geom_hline(yintercept = 0, linetype = &quot;dashed&quot;) + labs(x = &quot;Fitted values&quot;, y = &quot;Residuals&quot;, title = &quot;Residual plot&quot;) # Create a QQ-plot of the residuals using ggplot2 ggplot(residuals, aes(sample = y)) + stat_qq() + stat_qq_line() + labs(x = &quot;Theoretical Quantiles&quot;, y = &quot;Sample Quantiles&quot;, title = &quot;QQ-plot of Residuals&quot;) Build a MR model between runs scored and SLG, BA, OBP, and OPS. # build MR model: R/G ~ OPS + BA + OBP + SLG model2 &lt;- lm(R.G~OPS+BA+OBP+SLG,data=mlb22_off) # Nicely output regression information model2 %&gt;% tidy() %&gt;% mutate( p.value = scales::pvalue(p.value), term = c(&quot;Intercept&quot;, &quot;OPS&quot;,&quot;BA&quot;,&quot;OBP&quot;,&quot;SLG&quot;) ) %&gt;% kable(booktabs=T,digits=c(3,3,3,3), caption = &quot;MR Model Estimating Runs Per Game Using Team OPS, BA, OBP, SLG&quot;, col.names = c(&quot;Predictor&quot;, &quot;Estimate&quot;, &quot;Std Error&quot;, &quot;t stat&quot;, &quot;p-value&quot;)) %&gt;% kable_styling(latex_options = &quot;hold_position&quot;) Table 8.5: MR Model Estimating Runs Per Game Using Team OPS, BA, OBP, SLG Predictor Estimate Std Error t stat p-value Intercept -4.054 0.642 -6.312 &lt;0.001 OPS -49.862 61.599 -0.809 0.426 BA -4.482 4.081 -1.098 0.283 OBP 66.032 60.116 1.098 0.282 SLG 61.004 61.762 0.988 0.333 Example 8.3 Data for the MLB 2022 season including team WAR (wins above replacement) and team wins are contained in mlb_2022_team_war.csv. Output this data as a kable table. mlb22_war &lt;- read_csv(&quot;data/mlb_2022_team_war.csv&quot;) mlb22_war &lt;- mlb22_war %&gt;% rename(Wins=`Team Wins`,WAR=`Team WAR`) mlb22_war %&gt;% kable(booktabs=T) Team WAR Wins Los Angeles Dodgers 61.4 111 New York Yankees 54.7 99 Houston Astros 54.2 106 Atlanta Braves 50.3 101 New York Mets 48.5 101 St. Louis Cardinals 46.3 93 Toronto Blue Jays 45.2 92 Philadelphia Phillies 42.3 87 Cleveland Guardians 41.2 92 Tampa Bay Rays 39.6 86 Seattle Mariners 38.4 90 Baltimore Orioles 38.3 83 San Diego Padres 38.3 89 Minnesota Twins 36.0 78 Milwaukee Brewers 34.1 86 Chicago Cubs 31.0 74 Los Angeles Angels 30.4 73 San Francisco Giants 29.7 81 Miami Marlins 29.0 69 Chicago White Sox 27.9 81 Boston Red Sox 27.5 78 Texas Rangers 26.8 68 Arizona Diamondbacks 26.0 74 Kansas City Royals 21.6 65 Colorado Rockies 21.2 68 Cincinnati Reds 16.3 62 Detroit Tigers 13.1 66 Washington Nationals 12.1 55 Pittsburgh Pirates 10.2 62 Oakland Athletics 9.1 60 Fit a simple linear regression model with team wins as the dependent variable and team WAR as the independent variable. # build SLR model: Team Wins ~ Team WAR model &lt;- lm(Wins~WAR,data=mlb22_war) # Nicely output regression information model %&gt;% tidy() %&gt;% mutate( p.value = scales::pvalue(p.value), term = c(&quot;Intercept&quot;, &quot;Team WAR&quot;) ) %&gt;% kable(booktabs=T,digits=c(3,3,3,3), caption = &quot;SLR Model Estimating Team Wins Using Team WAR&quot;, col.names = c(&quot;Predictor&quot;, &quot;Estimate&quot;, &quot;Std Error&quot;, &quot;t stat&quot;, &quot;p-value&quot;)) %&gt;% kable_styling(latex_options = &quot;hold_position&quot;) Table 8.6: SLR Model Estimating Team Wins Using Team WAR Predictor Estimate Std Error t stat p-value Intercept 46.896 1.977 23.726 &lt;0.001 Team WAR 1.022 0.055 18.630 &lt;0.001 Plot a scatterplot along with the line of best fit. library(ggpubr) mlb22_war %&gt;% ggplot(aes(x=WAR,y=Wins)) + geom_point() + geom_smooth(method=&quot;lm&quot;) + stat_regline_equation(label.x.npc = 0.3,label.y.npc = 0.6) + labs(title = &quot;Team Wins vs. Team WAR&quot;, subtitle = &quot;2022 MLB Season | Teams&quot;, caption = &quot;Data: Baseball Reference&quot;, x = &quot;Team WAR&quot;, y = &quot;Team Wins&quot;) + theme_classic() 8.2 Residual Analysis It is important to check model assumptions. If assumptions are violated, then our inferences may be flawed. Complete residual analysis of the SLR model. # Create a data frame with the residuals residuals &lt;- data.frame(x = fitted(model), y = residuals(model)) # Create a residual plot using ggplot2 ggplot(residuals, aes(x, y)) + geom_point() + geom_hline(yintercept = 0, linetype = &quot;dashed&quot;) + labs(x = &quot;Fitted values&quot;, y = &quot;Residuals&quot;, title = &quot;Residual plot&quot;) # Create a QQ-plot of the residuals using ggplot2 ggplot(residuals, aes(sample = y)) + stat_qq() + stat_qq_line() + labs(x = &quot;Theoretical Quantiles&quot;, y = &quot;Sample Quantiles&quot;, title = &quot;QQ-plot of Residuals&quot;) In 2022, the Colorado Rockies were 68-94 and accumulated a total of 21.2 team wins above replacement (WAR). Estimate the Rockies team wins from their team WAR and compare this to their actual win total. mlb22_war &lt;- mlb22_war %&gt;% mutate(xWins = predict(model,data.frame(WAR=mlb22_war$WAR))) ( xWins &lt;- predict(model,data.frame(WAR=21.2)) ) ## 1 ## 68.57095 mlb22_war %&gt;% filter(Team==&quot;Colorado Rockies&quot;) ## # A tibble: 1 × 4 ## Team WAR Wins xWins ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Colorado Rockies 21.2 68 68.6 8.3 Polynomial Regression Example 8.4 Ken Griffey Jr. was a baseball hall of fame outfielder from 1989–2009. For each of his of his career, the number of home runs per 100 at-bats is record. This data is found in griffey_hr.csv. (From ) Output this dataset to a kable table. griffey &lt;- read_csv(&quot;data/griffey_hr.csv&quot;) griffey &lt;- griffey %&gt;% mutate(Year = Year-1988,`HR/100AB` = HR) %&gt;% select(Year,`HR/100AB`) griffey %&gt;% kable(booktabs=T,digits=c(0,2)) Year HR/100AB 1 3.52 2 3.69 3 4.01 4 4.78 5 7.73 6 9.24 7 6.54 8 8.99 9 9.21 10 8.85 11 7.92 12 7.69 13 6.04 14 4.06 15 7.83 16 6.67 17 7.13 18 6.31 19 5.68 20 3.67 21 4.91 Fit a SLR model between HR/AB and Year. model &lt;- lm(`HR/100AB`~Year,data=griffey) model %&gt;% tidy() %&gt;% mutate( p.value = scales::pvalue(p.value), term = c(&quot;Intercept&quot;, &quot;Year&quot;) ) %&gt;% kable(booktabs=T,digits=c(3,3,3,3), caption = &quot;SLR Model Estimating HR/100AB using Year&quot;, col.names = c(&quot;Predictor&quot;, &quot;Estimate&quot;, &quot;Std Error&quot;, &quot;t stat&quot;, &quot;p-value&quot;)) %&gt;% kable_styling(latex_options = &quot;hold_position&quot;) Table 8.7: SLR Model Estimating HR/100AB using Year Predictor Estimate Std Error t stat p-value Intercept 6.342 0.910 6.969 &lt;0.001 Year 0.006 0.072 0.077 0.940 Plot the SLR model and comment on the model fit. griffey %&gt;% ggplot(aes(x=Year,y=`HR/100AB`)) + geom_point() + geom_smooth(method=&quot;lm&quot;) + stat_regline_equation(label.x.npc = 0.3,label.y.npc = 0.6) + labs(title = &quot;Home Runs Per 100 At-Bats vs. Year&quot;, subtitle = &quot;Ken Griffey Jr.&#39;s Career&quot;, caption = &quot;Data: Baseball Reference, Analytic Methods in Sports&quot;, x = &quot;Year&quot;, y = &quot;Home Runs per 100 AB&quot;) + theme_classic() Plot the residuals as a function of fitted values for the SLR model. Is the linearity assumption appropriate? # Create a data frame with the residuals residuals &lt;- data.frame(x = fitted(model), y = residuals(model)) # Create a residual plot using ggplot2 ggplot(residuals, aes(x, y)) + geom_point() + geom_hline(yintercept = 0, linetype = &quot;dashed&quot;) + labs(x = &quot;Fitted values&quot;, y = &quot;Residuals&quot;, title = &quot;Residual plot&quot;) Repeat (b)-(c) using a quadratic model. model_quad &lt;- lm(`HR/100AB`~Year+I(Year^2),data=griffey) model_quad %&gt;% tidy() %&gt;% mutate( p.value = scales::pvalue(p.value), term = c(&quot;Intercept&quot;, &quot;Year&quot;,&quot;Year^2&quot;) ) %&gt;% kable(booktabs=T,digits=c(3,3,3,3), caption = &quot;SLR Model Estimating Home Runs per 100 At-Bats using Year&quot;, col.names = c(&quot;Predictor&quot;, &quot;Estimate&quot;, &quot;Std Error&quot;, &quot;t stat&quot;, &quot;p-value&quot;)) %&gt;% kable_styling(latex_options = &quot;hold_position&quot;) Table 8.8: SLR Model Estimating Home Runs per 100 At-Bats using Year Predictor Estimate Std Error t stat p-value Intercept 2.693 1.005 2.680 0.015 Year 0.957 0.210 4.549 &lt;0.001 Year^2 -0.043 0.009 -4.657 &lt;0.001 griffey %&gt;% ggplot(aes(x=Year,y=`HR/100AB`)) + geom_point() + geom_smooth(method=&quot;lm&quot;, formula = y ~ x + I(x^2)) + labs(title = &quot;Ken Griffey Jr.&#39;s Career&quot;, subtitle = &quot;Home Runs Per 100 At-Bats vs. Year&quot;, caption = &quot;Data: Baseball Reference, Analytic Methods in Sports&quot;, x = &quot;Year&quot;, y = &quot;Home Runs Per 100 At-Bats&quot;) + theme_minimal() 8.4 Variable Transformations Sometimes a variable transformation (either predictor or response) may be necessary to meet our model assumptions. Example 8.5 For the 2011-2012 NHL season, data was collected for all forwards that played at least 60 games and average at least 6 minutes per game. Create a kable table with the first ten entries. nhl_toi &lt;- read_csv(&quot;data/nhl_toi_11-12.csv&quot;) nhl_toi &lt;- nhl_toi %&gt;% mutate(PPG = P/GP) nhl_toi &lt;- nhl_toi %&gt;% column_to_rownames(&quot;Name&quot;) nhl_toi %&gt;% slice(1:10) %&gt;% kable(booktabs=T,digits=3) GP P TOI PPG Daniel Winnik 84 23 16.700 0.274 Cody Hodgson 83 41 13.817 0.494 Steven Stamkos 82 97 22.017 1.183 Ryan Getzlaf 82 57 21.600 0.695 Eric Staal 82 70 21.550 0.854 Zach Parise 82 69 21.483 0.841 Anze Kopitar 82 76 21.333 0.927 Dany Heatley 82 53 20.950 0.646 Joe Pavelski 82 61 20.617 0.744 Jarome Iginla 82 67 20.600 0.817 Fit a SLR model with Points Per Game (PPG) as the dependent variable and Time on Ice (TOI) as the independent variable. model &lt;- lm(PPG~TOI,data=nhl_toi) model %&gt;% tidy() %&gt;% mutate( p.value = scales::pvalue(p.value), term = c(&quot;Intercept&quot;, &quot;TOI&quot;) ) %&gt;% kable(booktabs=T,digits=c(3,3,3,3), caption = &quot;SLR Model Estimating Points Per Game Using Time on Ice&quot;, col.names = c(&quot;Predictor&quot;, &quot;Estimate&quot;, &quot;Std Error&quot;, &quot;t stat&quot;, &quot;p-value&quot;)) %&gt;% kable_styling(latex_options = &quot;hold_position&quot;) Table 8.9: SLR Model Estimating Points Per Game Using Time on Ice Predictor Estimate Std Error t stat p-value Intercept -0.505 0.037 -13.503 &lt;0.001 TOI 0.064 0.002 27.622 &lt;0.001 Plot the SLR model and assess the quality of the model. nhl_toi %&gt;% ggplot(aes(x=TOI,y=PPG)) + geom_point() + geom_smooth(method=&quot;lm&quot;) + stat_regline_equation(label.x.npc = 0.3,label.y.npc = 0.6) + labs(title = &quot;Points Per Game vs. Time on Ice&quot;, subtitle = &quot;NHL Forwards | 2011-2012 Season&quot;, caption = &quot;Data: Analytic Methods in Sports&quot;, x = &quot;Time on Ice (TOI)&quot;, y = &quot;Points Per Game (PPG)&quot;) + theme_light() Generate a fitted values versus residuals plot and use it to determine the appropriateness of the linearity assumption. # Create a data frame with the residuals residuals &lt;- data.frame(x = fitted(model), y = residuals(model)) # Create a residual plot using ggplot2 ggplot(residuals, aes(x, y)) + geom_point() + geom_hline(yintercept = 0, linetype = &quot;dashed&quot;) + labs(x = &quot;Fitted values&quot;, y = &quot;Residuals&quot;, title = &quot;Residual plot&quot;) Log-transform PPG and refit the SLR model. nhl_toi &lt;- nhl_toi %&gt;% mutate(logPPG = log(PPG)) model &lt;- lm(logPPG~TOI,data=nhl_toi) model %&gt;% tidy() %&gt;% mutate( p.value = scales::pvalue(p.value), term = c(&quot;Intercept&quot;, &quot;TOI&quot;) ) %&gt;% kable(booktabs=T,digits=c(3,3,3,3), caption = &quot;SLR Model Estimating Log Points Per Game Using Time on Ice&quot;, col.names = c(&quot;Predictor&quot;, &quot;Estimate&quot;, &quot;Std Error&quot;, &quot;t stat&quot;, &quot;p-value&quot;)) %&gt;% kable_styling(latex_options = &quot;hold_position&quot;) Table 8.10: SLR Model Estimating Log Points Per Game Using Time on Ice Predictor Estimate Std Error t stat p-value Intercept -3.39 0.089 -38.157 &lt;0.001 TOI 0.16 0.005 29.191 &lt;0.001 Plot the log-transformed model. Does the model seem appropriate? nhl_toi %&gt;% ggplot(aes(x=TOI,y=logPPG)) + geom_point() + geom_smooth(method=&quot;lm&quot;,se=F) + labs(title = &quot;Log Points Per Game vs. Time on Ice&quot;, subtitle = &quot;NHL Forwards | 2011-2012 Season&quot;, caption = &quot;Analytic Methods in Sports&quot;, x = &quot;Time on Ice (TOI)&quot;, y = &quot;Points Per Game (logPPG)&quot;) + theme_classic2() + coord_trans(y = &quot;exp&quot;) + scale_y_continuous(breaks=-3:1) Generate a fitted values versus residuals plot and use it to determine the appropriateness of the linearity assumption. # Create a data frame with the residuals residuals &lt;- data.frame(x = fitted(model), y = residuals(model)) # Create a residual plot using ggplot2 ggplot(residuals, aes(x, y)) + geom_point() + geom_hline(yintercept = 0, linetype = &quot;dashed&quot;) + labs(x = &quot;Fitted values&quot;, y = &quot;Residuals&quot;, title = &quot;Residual plot&quot;) 8.5 Multiple Regression and Model Selection Suppose we want to build a multiple regression model with a number of predictor variables. Which predictor variables should we include in our model? There are many ways to do model selection. We will focus on all library(rvest) url &lt;- &quot;https://www.baseball-reference.com/leagues/majors/2022.shtml&quot; site &lt;- read_html(url) raw_data &lt;- site %&gt;% html_elements(&quot;#teams_standard_batting&quot;) %&gt;% html_table() raw_data %&gt;% data.frame() %&gt;% select(1:10) %&gt;% slice(1:5) %&gt;% kable(booktabs=T) Tm X.Bat BatAge R.G G PA AB R H X2B Arizona Diamondbacks 57 26.5 4.33 162 6027 5351 702 1232 262 Atlanta Braves 53 27.5 4.87 162 6082 5509 789 1394 298 Baltimore Orioles 58 27.0 4.16 162 6049 5429 674 1281 275 Boston Red Sox 54 28.8 4.54 162 6144 5539 735 1427 352 Chicago Cubs 64 27.9 4.06 162 6072 5425 657 1293 265 # convert from character to numeric mlb_2022 &lt;- raw_data %&gt;% data.frame() %&gt;% mutate_if(is.character, as.numeric) # remove some unnecessary columns mlb_2022 &lt;- mlb_2022 %&gt;% select(-Tm,-X.Bat,-BatAge,-G,-R,-AB,-PA,-OPS.,-RBI,-IBB) %&gt;% slice(1:30) mlb_2022 %&gt;% slice(1:5) %&gt;% select(1:10) %&gt;% kable(booktabs=T) R.G H X2B X3B HR SB CS BB SO BA 4.33 1232 262 24 173 104 29 531 1341 0.230 4.87 1394 298 11 243 87 31 470 1498 0.253 4.16 1281 275 25 171 95 31 476 1390 0.236 4.54 1427 352 12 155 52 20 478 1373 0.258 4.06 1293 265 31 159 111 37 507 1448 0.238 model1 &lt;- lm(R.G~.,data=mlb_2022) model1 %&gt;% tidy() %&gt;% mutate( p.value = scales::pvalue(p.value)) %&gt;% kable(booktabs=T,digits=c(3,3,3,3), caption = &quot;MR Model Estimating Runs Per Game Using Multiple Variables&quot;, col.names = c(&quot;Predictor&quot;, &quot;Estimate&quot;, &quot;Std Error&quot;, &quot;t stat&quot;, &quot;p-value&quot;)) %&gt;% kable_styling(latex_options = &quot;hold_position&quot;) Table 8.11: MR Model Estimating Runs Per Game Using Multiple Variables Predictor Estimate Std Error t stat p-value (Intercept) 0.754 1.519 0.496 0.629 H 0.012 0.003 4.147 0.001 X2B 0.002 0.005 0.436 0.671 X3B 0.003 0.013 0.260 0.799 HR 0.006 0.016 0.387 0.706 SB 0.000 0.001 -0.281 0.784 CS -0.002 0.003 -0.577 0.574 BB 0.003 0.003 0.968 0.352 SO 0.000 0.000 -0.303 0.767 BA -52.967 35.927 -1.474 0.166 OBP 36.428 39.670 0.918 0.377 SLG 8.699 51.196 0.170 0.868 OPS -16.641 35.971 -0.463 0.652 TB NA NA NA NA GDP -0.004 0.001 -4.588 &lt;0.001 HBP 0.003 0.003 1.091 0.297 SH 0.002 0.002 1.412 0.183 SF 0.008 0.002 3.300 0.006 LOB -0.005 0.001 -7.013 &lt;0.001 8.5.1 Model Selection using BIC library(leaps) regsubsets.out &lt;- regsubsets(`R.G`~., data = mlb_2022, nbest = 1, nvmax = 10, method = &quot;exhaustive&quot;) ## Warning in leaps.setup(x, y, wt = wt, nbest = nbest, nvmax = nvmax, force.in = ## force.in, : 1 linear dependencies found ## Reordering variables and trying again: summary.out &lt;- summary(regsubsets.out) plot(summary.out$bic, xlab = &quot;Number of Variables&quot;, ylab = &quot;BIC&quot;, type = &quot;l&quot;) bic_min = which.min(summary.out$bic) # 6 points(bic_min, summary.out$bic[bic_min], col = &quot;red&quot;, cex = 2, pch = 20) # Model with only one predictor summary.out$which[1,] ## (Intercept) H X2B X3B HR SB ## TRUE FALSE FALSE FALSE FALSE FALSE ## CS BB SO BA OBP SLG ## FALSE FALSE FALSE FALSE FALSE FALSE ## OPS TB GDP HBP SH SF ## TRUE FALSE FALSE FALSE FALSE FALSE ## LOB ## FALSE # Model with lowest BIC which.min(summary.out$bic) ## [1] 9 summary.out$which[which.min(summary.out$bic),] ## (Intercept) H X2B X3B HR SB ## TRUE FALSE FALSE FALSE FALSE FALSE ## CS BB SO BA OBP SLG ## TRUE FALSE FALSE TRUE TRUE TRUE ## OPS TB GDP HBP SH SF ## FALSE TRUE TRUE FALSE TRUE TRUE ## LOB ## TRUE # Model with highest Adj R^2 which.max(summary.out$adjr2) ## [1] 10 summary.out$which[which.max(summary.out$adjr2),] ## (Intercept) H X2B X3B HR SB ## TRUE TRUE FALSE FALSE FALSE FALSE ## CS BB SO BA OBP SLG ## TRUE FALSE FALSE TRUE TRUE FALSE ## OPS TB GDP HBP SH SF ## TRUE TRUE TRUE FALSE TRUE TRUE ## LOB ## TRUE # Model chosen to minimize BIC model2 &lt;- lm(R.G~CS+BA+OBP+SLG+TB+GDP+SH+SF+LOB,data=mlb_2022) model2 %&gt;% tidy() %&gt;% mutate( p.value = scales::pvalue(p.value)) %&gt;% kable(booktabs=T,digits=c(3,3,3,3), caption = &quot;MR Model Estimating Runs Per Game Using Multiple Variables&quot;, col.names = c(&quot;Predictor&quot;, &quot;Estimate&quot;, &quot;Std Error&quot;, &quot;t stat&quot;, &quot;p-value&quot;)) %&gt;% kable_styling(latex_options = &quot;hold_position&quot;) Table 8.12: MR Model Estimating Runs Per Game Using Multiple Variables Predictor Estimate Std Error t stat p-value (Intercept) -0.382 0.420 -0.909 0.374 CS -0.004 0.001 -2.582 0.018 BA -25.454 2.544 -10.004 &lt;0.001 OBP 47.597 3.190 14.920 &lt;0.001 SLG -43.279 4.999 -8.658 &lt;0.001 TB 0.009 0.001 10.082 &lt;0.001 GDP -0.003 0.001 -5.654 &lt;0.001 SH 0.003 0.001 2.540 0.019 SF 0.009 0.001 6.207 &lt;0.001 LOB -0.005 0.000 -10.590 &lt;0.001 8.6 Confounding Variables Definition 8.3 A confounding variable is a variable that is correlated to a predictor variable and response variable that causes a spurious association. Example 8.6 A statistician hypothesizes that an NBA team’s draft position can be used to predict the number of regular-season wins for the team for the upcoming season. To investigate the relationship, they decide to estimate the following simple linear regression model: \\(Wins\\ = \\beta_0 + \\beta_1(Draft\\ Position) + \\epsilon_i\\) Using 2021-22 NBA data, the estimated intercept and slope for the model are: # Data: https://en.wikipedia.org/wiki/2021_NBA_draft NBA_Data &lt;- read.csv(&quot;data/NBA_Draft_and_Win_Data.csv&quot;) lm(Wins_2021_2022 ~ Draft_Position_2021, data=NBA_Data) ## ## Call: ## lm(formula = Wins_2021_2022 ~ Draft_Position_2021, data = NBA_Data) ## ## Coefficients: ## (Intercept) Draft_Position_2021 ## 30.2621 0.6928 Interpret the estimated slope in this model. Recognizing that the SLR model may lead to erroneous lines of logic, the statistician decides to tackle the confounding by adding the wins for the team in the previous season to the model as a covariate. The theoretical model being estimated is now as follows: \\(Wins\\ = \\beta_0 + \\beta_1(Draft\\ Position) + \\beta_2(Previous\\ Season\\ Wins) + \\epsilon_i\\) lm(Wins_2021_2022 ~ Draft_Position_2021 + Wins_2020_2021_Scaled, data=NBA_Data) ## ## Call: ## lm(formula = Wins_2021_2022 ~ Draft_Position_2021 + Wins_2020_2021_Scaled, ## data = NBA_Data) ## ## Coefficients: ## (Intercept) Draft_Position_2021 Wins_2020_2021_Scaled ## -12.731 -1.859 2.013 When controlling for an NBA team’s wins in the previous season, the sign for the slope coefficient for draft position flips to a negative. This suggests that for teams with the same winning percentage in the previous season, a lower draft position is associated with more wins in the following season. The results of this model, which included an important confounding variable, aligned with the conventional wisdom that lower draft positions are helpful for a team’s future success. 8.7 Interaction Sometimes the relationship between an independent variable and a dependent variable depend on the value of a different independent value. In such a case, we say that the predictor variables interact and we should consider including an interaction term in our model. # load nfl team statistics data from 2022 nfl22 &lt;- read_csv(&quot;data/nfl22.csv&quot;,show_col_types = F) nfl22 &lt;- nfl22 %&gt;% slice(1:32) %&gt;% mutate(PPG=PF/G,RYPG=Rush_Yds/G,PYPG=Pass_Yds/G) %&gt;% select(Tm,PPG,RYPG,PYPG) %&gt;% column_to_rownames(&quot;Tm&quot;) nfl22 %&gt;% slice(1:5) %&gt;% kable(booktabs=T,digits=1) PPG RYPG PYPG Kansas City Chiefs 29.2 115.9 297.8 Philadelphia Eagles 28.1 147.6 241.5 Dallas Cowboys 27.5 135.2 219.8 Buffalo Bills 28.4 139.5 258.1 Detroit Lions 26.6 128.2 251.8 library(gridExtra) p1 &lt;- nfl22 %&gt;% ggplot(aes(x=RYPG,y=PPG)) + geom_point() + geom_smooth(method=&quot;lm&quot;,se=F) + labs(title=&quot;Rushing Yards Per Game vs. Points Per Game&quot;, x=&quot;Rushing Yards Per Game (RYPG)&quot;, y=&quot;Points Per Game&quot;) p2 &lt;- nfl22 %&gt;% ggplot(aes(x=PYPG,y=PPG)) + geom_point() + geom_smooth(method=&quot;lm&quot;,se=F) + labs(title=&quot;Passing Yards Per Game vs. Points Per Game&quot;, x=&quot;Passing Yards Per Game (RYPG)&quot;, y=&quot;Points Per Game&quot;) p3 &lt;- nfl22 %&gt;% ggplot(aes(x=RYPG,y=PYPG)) + geom_point() + geom_smooth(method=&quot;lm&quot;,se=F) + labs(title=&quot;Rushing Yards Per Game vs. Passing Yards Per Game&quot;, x=&quot;Rushing Yards Per Game (RYPG)&quot;, y=&quot;Passing Yards Per Game&quot;) grid.arrange(p1,p2,p3,nrow=3) model1 &lt;- lm(PPG~RYPG+PYPG,data=nfl22) # Nicely output regression information model1 %&gt;% tidy() %&gt;% mutate( p.value = scales::pvalue(p.value), term = c(&quot;Intercept&quot;,&quot;RYPG&quot;,&quot;PYPG&quot;) ) %&gt;% kable(booktabs=T,digits=c(3,3,3,3), caption = &quot;SLR Model Estimating PPG Using RYPG and PYPG&quot;, col.names = c(&quot;Predictor&quot;, &quot;Estimate&quot;, &quot;Std Error&quot;, &quot;t stat&quot;, &quot;p-value&quot;)) %&gt;% kable_styling(latex_options = &quot;hold_position&quot;) Table 8.13: SLR Model Estimating PPG Using RYPG and PYPG Predictor Estimate Std Error t stat p-value Intercept -15.509 3.825 -4.055 &lt;0.001 RYPG 0.122 0.017 7.280 &lt;0.001 PYPG 0.103 0.010 9.833 &lt;0.001 model2 &lt;- lm(PPG~RYPG*PYPG,data=nfl22) # Nicely output regression information model2 %&gt;% tidy() %&gt;% mutate( p.value = scales::pvalue(p.value), term = c(&quot;Intercept&quot;,&quot;RYPG&quot;,&quot;PYPG&quot;,&quot;RYPG:PYPG&quot;) ) %&gt;% kable(booktabs=T,digits=c(3,3,3,3), caption = &quot;SLR Model Estimating PPG Using RYPG and PYPG&quot;, col.names = c(&quot;Predictor&quot;, &quot;Estimate&quot;, &quot;Std Error&quot;, &quot;t stat&quot;, &quot;p-value&quot;)) %&gt;% kable_styling(latex_options = &quot;hold_position&quot;) Table 8.14: SLR Model Estimating PPG Using RYPG and PYPG Predictor Estimate Std Error t stat p-value Intercept -7.082 8.751 -0.809 0.425 RYPG 0.056 0.064 0.868 0.393 PYPG 0.063 0.039 1.627 0.115 RYPG:PYPG 0.000 0.000 1.070 0.294 Example 8.7 Acquire the average fastball and curveball velocities for baseball pitchers in 2022. Assess whether FBv and CBv interact when modeling K/9 (strikeouts per nine innings) # pit22 &lt;- fg_pitch_leaders(x=2022,y=2022,qual = &quot;n&quot;) %&gt;% # select(Name,FBv,CBv,`K_9`) # pit22 %&gt;% na.omit() %&gt;% arrange(desc(FBv)) %&gt;% slice(1:5) %&gt;% kable(booktabs=T) # pit_mod1 &lt;- lm(K_9~FBv+CBv,data=pit22) # pit_mod2 &lt;- lm(K_9~FBv*CBv,data=pit22) 8.8 Weighted Least Squares Regression Recall from Example 8.1 where we attempted to predict ERA in 2022 from ERA and FIP from 2021. One concern in this analysis was that each pitcher pitched a different number of innings. We’d like to account for this by giving more weight to pitchers with more innings pitched. This can be accomplished by using weighted least squares regression. Weighted least squares regression is particularly used when the data exhibits non-constant variance Example 8.8 Build SLR models predicting ERA22 from ERA21 with and without weights. pit21 &lt;- bref_daily_pitcher(&quot;2021-01-01&quot;, &quot;2021-12-31&quot;) %&gt;% fip_plus() %&gt;% dplyr::select(Name, IP, ERA, FIP) %&gt;% dplyr::arrange(dplyr::desc(IP)) %&gt;% mutate(IP21=IP,ERA21=ERA,FIP21=FIP) pit22 &lt;- bref_daily_pitcher(&quot;2022-01-01&quot;, &quot;2022-12-31&quot;) %&gt;% fip_plus() %&gt;% dplyr::select(Name, IP, ERA, FIP) %&gt;% dplyr::arrange(dplyr::desc(IP)) %&gt;% mutate(IP22=IP,ERA22=ERA,FIP22=FIP) # merge the datasets together, remove redundant columns all_pit_min0 &lt;- pit21 %&gt;% left_join(pit22,by = &quot;Name&quot;) %&gt;% select(-c(2:4,8:10)) %&gt;% filter(IP21&gt;0 &amp; IP22&gt;0) all_pit_min5 &lt;- pit21 %&gt;% left_join(pit22,by = &quot;Name&quot;) %&gt;% select(-c(2:4,8:10)) %&gt;% filter(IP21&gt;5 &amp; IP22&gt;5) all_pit %&gt;% ggplot(aes(x=ERA21,y=ERA22,size=IP21+IP22)) + geom_point(alpha=0.2,color=&quot;blue&quot;) + scale_size(range = c(0,5)) mod_slr &lt;- lm(ERA22~ERA21,data=all_pit_min0) mod_wls &lt;- lm(ERA22~ERA21,data=all_pit_min0,weights = IP21) Table 8.15: SLR Model Estimating ERA2022 using ERA2021 (equal weights) Predictor Estimate Std Error t stat p-value Intercept 4.475 0.258 17.359 &lt;0.001 Earned Run Average, 2021 0.019 0.044 0.421 0.674 Table 8.16: SLR Model Estimating ERA2022 using ERA2021 (weighted by IP) Predictor Estimate Std Error t stat p-value Intercept 3.156 0.324 9.728 &lt;0.001 Earned Run Average, 2021 0.261 0.076 3.458 &lt;0.001 mod_slr &lt;- lm(ERA22~ERA21,data=all_pit_min5) mod_wls &lt;- lm(ERA22~ERA21,data=all_pit_min5,weights = IP21) Table 8.17: SLR Model Estimating ERA2022 using ERA2021 (equal weights) Predictor Estimate Std Error t stat p-value Intercept 3.726 0.241 15.438 &lt;0.001 Earned Run Average, 2021 0.135 0.051 2.658 0.008 Table 8.18: SLR Model Estimating ERA2022 using ERA2021 (weighted by IP) Predictor Estimate Std Error t stat p-value Intercept 3.018 0.283 10.676 &lt;0.001 Earned Run Average, 2021 0.279 0.067 4.183 &lt;0.001 8.9 Stepwise Regression using Cross-Validation Cross-validation is a resampling method that uses different portions of the data to train and test models. It is often used when we aim to do prediction. Example 8.9 Using the 2022 MLB team statistics data, use cross-validation to determine a linear model with runs/game as the response and BA, OBP, SLG, and OPS as predictors. Use 10-fold cross-validation with 3 repeats. # Acquire the data library(rvest) url &lt;- &quot;https://www.baseball-reference.com/leagues/majors/2022.shtml&quot; site &lt;- read_html(url) mlb22 &lt;- site %&gt;% html_elements(&quot;#teams_standard_batting&quot;) %&gt;% html_table() mlb22 &lt;- mlb22 %&gt;% data.frame() %&gt;% column_to_rownames(&quot;Tm&quot;) %&gt;% rename(`R/G`=R.G) %&gt;% slice(-(31:33)) %&gt;% select(`R/G`,BA,OBP,SLG,OPS) mlb22 &lt;- write_csv(mlb22,&quot;data/mlb22.csv&quot;) mlb22 &lt;- read_csv(&quot;data/mlb22.csv&quot;) set.seed(2023) library(caret) mod_null &lt;- lm(`R/G` ~ 1, data=mlb22) mod_full &lt;- lm(`R/G` ~ ., data=mlb22) set_train &lt;- trainControl(method=&quot;repeatedcv&quot;, number=10, repeats=3) mod_cv &lt;- train(`R/G` ~ ., data=mlb22, scope = formula(mod_null), method=&quot;lmStepAIC&quot;, direction=&quot;both&quot;, trace=FALSE, trControl=set_train) # Null model coef(mod_null) ## (Intercept) ## 4.284 # Full model with all variables coef(mod_full) ## (Intercept) BA OBP SLG OPS ## -4.054414 -4.481930 66.032434 61.003985 -49.862273 # Model selected using stepwise selection with CV coef(mod_cv$finalModel) ## (Intercept) BA OBP SLG ## -3.982217 -6.311483 17.489115 11.030694 8.10 Ridge Regression Ridge regression is a method for estimating coefficients of a multiple regression model and used particularly used when predictor variables are highly correlated. In particular, model estimates of \\(\\hat{\\beta}_i\\) are calculated to minimize: \\(\\sum_{i=1}^n (y_i - \\beta_0 - \\sum_{j=1}^p \\beta_j x_{ij})^2 + \\lambda \\sum_{j=1}^p \\beta_j^2\\) Example 8.10 NHL team statistics for the 2021-2022 season is contained in nhl21-22.csv. The goal is to build a ridge regression model with team points as the response and other team statistics as the predictors. Load the data and display in a kable table. # Load data and output a subset of the table nhl2122 &lt;- read_csv(&quot;data/nhl21-22.csv&quot;) nhl2122$Team &lt;- gsub(&quot;\\\\*&quot;, &quot;&quot;,nhl2122$Team) nhl2122 %&gt;% select(1:10) %&gt;% slice(1:10) %&gt;% kable(booktabs=T) Team PTS SOS GF/G GA/G PP% PK% SH SHA PIM/G Florida Panthers 122 -0.08 4.11 2.95 24.43 79.54 12 8 10.1 Colorado Avalanche 119 -0.04 3.76 2.83 24.01 79.66 6 5 9.0 Carolina Hurricanes 116 -0.05 3.38 2.44 21.98 88.04 4 3 9.2 Toronto Maple Leafs 115 -0.06 3.80 3.07 27.27 82.05 13 4 8.6 Minnesota Wild 113 -0.02 3.72 3.04 20.54 76.14 2 5 10.8 Calgary Flames 111 -0.05 3.55 2.51 22.88 83.20 7 3 9.1 Tampa Bay Lightning 110 -0.02 3.48 2.78 23.94 80.56 7 5 11.0 New York Rangers 110 -0.03 3.05 2.49 25.23 82.30 8 2 8.2 St. Louis Blues 109 -0.05 3.77 2.91 26.97 84.09 9 5 7.5 Boston Bruins 107 -0.05 3.09 2.66 21.19 81.30 5 6 9.9 Fit the optimal value for lambda. library(glmnet) set.seed(2023) y &lt;- nhl2122$PTS x &lt;- nhl2122 %&gt;% select(-Team,-PTS) %&gt;% scale() %&gt;% data.matrix() lambdas &lt;- 10^seq(3, -3, by = -.1) # fit the ridge regression model model &lt;- glmnet(x, y, alpha = 0, lambda = lambdas) # fit the ridge regression model using cross-validation cv_model &lt;- cv.glmnet(x, y, alpha = 0, lambda = lambdas) ( best_lambda &lt;- cv_model$lambda.min ) ## [1] 1.584893 Plot MSE as a function of log(lambda). plot(cv_model) Create a trace plot. # Trace plot # Note that coefficients shrink to zero as lambda gets large # When lambda is small, we get ordinary least squares regression plot(model,xvar=&quot;lambda&quot;,label = T) Find the final ridge regression model. # Use optimal lambda to find final ridge regression model best_model &lt;- glmnet(x, y, alpha = 0, lambda = best_lambda) coef(best_model) ## 12 x 1 sparse Matrix of class &quot;dgCMatrix&quot; ## s0 ## (Intercept) 91.0000000 ## SOS -4.5830640 ## GF/G 7.6021591 ## GA/G -6.6140452 ## PP% 2.1545416 ## PK% -1.6310942 ## SH -0.3088951 ## SHA -0.2400908 ## PIM/G -0.5156325 ## oPIM/G 0.5151495 ## S% 0.2863092 ## SV% 1.5397393 8.11 Lasso Regression Lasso regression is a method for estimating coefficients of a multiple regression model and is especially useful for variable selection. In particular, model estimates of \\(\\hat{\\beta}_i\\) are calculated to minimize: \\(\\sum_{i=1}^n (y_i - \\beta_0 - \\sum_{j=1}^p \\beta_j x_{ij})^2 + \\lambda \\sum_{j=1}^p |\\beta_j|\\) Example 8.11 Use the NHL 2021-2022 team statistics dataset to fit a regression model using LASSO. Fit the optimal value for lambda. set.seed(2023) y &lt;- nhl2122$PTS x &lt;- nhl2122 %&gt;% select(-Team,-PTS) %&gt;% scale() %&gt;% data.matrix() lambdas &lt;- 10^seq(2, -2, by = -.1) # fit the ridge regression model model &lt;- glmnet(x, y, alpha = 1, lambda = lambdas) # fit the ridge regression model using cross-validation cv_model &lt;- cv.glmnet(x, y, alpha = 1, lambda = lambdas) ( best_lambda &lt;- cv_model$lambda.min ) ## [1] 1 Plot MSE as a function of log(lambda). plot(cv_model) Create a trace plot. # Trace plot # Note that coefficients shrink to zero as lambda gets large # When lambda is small, we get ordinary least squares regression plot(model,xvar=&quot;lambda&quot;,label = T) Find the final lasso regression model. # Use optimal lambda to find final lasso regression model lasso_model &lt;- glmnet(x, y, alpha = 1, lambda = best_lambda) coef(lasso_model) ## 12 x 1 sparse Matrix of class &quot;dgCMatrix&quot; ## s0 ## (Intercept) 91.0000000 ## SOS -0.7500131 ## GF/G 10.0306214 ## GA/G -9.1194278 ## PP% 1.2783637 ## PK% . ## SH . ## SHA . ## PIM/G . ## oPIM/G . ## S% . ## SV% . 8.12 Elastic Net Elastic Net Regularization is a method for estimating coefficients of a multiple regression model by combining Ridge and LASSO Regression In particular, model estimates of \\(\\hat{\\beta}_i\\) are calculated to minimize: \\(\\sum_{i=1}^n (y_i - \\beta_0 - \\sum_{j=1}^p \\beta_j x_{ij})^2 + \\lambda \\cdot \\left( \\alpha \\cdot \\sum_{j=1}^p |\\beta_j| + \\frac{1-\\alpha}{2} \\sum_{j=1}^p \\beta_j^2 \\right)\\) Example 8.12 Use the NHL 2021-2022 team statistics dataset to fit a regression model using Elastic Net and cross-validation. First tune the model parameters, \\(\\alpha\\) and \\(\\lambda\\). set.seed(2023) library(caret) cv5 = trainControl(method = &quot;cv&quot;, number = 5) elnet = train(PTS~.-Team,data=nhl2122, metric = &quot;RMSE&quot;, preProcess = c(&quot;center&quot;, &quot;scale&quot;), tuneGrid = expand.grid( .alpha = seq(0, 1, length.out = 10), .lambda = seq(0, 5, length.out = 101)), method = &quot;glmnet&quot;, trControl = cv5) elnet$bestTune ## alpha lambda ## 931 1 1.05 Find the final model after tuning. elastic_mod &lt;- glmnet(x, y, alpha = elnet$bestTune$alpha, lambda = elnet$bestTune$lambda) coef(elastic_mod) ## 12 x 1 sparse Matrix of class &quot;dgCMatrix&quot; ## s0 ## (Intercept) 91.0000000 ## SOS -0.7821577 ## GF/G 9.9863842 ## GA/G -9.0747940 ## PP% 1.2652996 ## PK% . ## SH . ## SHA . ## PIM/G . ## oPIM/G . ## S% . ## SV% . 8.13 Mixed Effects Models The term factor refers to a variable that is thought to influence the outcome of an experiment. A factor has levels, which refer the the specific values of that factor. For example, team might be a factor with 30 levels, one for each team. the specific factors that were used in the experiment, and their levels, are of direct interest to the researcher. Conclusions of the analysis apply to the factors and the specific factor levels tested. Example: is there a difference in spin rate among these four pitchers? the levels of a random factor represent a random sample from a larger population of possible levels. Example: How much variability in spin rate is explained by year? Say there are 30 possible years of data (levels), and we would like to know if year makes a difference (at all). The term effect refers to a variable’s coefficient, or in some cases, the difference between two coefficients. effects or coefficients associated with fixed factors (these effects are of direct interest) effects or coefficients associated with random factors (these effects are NOT of direct interest; the variation among effects is of interest) Example 8.13 In this exercise, we will assess the relationship between the Four Factors and Win Percentage in professional basketball using team statistics from 2000-2022. Scrape advanced team statistics from Basketball Reference for the years 2000-2022. We are interested in the following variables: Team, Four Factors, Season. url_base &lt;- &quot;https://www.basketball-reference.com/leagues/NBA_&quot; year = 2000:2022 n_year = length(year) url_end &lt;- &quot;.html&quot; library(rvest) nba_team_data &lt;- NULL for(i in 1:n_year){ url &lt;- paste(url_base,year[i],url_end,sep = &quot;&quot;) site &lt;- read_html(url) temp_table &lt;- site %&gt;% html_element(&quot;#advanced-team&quot;) %&gt;% html_table() %&gt;% data.frame() names(temp_table) &lt;- as.character(temp_table[1,]) temp_table &lt;- temp_table[-1,] %&gt;% select(1:22) %&gt;% filter(Team != &quot;League Average&quot;) %&gt;% mutate(Team = gsub(&quot;\\\\*&quot;, &quot;&quot;, Team)) teams &lt;- temp_table %&gt;% select(Team) %&gt;% slice(1:30) temp_table[,3:22] &lt;- temp_table %&gt;% select(3:22) %&gt;% mutate_if(is.character, as.numeric) temp_table &lt;- temp_table %&gt;% mutate(WinPct = W/(W+L)) %&gt;% select(Team,`WinPct`,`eFG%`,`TOV%`,`ORB%`,`FT/FGA`) %&gt;% mutate(Season=year[i]) nba_team_data &lt;- rbind(nba_team_data,temp_table) } nba_team_data &lt;- nba_team_data %&gt;% as.data.frame() nba_team_data %&gt;% slice(1:5) %&gt;% kable(booktabs=T,digits=3) Team WinPct eFG% TOV% ORB% FT/FGA Season Los Angeles Lakers 0.817 0.484 12.7 30.6 0.241 2000 Portland Trail Blazers 0.720 0.501 14.5 30.3 0.240 2000 San Antonio Spurs 0.646 0.488 14.3 27.8 0.258 2000 Phoenix Suns 0.646 0.491 15.2 29.3 0.217 2000 Utah Jazz 0.671 0.490 14.3 29.5 0.260 2000 Inspect the correlational structure of the dataset nba_team_data %&gt;% select(-Team,-Season) %&gt;% ggpairs() Fit a mixed effects model with team modeled as a random effect and the four factors as fixed effects. library(lme4) nba_team_data_scaled &lt;- nba_team_data %&gt;% mutate_if(is.numeric,scale) nba_model &lt;- lmer(WinPct~(1|Team)+`eFG%`+`TOV%`+`ORB%`+`FT/FGA`, data=nba_team_data_scaled) summary(nba_model) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: WinPct ~ (1 | Team) + `eFG%` + `TOV%` + `ORB%` + `FT/FGA` ## Data: nba_team_data_scaled ## ## REML criterion at convergence: 1537.4 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.11982 -0.65998 -0.00056 0.65763 2.69461 ## ## Random effects: ## Groups Name Variance Std.Dev. ## Team (Intercept) 0.05759 0.2400 ## Residual 0.50651 0.7117 ## Number of obs: 685, groups: Team, 36 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) -0.01452 0.04950 -0.293 ## `eFG%` 0.67970 0.03774 18.009 ## `TOV%` -0.25415 0.03357 -7.570 ## `ORB%` 0.43837 0.03864 11.346 ## `FT/FGA` 0.23650 0.03223 7.339 ## ## Correlation of Fixed Effects: ## (Intr) `eFG%` `TOV%` `ORB%` ## `eFG%` 0.016 ## `TOV%` 0.005 0.283 ## `ORB%` 0.007 0.531 -0.073 ## `FT/FGA` -0.002 -0.063 -0.254 -0.321 Fit a mixed effects model with team and season modeled as random effects and the four factors as fixed effects. library(lme4) nba_team_data_scaled &lt;- nba_team_data %&gt;% mutate_if(is.numeric,scale) nba_model &lt;- lmer(WinPct~(1|Team)+(1|Season)+`eFG%`+`TOV%`+`ORB%`+`FT/FGA`, data=nba_team_data_scaled) summary(nba_model) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: WinPct ~ (1 | Team) + (1 | Season) + `eFG%` + `TOV%` + `ORB%` + ## `FT/FGA` ## Data: nba_team_data_scaled ## ## REML criterion at convergence: 1353.1 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.09019 -0.68621 -0.01116 0.61425 2.79536 ## ## Random effects: ## Groups Name Variance Std.Dev. ## Team (Intercept) 0.05333 0.2309 ## Season (Intercept) 0.44107 0.6641 ## Residual 0.33990 0.5830 ## Number of obs: 685, groups: Team, 36; Season, 23 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) -0.003365 0.145762 -0.023 ## `eFG%` 1.017012 0.037093 27.418 ## `TOV%` -0.362411 0.029101 -12.454 ## `ORB%` 0.301020 0.034965 8.609 ## `FT/FGA` 0.182931 0.031299 5.845 ## ## Correlation of Fixed Effects: ## (Intr) `eFG%` `TOV%` `ORB%` ## `eFG%` 0.007 ## `TOV%` 0.001 0.157 ## `ORB%` 0.000 0.271 -0.021 ## `FT/FGA` -0.001 -0.177 -0.212 -0.163 8.14 Logistic Regression 8.14.1 Sack and Interception Probability Models (Mathletics, chapter 27, page 230) (Mathletics, chapter 1, page 13) 8.14.2 Soccer Goal Logistic Model (Mathletics, chapter 39, page 354) 8.14.3 Field Goal Success (AM, page 266) "],["principal-component-analysis.html", "Chapter 9 Principal Component Analysis", " Chapter 9 Principal Component Analysis "],["clustering.html", "Chapter 10 Clustering", " Chapter 10 Clustering "],["classification.html", "Chapter 11 Classification", " Chapter 11 Classification "],["nonparametric-methods.html", "Chapter 12 Nonparametric Methods", " Chapter 12 Nonparametric Methods "],["sports-drafts.html", "Chapter 13 Sports Drafts", " Chapter 13 Sports Drafts "],["baseball-1.html", "Chapter 14 Baseball", " Chapter 14 Baseball "],["football-1.html", "Chapter 15 Football", " Chapter 15 Football "],["basketball-1.html", "Chapter 16 Basketball", " Chapter 16 Basketball "],["hockey-1.html", "Chapter 17 Hockey", " Chapter 17 Hockey "],["soccer-1.html", "Chapter 18 Soccer", " Chapter 18 Soccer "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
