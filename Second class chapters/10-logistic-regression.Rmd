---
output:
  pdf_document: default
  html_document: default
---
```{r, echo=F, message=F,warning=F}
library(tidyverse)
library(kableExtra)
knitr::opts_chunk$set(tidy=FALSE,message=F,warning=F)

# kable table global setup
kt <- function(data) {
  knitr::kable(data, digits=3, align=c('l','c','c','c','c','c','c','c','c')) %>% kable_styling(bootstrap_options='striped', latex_options='HOLD_position', full_width = F, position = "center")
}
```


# Logistic Regression

In the previous regression examples, we have considered cases where the response variable is a continuous random variable. There are many cases in sports analytics where the response may be a binary or categorical variable. In such cases, logistic regression is likely a more appropriate model.

Let $\pi_i$ be the probability be that the response variable, $Y_i$, is equal to 1 and $1-\pi_i$ is the probability that $Y_i$ is equal to 0.

:::{.definition}
The ***log-odds*** (or ***logit***) of a probability $p$ is defined by:

$logit(p) = log.odds(p) = log\left(\frac{p}{1-p}\right)$
:::

## Logistic Regression Model

Logistic regression allows us to model the logit as a linear function of the predictor variables.

For example, a simple logistic regression model is defined by:

$logit(p) = log\left(\frac{p}{1-p}\right) = \beta_0 + \beta_1 x$ \

We also have:

$E[Y_i] = \pi_i = \frac{exp(\beta_0+\beta_1X_i)}{1+exp(\beta_0+\beta_1X_i)}$ \

:::{.definition}
The ***odds ratio*** of event $X_1$ relative to event $X_2$ is defined by:

$\hat{OR} = \frac{odds_1}{odds_2} = \exp{\hat{\beta}_1}$

The odds ratio represents the change in odds for a one-unit increase in $X$. \
:::

\newpage

## Example: NFL Spread and Winning

```{r}
# Data from Kaggle:
# https://www.kaggle.com/datasets/tobycrabtree/nfl-scores-and-betting-data
nfl_spread <- read_csv("data/nfl_spread_history.csv",show_col_types = F)
names(nfl_spread)
nfl_spread %>% slice(1:5) %>% select(1,5,6,7,8,10)
```

\newpage

```{r}
# adjust date format
nfl_spread$schedule_date <- as.Date(nfl_spread$schedule_date, "%m/%d/%Y")

# select games since 2000 and grab variables of interest
nfl_spread <- nfl_spread %>% 
  filter(schedule_date > "2000-01-01") %>%
  select(team_home,score_home,team_away,score_away,
         team_favorite_id,spread_favorite)

teams <- read.csv("data/nfl_teams.csv")
teams <- teams %>% filter(team_division != "")
team_names <- teams$team_name 
team_ids <- teams$team_id 
team_df <- data.frame(favorite_team = team_names, team_favorite_id = team_ids)
team_df %>% slice(1:5) %>% kable(booktabs=T)
```

\newpage

```{r}
nfl_spread <- nfl_spread %>% 
  inner_join(team_df,by="team_favorite_id",multiple="all")

nfl_spread <- nfl_spread %>% 
  mutate(home_diff = score_home - score_away,
         winning_team = ifelse(score_home > score_away,team_home,team_away),
         favorite_win = ifelse(favorite_team == winning_team,1,0),
         home_spread = ifelse(team_home==favorite_team,spread_favorite,-spread_favorite),
         home_win = ifelse(team_home == winning_team,1,0),
         home_won = ifelse(home_win == 1,home_spread,NA),
         home_lost = ifelse(home_win == 0,home_spread,NA))
nfl_spread %>% 
  slice(1:5) %>% 
  select(team_home,team_away,score_home,score_away,home_spread,home_win) %>% 
  kable(booktabs=T)
```

\newpage

```{r,message=F}
nfl_spread %>% ggplot(aes(x=home_spread,y=home_win)) +
  geom_smooth(method = "glm", 
    method.args = list(family = "binomial")) + 
  geom_rug(aes(x = home_won), sides = "t", alpha = 0.1) +
  geom_rug(aes(x = home_lost), sides = "b", alpha = 0.1)
```

\newpage

```{r}
mod <- glm(home_win~home_spread,data=nfl_spread,family="binomial")
summary(mod)
```

```{r}
predict(mod,newdata=data.frame(home_spread = c(-10,-5,-1,0,1,5,10)),type="response")
```

(a) Write the estimated logistic regression equation.\ \vfill

(b) Determine and interpret the change in log-odds for a one-unit increase in home_spread.\ \vfill

(c) Estimate the probability that the home team wins given they are 5 point favorites. \ \vfill

\newpage

## Multiple Logistic Regression

We can extend the framework of the simple logistic regression model to include multiple predictor variables. In this case, we have the following multiple logistic regression model.

$logit(p) = log\left(\frac{p}{1-p}\right) = \beta_0 + \beta_1 x_1 + \ldots + \beta_p x_p$ \

We also have:

$E[Y_i] = \pi_i = \frac{exp(\beta_0+\beta_1X_i+\ldots + \beta_pX_p)}{1+exp(\beta_0+\beta_1X_i+\ldots + \beta_pX_p)}$ \


## Example: Field Goal Success

```{r}
# Example outlined at:
# http://rstudio-pubs-static.s3.amazonaws.com/
# 264999_c04ec6882e474eb9ab5f3feb3e62e40d.html

nfl_fg <- read_csv("data/nfl2008_fga.csv",show_col_types = F)
names(nfl_fg)

nfl_fg %>% 
  slice_head(n=10) %>% 
  select(1:10) %>% 
  kable(booktabs=T)
```

\newpage

```{r}
nfl_fg <- nfl_fg %>% 
  mutate(Result = ifelse(GOOD==1,"Made","Missed"))
nfl_fg %>% 
  ggplot(aes(x=distance,y=GOOD)) + 
  geom_point() +
  geom_smooth(method = "glm", 
    method.args = list(family = "binomial")) +  
  geom_jitter(height = 0.05)
```

\newpage

```{r,message=F}
nfl_fg %>% ggplot(aes(distance)) + geom_histogram() + facet_grid(~Result)
```

\newpage

```{r,message=F}
nfl_fg <- read_csv("data/nfl2008_fga.csv",show_col_types = F)
names(nfl_fg) <- tolower(names(nfl_fg))
names(nfl_fg) <- str_replace(names(nfl_fg), "team", "_team")
names(nfl_fg) <- str_replace(names(nfl_fg), "score", "_score")
# rename some other variables
nfl_fg <- nfl_fg %>% 
  dplyr::rename(game_date = gamedate, 
         to_go = togo, 
         yd_line = ydline, 
         home_kick = homekick, 
         time_rem = timerem)
nfl_fg <- nfl_fg %>% 
  dplyr::rename(kick_score_diff = kickdiff, 
         min_rem = min, 
         sec_rem = sec, 
         def_team = def,
         made = good)

library(lubridate)
nfl_fg$game_date <- ymd(nfl_fg$game_date)
kicker_list <- nfl_fg %>% 
  group_by(name, kicker, kick_team) %>% 
  summarise(n = n(), made = mean(made)) %>% 
  arrange(name)
kicker_list %>% data.frame() %>% slice_head(n=10) %>% kable(booktabs=T)
```

\newpage

```{r,message=F}
# fix duplicate names and their IDs
index <- which(nfl_fg$name == "S.Hauschka" & nfl_fg$kicker == 3)
nfl_fg[["kicker"]][[index]] <- 4
index <- which(nfl_fg$name == "J.Brown" & nfl_fg$kicker == 34)
nfl_fg[["kicker"]][[index]] <- 35
index <- which(nfl_fg$kicker == 9 & nfl_fg$name == "D.Rayner")
nfl_fg[["kicker"]][[index]] <- 38
index <- which(nfl_fg$kicker == 26 & nfl_fg$name == "M.Nugent")
nfl_fg[["kicker"]][[index]] <- 39

kicker_list <- nfl_fg %>% 
  group_by(name, kicker, kick_team) %>% 
  summarise(n = n(), made = mean(made)) %>% 
  arrange(name)
kicker_list %>% data.frame() %>% slice_head(n=10) %>% kable(booktabs=T)
```

\newpage

```{r,message=F}
# dataframe of kickers with less than 5 attempts
temp <- nfl_fg %>% 
  group_by(name, kicker) %>% 
  summarise(n = n(), made = mean(made)) %>% 
  filter(n < 5)
# list of names of kickers with less than 5 attempts
names = temp$name
# filter dataset to not include the kickers with less than 5 attempts
for (n in names) {
  nfl_fg <- nfl_fg %>% filter(name != n)
}
temp <- nfl_fg %>% 
  group_by(name) %>% 
  summarise(n= n(), made_pct = mean(made)) %>% 
  arrange(desc(made_pct), desc(n)) %>% 
  mutate(kicker_rank = rank(desc(made_pct), ties.method = "first")) %>% 
  arrange(kicker_rank)
temp %>% slice(1:10) %>% kable(booktabs=T)
temp <- temp %>% 
  select(name, kicker_rank)
nfl_fg <- left_join(nfl_fg, temp, by = "name")
nfl_fg$name <- NULL
nfl_fg$kicker <- NULL
```

\newpage

```{r}
fg_mod <- glm(made ~ distance, data = nfl_fg, family = "binomial")
summary(fg_mod)
```

```{r}
predict(fg_mod,newdata=data.frame(distance = c(30,40,50,60,70)),type="response")
```



\newpage

```{r}
fg_mod2 <- glm(made ~ distance+kicker_rank, data = nfl_fg, family = "binomial")
summary(fg_mod2)
```

```{r}
predict(fg_mod2,newdata=data.frame(distance = 50,kicker_rank=1),type="response")
```

(a) Write the estimated logistic regression equation.\ \vfill

(b) Determine and interpret the change in log-odds for a one-unit increase in distance while holding kicker rank constant.\ \vfill

(c) Determine and interpret the change in log-odds for a one-unit increase in kicker rank while holding distance constant.\ \vfill

(d) Estimate the probability that a field goal is good given that it was from 50 yards and was kicked by the top ranked kicker. \ \vfill
